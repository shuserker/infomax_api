#!/usr/bin/env python3
"""
POSCO ì›Œì¹˜í–„ìŠ¤í„° ì›¹í›… ë³µì› ì „ìš© ë°±ì—… ê´€ë¦¬ì
Webhook Restoration Backup Manager

ì›¹í›… ë³µì› ì‘ì—…ì— íŠ¹í™”ëœ ë°±ì—… ë° ë¡¤ë°± ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import sys
import shutil
import json
import hashlib
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import logging
import traceback

# í•œê¸€ ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('webhook_backup.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class WebhookBackupManager:
    """ì›¹í›… ë³µì› ì „ìš© ë°±ì—… ê´€ë¦¬ì"""
    
    def __init__(self):
        self.backup_root = Path("webhook_backup")
        self.backup_root.mkdir(parents=True, exist_ok=True)
        
        # ì›¹í›… ê´€ë ¨ í•µì‹¬ íŒŒì¼ë“¤
        self.webhook_files = [
            "core/monitoring/monitor_WatchHamster_v3.0.py",
            "webhook_message_restorer.py",
            "webhook_config_restorer.py",
            "compatibility_checker.py"
        ]
        
        # ë°±ì—… ë©”íƒ€ë°ì´í„° íŒŒì¼
        self.metadata_file = self.backup_root / "webhook_backup_metadata.json"
        self.load_metadata()
        
        # ìë™ ë¡¤ë°± ì„¤ì •
        self.auto_rollback_enabled = True
        self.max_backup_count = 10
    
    def load_metadata(self):
        """ë°±ì—… ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
                logger.info("ë°±ì—… ë©”íƒ€ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤")
            except Exception as e:
                logger.warning(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.metadata = {}
        else:
            self.metadata = {}
            logger.info("ìƒˆë¡œìš´ ë°±ì—… ë©”íƒ€ë°ì´í„°ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤")
    
    def save_metadata(self):
        """ë°±ì—… ë©”íƒ€ë°ì´í„° ì €ì¥"""
        try:
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, ensure_ascii=False, indent=2)
            logger.debug("ë°±ì—… ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤")
        except Exception as e:
            logger.error(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            raise
    
    def create_backup(self, backup_name: str, description: str = "") -> str:
        """ì›¹í›… ê´€ë ¨ íŒŒì¼ë“¤ì˜ ë°±ì—… ìƒì„±"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_id = f"webhook_backup_{backup_name}_{timestamp}"
        backup_path = self.backup_root / backup_id
        
        logger.info(f"ğŸ”„ ì›¹í›… ë°±ì—… ìƒì„± ì‹œì‘: {backup_id}")
        
        try:
            # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
            backup_path.mkdir(exist_ok=True)
            
            backed_up_files = []
            file_checksums = {}
            total_size = 0
            
            # ì›¹í›… ê´€ë ¨ íŒŒì¼ë“¤ ë°±ì—…
            for file_path in self.webhook_files:
                source_path = Path(file_path)
                
                if source_path.exists():
                    # ìƒëŒ€ ê²½ë¡œ ìœ ì§€í•˜ì—¬ ë°±ì—…
                    dest_path = backup_path / file_path
                    dest_path.parent.mkdir(parents=True, exist_ok=True)
                    
                    # íŒŒì¼ ë³µì‚¬
                    shutil.copy2(source_path, dest_path)
                    
                    # ì²´í¬ì„¬ ê³„ì‚°
                    checksum = self._calculate_file_checksum(source_path)
                    file_checksums[file_path] = checksum
                    
                    # íŒŒì¼ í¬ê¸° ì¶”ê°€
                    file_size = source_path.stat().st_size
                    total_size += file_size
                    
                    backed_up_files.append(file_path)
                    logger.debug(f"ë°±ì—… ì™„ë£Œ: {file_path} ({file_size} bytes)")
                else:
                    logger.warning(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ë°±ì—…ì—ì„œ ì œì™¸: {file_path}")
            
            # ì¶”ê°€ ì„¤ì • íŒŒì¼ë“¤ë„ ë°±ì—… (ì¡´ì¬í•˜ëŠ” ê²½ìš°)
            additional_files = [
                "webhook_restoration.log",
                "compatibility_integration_test_results.json",
                "webhook_config_restoration_report_*.txt"
            ]
            
            for pattern in additional_files:
                if '*' in pattern:
                    # ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´ ì²˜ë¦¬
                    import glob
                    matching_files = glob.glob(pattern)
                    for file_path in matching_files:
                        if Path(file_path).exists():
                            dest_path = backup_path / file_path
                            dest_path.parent.mkdir(parents=True, exist_ok=True)
                            shutil.copy2(file_path, dest_path)
                            backed_up_files.append(file_path)
                else:
                    if Path(pattern).exists():
                        dest_path = backup_path / pattern
                        dest_path.parent.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(pattern, dest_path)
                        backed_up_files.append(pattern)
            
            # ë°±ì—… ë©”íƒ€ë°ì´í„° ì €ì¥
            self.metadata[backup_id] = {
                'backup_name': backup_name,
                'description': description,
                'created_at': datetime.now().isoformat(),
                'backup_path': str(backup_path),
                'backed_up_files': backed_up_files,
                'file_checksums': file_checksums,
                'file_count': len(backed_up_files),
                'total_size': total_size,
                'status': 'completed'
            }
            
            self.save_metadata()
            
            # ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
            self._cleanup_old_backups()
            
            logger.info(f"âœ… ì›¹í›… ë°±ì—… ìƒì„± ì™„ë£Œ: {backup_id}")
            logger.info(f"   ë°±ì—…ëœ íŒŒì¼ ìˆ˜: {len(backed_up_files)}ê°œ")
            logger.info(f"   ì´ í¬ê¸°: {total_size / 1024:.1f}KB")
            
            return backup_id
            
        except Exception as e:
            logger.error(f"âŒ ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            logger.error(f"ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            
            # ì‹¤íŒ¨í•œ ë°±ì—… ë””ë ‰í† ë¦¬ ì •ë¦¬
            if backup_path.exists():
                shutil.rmtree(backup_path)
            
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ì‹¤íŒ¨ ê¸°ë¡
            if backup_id in self.metadata:
                self.metadata[backup_id]['status'] = 'failed'
                self.metadata[backup_id]['error'] = str(e)
                self.save_metadata()
            
            raise
    
    def _calculate_file_checksum(self, file_path: Path) -> str:
        """íŒŒì¼ ì²´í¬ì„¬ ê³„ì‚°"""
        hash_sha256 = hashlib.sha256()
        
        try:
            with open(file_path, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_sha256.update(chunk)
            return hash_sha256.hexdigest()
        except Exception as e:
            logger.warning(f"ì²´í¬ì„¬ ê³„ì‚° ì‹¤íŒ¨ {file_path}: {e}")
            return ""
    
    def rollback_to_backup(self, backup_id: str) -> bool:
        """ì§€ì •ëœ ë°±ì—…ìœ¼ë¡œ ë¡¤ë°±"""
        if backup_id not in self.metadata:
            logger.error(f"âŒ ë°±ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {backup_id}")
            return False
        
        backup_info = self.metadata[backup_id]
        backup_path = Path(backup_info['backup_path'])
        
        if not backup_path.exists():
            logger.error(f"âŒ ë°±ì—… ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {backup_path}")
            return False
        
        logger.info(f"ğŸ”„ ì›¹í›… ë¡¤ë°± ì‹œì‘: {backup_id}")
        
        try:
            # í˜„ì¬ ìƒíƒœë¥¼ ë¹„ìƒ ë°±ì—…ìœ¼ë¡œ ì €ì¥
            emergency_backup_id = self.create_backup(
                "emergency_before_rollback",
                f"ë¡¤ë°± ì „ ë¹„ìƒ ë°±ì—… (ë¡¤ë°± ëŒ€ìƒ: {backup_id})"
            )
            logger.info(f"ë¹„ìƒ ë°±ì—… ìƒì„± ì™„ë£Œ: {emergency_backup_id}")
            
            # ë°±ì—…ëœ íŒŒì¼ë“¤ì„ ì›ë˜ ìœ„ì¹˜ë¡œ ë³µì›
            restored_files = []
            failed_files = []
            
            for file_path in backup_info['backed_up_files']:
                try:
                    source_path = backup_path / file_path
                    dest_path = Path(file_path)
                    
                    if source_path.exists():
                        # ëŒ€ìƒ ë””ë ‰í† ë¦¬ ìƒì„±
                        dest_path.parent.mkdir(parents=True, exist_ok=True)
                        
                        # íŒŒì¼ ë³µì›
                        shutil.copy2(source_path, dest_path)
                        
                        # ì²´í¬ì„¬ ê²€ì¦ (ê°€ëŠ¥í•œ ê²½ìš°)
                        if file_path in backup_info.get('file_checksums', {}):
                            expected_checksum = backup_info['file_checksums'][file_path]
                            actual_checksum = self._calculate_file_checksum(dest_path)
                            
                            if expected_checksum and actual_checksum != expected_checksum:
                                logger.warning(f"ì²´í¬ì„¬ ë¶ˆì¼ì¹˜ {file_path}: ì˜ˆìƒ={expected_checksum[:8]}..., ì‹¤ì œ={actual_checksum[:8]}...")
                        
                        restored_files.append(file_path)
                        logger.debug(f"ë³µì› ì™„ë£Œ: {file_path}")
                    else:
                        logger.warning(f"ë°±ì—… íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {source_path}")
                        failed_files.append(file_path)
                        
                except Exception as e:
                    logger.error(f"íŒŒì¼ ë³µì› ì‹¤íŒ¨ {file_path}: {e}")
                    failed_files.append(file_path)
            
            # ë¡¤ë°± ê²°ê³¼ ê¸°ë¡
            rollback_info = {
                'rollback_id': f"rollback_{backup_id}_{int(time.time())}",
                'source_backup_id': backup_id,
                'emergency_backup_id': emergency_backup_id,
                'rollback_time': datetime.now().isoformat(),
                'restored_files': restored_files,
                'failed_files': failed_files,
                'success': len(failed_files) == 0
            }
            
            # ë¡¤ë°± ê¸°ë¡ì„ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
            if 'rollback_history' not in self.metadata:
                self.metadata['rollback_history'] = []
            self.metadata['rollback_history'].append(rollback_info)
            self.save_metadata()
            
            if rollback_info['success']:
                logger.info(f"âœ… ì›¹í›… ë¡¤ë°± ì™„ë£Œ: {backup_id}")
                logger.info(f"   ë³µì›ëœ íŒŒì¼ ìˆ˜: {len(restored_files)}ê°œ")
                return True
            else:
                logger.error(f"âŒ ì›¹í›… ë¡¤ë°± ë¶€ë¶„ ì‹¤íŒ¨: {len(failed_files)}ê°œ íŒŒì¼ ì‹¤íŒ¨")
                logger.error(f"   ì‹¤íŒ¨í•œ íŒŒì¼ë“¤: {failed_files}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ë¡¤ë°± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            logger.error(f"ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
            return False
    
    def auto_rollback_on_error(self, error_context: str) -> bool:
        """ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ ë¡¤ë°±"""
        if not self.auto_rollback_enabled:
            logger.info("ìë™ ë¡¤ë°±ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
            return False
        
        logger.warning(f"ğŸš¨ ì˜¤ë¥˜ ê°ì§€ë¡œ ì¸í•œ ìë™ ë¡¤ë°± ì‹œë„: {error_context}")
        
        # ê°€ì¥ ìµœê·¼ ë°±ì—… ì°¾ê¸°
        recent_backup = self.get_most_recent_backup()
        
        if not recent_backup:
            logger.error("âŒ ìë™ ë¡¤ë°±í•  ë°±ì—…ì´ ì—†ìŠµë‹ˆë‹¤")
            return False
        
        logger.info(f"ê°€ì¥ ìµœê·¼ ë°±ì—…ìœ¼ë¡œ ìë™ ë¡¤ë°± ì‹œë„: {recent_backup}")
        
        try:
            success = self.rollback_to_backup(recent_backup)
            
            if success:
                logger.info(f"âœ… ìë™ ë¡¤ë°± ì„±ê³µ: {recent_backup}")
                
                # ìë™ ë¡¤ë°± ê¸°ë¡
                auto_rollback_info = {
                    'auto_rollback_time': datetime.now().isoformat(),
                    'error_context': error_context,
                    'backup_used': recent_backup,
                    'success': True
                }
                
                if 'auto_rollback_history' not in self.metadata:
                    self.metadata['auto_rollback_history'] = []
                self.metadata['auto_rollback_history'].append(auto_rollback_info)
                self.save_metadata()
                
                return True
            else:
                logger.error(f"âŒ ìë™ ë¡¤ë°± ì‹¤íŒ¨: {recent_backup}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ìë™ ë¡¤ë°± ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def get_most_recent_backup(self) -> Optional[str]:
        """ê°€ì¥ ìµœê·¼ ë°±ì—… ID ë°˜í™˜"""
        if not self.metadata:
            return None
        
        # ë¹„ìƒ ë°±ì—…ì€ ì œì™¸í•˜ê³  ì¼ë°˜ ë°±ì—…ë§Œ ê³ ë ¤
        regular_backups = {
            backup_id: info for backup_id, info in self.metadata.items()
            if isinstance(info, dict) and 
            info.get('status') == 'completed' and
            'emergency' not in info.get('backup_name', '')
        }
        
        if not regular_backups:
            return None
        
        # ìƒì„± ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìµœê·¼ ê²ƒ ë°˜í™˜
        sorted_backups = sorted(
            regular_backups.items(),
            key=lambda x: x[1].get('created_at', ''),
            reverse=True
        )
        
        return sorted_backups[0][0] if sorted_backups else None
    
    def list_backups(self) -> List[Dict[str, Any]]:
        """ë°±ì—… ëª©ë¡ ì¡°íšŒ"""
        backups = []
        
        for backup_id, info in self.metadata.items():
            if isinstance(info, dict) and 'backup_name' in info:
                backups.append({
                    'backup_id': backup_id,
                    'backup_name': info.get('backup_name', ''),
                    'description': info.get('description', ''),
                    'created_at': info.get('created_at', ''),
                    'file_count': info.get('file_count', 0),
                    'total_size': info.get('total_size', 0),
                    'status': info.get('status', 'unknown')
                })
        
        # ìƒì„± ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬ (ìµœì‹  ìˆœ)
        backups.sort(key=lambda x: x['created_at'], reverse=True)
        return backups
    
    def verify_backup_integrity(self, backup_id: str) -> bool:
        """ë°±ì—… ë¬´ê²°ì„± ê²€ì¦"""
        if backup_id not in self.metadata:
            logger.error(f"ë°±ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {backup_id}")
            return False
        
        backup_info = self.metadata[backup_id]
        backup_path = Path(backup_info['backup_path'])
        
        if not backup_path.exists():
            logger.error(f"ë°±ì—… ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {backup_path}")
            return False
        
        logger.info(f"ğŸ” ë°±ì—… ë¬´ê²°ì„± ê²€ì¦ ì‹œì‘: {backup_id}")
        
        try:
            file_checksums = backup_info.get('file_checksums', {})
            verification_results = []
            
            for file_path in backup_info.get('backed_up_files', []):
                backup_file_path = backup_path / file_path
                
                if not backup_file_path.exists():
                    logger.error(f"ë°±ì—… íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {backup_file_path}")
                    verification_results.append(False)
                    continue
                
                # ì²´í¬ì„¬ ê²€ì¦ (ê°€ëŠ¥í•œ ê²½ìš°)
                if file_path in file_checksums:
                    expected_checksum = file_checksums[file_path]
                    actual_checksum = self._calculate_file_checksum(backup_file_path)
                    
                    if expected_checksum and actual_checksum != expected_checksum:
                        logger.error(f"ì²´í¬ì„¬ ë¶ˆì¼ì¹˜ {file_path}: ì˜ˆìƒ={expected_checksum[:8]}..., ì‹¤ì œ={actual_checksum[:8]}...")
                        verification_results.append(False)
                    else:
                        verification_results.append(True)
                else:
                    # ì²´í¬ì„¬ì´ ì—†ëŠ” ê²½ìš° íŒŒì¼ ì¡´ì¬ë§Œ í™•ì¸
                    verification_results.append(True)
            
            success = all(verification_results)
            
            if success:
                logger.info(f"âœ… ë°±ì—… ë¬´ê²°ì„± ê²€ì¦ í†µê³¼: {backup_id}")
            else:
                logger.error(f"âŒ ë°±ì—… ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨: {backup_id}")
            
            return success
            
        except Exception as e:
            logger.error(f"ë°±ì—… ë¬´ê²°ì„± ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def _cleanup_old_backups(self):
        """ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬"""
        try:
            backups = self.list_backups()
            
            if len(backups) <= self.max_backup_count:
                return
            
            # ì˜¤ë˜ëœ ë°±ì—…ë“¤ ì‚­ì œ (ë¹„ìƒ ë°±ì—…ì€ ì œì™¸)
            backups_to_delete = []
            regular_backups = [b for b in backups if 'emergency' not in b['backup_name']]
            
            if len(regular_backups) > self.max_backup_count:
                backups_to_delete = regular_backups[self.max_backup_count:]
            
            for backup in backups_to_delete:
                backup_id = backup['backup_id']
                backup_info = self.metadata[backup_id]
                backup_path = Path(backup_info['backup_path'])
                
                if backup_path.exists():
                    shutil.rmtree(backup_path)
                    logger.info(f"ì˜¤ë˜ëœ ë°±ì—… ì‚­ì œ: {backup_id}")
                
                del self.metadata[backup_id]
            
            if backups_to_delete:
                self.save_metadata()
                logger.info(f"ì´ {len(backups_to_delete)}ê°œì˜ ì˜¤ë˜ëœ ë°±ì—…ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤")
                
        except Exception as e:
            logger.warning(f"ë°±ì—… ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def get_backup_status(self) -> Dict[str, Any]:
        """ë°±ì—… ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        backups = self.list_backups()
        
        status = {
            'total_backups': len(backups),
            'successful_backups': len([b for b in backups if b['status'] == 'completed']),
            'failed_backups': len([b for b in backups if b['status'] == 'failed']),
            'total_size': sum(b['total_size'] for b in backups),
            'auto_rollback_enabled': self.auto_rollback_enabled,
            'max_backup_count': self.max_backup_count,
            'backup_root': str(self.backup_root),
            'most_recent_backup': self.get_most_recent_backup()
        }
        
        # ë¡¤ë°± íˆìŠ¤í† ë¦¬ ì •ë³´ ì¶”ê°€
        rollback_history = self.metadata.get('rollback_history', [])
        auto_rollback_history = self.metadata.get('auto_rollback_history', [])
        
        status['rollback_count'] = len(rollback_history)
        status['auto_rollback_count'] = len(auto_rollback_history)
        status['last_rollback'] = rollback_history[-1]['rollback_time'] if rollback_history else None
        status['last_auto_rollback'] = auto_rollback_history[-1]['auto_rollback_time'] if auto_rollback_history else None
        
        return status

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='POSCO ì›Œì¹˜í–„ìŠ¤í„° ì›¹í›… ë°±ì—… ê´€ë¦¬ì')
    parser.add_argument('--create', type=str, help='ë°±ì—… ìƒì„± (ë°±ì—… ì´ë¦„ ì§€ì •)')
    parser.add_argument('--description', type=str, default='', help='ë°±ì—… ì„¤ëª…')
    parser.add_argument('--list', action='store_true', help='ë°±ì—… ëª©ë¡ ì¡°íšŒ')
    parser.add_argument('--rollback', type=str, help='ì§€ì •ëœ ë°±ì—…ìœ¼ë¡œ ë¡¤ë°±')
    parser.add_argument('--verify', type=str, help='ë°±ì—… ë¬´ê²°ì„± ê²€ì¦')
    parser.add_argument('--status', action='store_true', help='ë°±ì—… ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ')
    parser.add_argument('--auto-rollback', type=str, help='ìë™ ë¡¤ë°± í…ŒìŠ¤íŠ¸ (ì˜¤ë¥˜ ì»¨í…ìŠ¤íŠ¸ ì§€ì •)')
    
    args = parser.parse_args()
    
    backup_manager = WebhookBackupManager()
    
    try:
        if args.create:
            backup_id = backup_manager.create_backup(args.create, args.description)
            print(f"âœ… ë°±ì—… ìƒì„± ì™„ë£Œ: {backup_id}")
            
        elif args.list:
            backups = backup_manager.list_backups()
            print("\nğŸ“‹ ì›¹í›… ë°±ì—… ëª©ë¡:")
            print("-" * 100)
            for backup in backups:
                print(f"ID: {backup['backup_id']}")
                print(f"ì´ë¦„: {backup['backup_name']}")
                print(f"ì„¤ëª…: {backup['description']}")
                print(f"ìƒì„±ì¼: {backup['created_at']}")
                print(f"íŒŒì¼ ìˆ˜: {backup['file_count']:,}ê°œ")
                print(f"í¬ê¸°: {backup['total_size'] / 1024:.1f}KB")
                print(f"ìƒíƒœ: {backup['status']}")
                print("-" * 100)
                
        elif args.rollback:
            success = backup_manager.rollback_to_backup(args.rollback)
            if success:
                print(f"âœ… ë¡¤ë°± ì™„ë£Œ: {args.rollback}")
            else:
                print(f"âŒ ë¡¤ë°± ì‹¤íŒ¨: {args.rollback}")
                
        elif args.verify:
            is_valid = backup_manager.verify_backup_integrity(args.verify)
            if is_valid:
                print(f"âœ… ë°±ì—… ë¬´ê²°ì„± ê²€ì¦ í†µê³¼: {args.verify}")
            else:
                print(f"âŒ ë°±ì—… ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨: {args.verify}")
                
        elif args.status:
            status = backup_manager.get_backup_status()
            print("\nğŸ“Š ì›¹í›… ë°±ì—… ì‹œìŠ¤í…œ ìƒíƒœ:")
            print("-" * 50)
            print(f"ì´ ë°±ì—… ìˆ˜: {status['total_backups']}ê°œ")
            print(f"ì„±ê³µí•œ ë°±ì—…: {status['successful_backups']}ê°œ")
            print(f"ì‹¤íŒ¨í•œ ë°±ì—…: {status['failed_backups']}ê°œ")
            print(f"ì´ í¬ê¸°: {status['total_size'] / 1024:.1f}KB")
            print(f"ìë™ ë¡¤ë°±: {'í™œì„±í™”' if status['auto_rollback_enabled'] else 'ë¹„í™œì„±í™”'}")
            print(f"ìµœëŒ€ ë°±ì—… ìˆ˜: {status['max_backup_count']}ê°œ")
            print(f"ë°±ì—… ë””ë ‰í† ë¦¬: {status['backup_root']}")
            print(f"ìµœê·¼ ë°±ì—…: {status['most_recent_backup'] or 'ì—†ìŒ'}")
            print(f"ë¡¤ë°± íšŸìˆ˜: {status['rollback_count']}íšŒ")
            print(f"ìë™ ë¡¤ë°± íšŸìˆ˜: {status['auto_rollback_count']}íšŒ")
            
        elif args.auto_rollback:
            success = backup_manager.auto_rollback_on_error(args.auto_rollback)
            if success:
                print(f"âœ… ìë™ ë¡¤ë°± ì„±ê³µ: {args.auto_rollback}")
            else:
                print(f"âŒ ìë™ ë¡¤ë°± ì‹¤íŒ¨: {args.auto_rollback}")
                
        else:
            parser.print_help()
            
    except Exception as e:
        logger.error(f"âŒ ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()