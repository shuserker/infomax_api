#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
POSCO ì‹œìŠ¤í…œ ìµœì¢… ì•ˆì •ì„± ê²€ì¦ í…ŒìŠ¤íŠ¸
ì •ìƒ ì»¤ë°‹ a763ef84 ê¸°ì¤€ ì™„ì „ ë³µêµ¬ ì‹œìŠ¤í…œì˜ ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ì„ ì¢…í•© ê²€ì¦
"""

import os
import sys
import time
import json
import psutil
import threading
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import logging

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆ import ê°€ëŠ¥í•˜ê²Œ í•¨
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('recovery_config/stability_test.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SystemStabilityTester:
    """ì‹œìŠ¤í…œ ì•ˆì •ì„± ì¢…í•© ê²€ì¦ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.test_results = {
            'start_time': datetime.now().isoformat(),
            'tests': {},
            'performance_metrics': {},
            'stability_score': 0,
            'recommendations': []
        }
        self.base_path = os.path.dirname(os.path.abspath(__file__))
        
    def run_comprehensive_stability_test(self) -> Dict[str, Any]:
        """ì¢…í•© ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸ” POSCO ì‹œìŠ¤í…œ ìµœì¢… ì•ˆì •ì„± ê²€ì¦ ì‹œì‘")
        
        # 1. ì‹œìŠ¤í…œ ì„±ëŠ¥ ê¸°ì¤€ì„  ì¸¡ì •
        self._measure_baseline_performance()
        
        # 2. ê¸°ëŠ¥ ì™„ì„±ë„ ê²€ì¦
        self._verify_feature_completeness()
        
        # 3. ì˜¤ë¥˜ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜ ê²€ì¦
        self._verify_error_handling()
        
        # 4. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ê²€ì¦
        self._verify_monitoring_system()
        
        # 5. ë¶€í•˜ í…ŒìŠ¤íŠ¸
        self._run_load_test()
        
        # 6. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê²€ì¦
        self._verify_memory_stability()
        
        # 7. ì¥ê¸° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
        self._run_long_term_stability_test()
        
        # 8. ìµœì¢… ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚°
        self._calculate_stability_score()
        
        # 9. ê²°ê³¼ ì €ì¥
        self._save_results()
        
        return self.test_results
    
    def _measure_baseline_performance(self):
        """ì‹œìŠ¤í…œ ì„±ëŠ¥ ê¸°ì¤€ì„  ì¸¡ì •"""
        logger.info("ğŸ“Š ì‹œìŠ¤í…œ ì„±ëŠ¥ ê¸°ì¤€ì„  ì¸¡ì • ì¤‘...")
        
        try:
            # CPU ì‚¬ìš©ë¥  ì¸¡ì •
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¸¡ì •
            memory = psutil.virtual_memory()
            
            # ë””ìŠ¤í¬ ì‚¬ìš©ë¥  ì¸¡ì •
            disk = psutil.disk_usage('/')
            
            # ë„¤íŠ¸ì›Œí¬ ìƒíƒœ ì¸¡ì •
            network = psutil.net_io_counters()
            
            performance_data = {
                'cpu_usage_percent': cpu_percent,
                'memory_usage_percent': memory.percent,
                'memory_available_gb': memory.available / (1024**3),
                'disk_usage_percent': (disk.used / disk.total) * 100,
                'disk_free_gb': disk.free / (1024**3),
                'network_bytes_sent': network.bytes_sent,
                'network_bytes_recv': network.bytes_recv
            }
            
            self.test_results['performance_metrics']['baseline'] = performance_data
            self.test_results['tests']['baseline_performance'] = {
                'status': 'PASS',
                'message': 'ì‹œìŠ¤í…œ ì„±ëŠ¥ ê¸°ì¤€ì„  ì¸¡ì • ì™„ë£Œ',
                'details': performance_data
            }
            
            logger.info(f"âœ… ì„±ëŠ¥ ê¸°ì¤€ì„  ì¸¡ì • ì™„ë£Œ: CPU {cpu_percent}%, ë©”ëª¨ë¦¬ {memory.percent}%")
            
        except Exception as e:
            self.test_results['tests']['baseline_performance'] = {
                'status': 'FAIL',
                'message': f'ì„±ëŠ¥ ê¸°ì¤€ì„  ì¸¡ì • ì‹¤íŒ¨: {str(e)}'
            }
            logger.error(f"âŒ ì„±ëŠ¥ ê¸°ì¤€ì„  ì¸¡ì • ì‹¤íŒ¨: {e}")
    
    def _verify_feature_completeness(self):
        """ê¸°ëŠ¥ ì™„ì„±ë„ ê²€ì¦"""
        logger.info("ğŸ”§ ê¸°ëŠ¥ ì™„ì„±ë„ ê²€ì¦ ì¤‘...")
        
        try:
            # í•µì‹¬ ëª¨ë“ˆë“¤ import í…ŒìŠ¤íŠ¸
            core_modules = [
                'environment_setup',
                'integrated_api_module',
                'integrated_news_parser',
                'news_message_generator',
                'webhook_sender',
                'watchhamster_monitor',
                'ai_analysis_engine',
                'business_day_comparison_engine'
            ]
            
            import_results = {}
            for module in core_modules:
                try:
                    # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì§ì ‘ import
                    import sys
                    import os
                    current_dir = os.path.dirname(os.path.abspath(__file__))
                    if current_dir not in sys.path:
                        sys.path.insert(0, current_dir)
                    
                    __import__(module)
                    import_results[module] = 'SUCCESS'
                except Exception as e:
                    import_results[module] = f'FAIL: {str(e)}'
            
            # ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            feature_tests = self._run_feature_tests()
            
            success_count = sum(1 for result in import_results.values() if result == 'SUCCESS')
            total_count = len(import_results)
            completeness_score = (success_count / total_count) * 100
            
            self.test_results['tests']['feature_completeness'] = {
                'status': 'PASS' if completeness_score >= 90 else 'FAIL',
                'message': f'ê¸°ëŠ¥ ì™„ì„±ë„: {completeness_score:.1f}% ({success_count}/{total_count})',
                'details': {
                    'module_imports': import_results,
                    'feature_tests': feature_tests,
                    'completeness_score': completeness_score
                }
            }
            
            logger.info(f"âœ… ê¸°ëŠ¥ ì™„ì„±ë„ ê²€ì¦ ì™„ë£Œ: {completeness_score:.1f}%")
            
        except Exception as e:
            self.test_results['tests']['feature_completeness'] = {
                'status': 'FAIL',
                'message': f'ê¸°ëŠ¥ ì™„ì„±ë„ ê²€ì¦ ì‹¤íŒ¨: {str(e)}'
            }
            logger.error(f"âŒ ê¸°ëŠ¥ ì™„ì„±ë„ ê²€ì¦ ì‹¤íŒ¨: {e}")
    
    def _run_feature_tests(self) -> Dict[str, str]:
        """ê°œë³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        feature_tests = {}
        
        try:
            # í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
            import sys
            import os
            current_dir = os.path.dirname(os.path.abspath(__file__))
            if current_dir not in sys.path:
                sys.path.insert(0, current_dir)
            
            # API ì—°ë™ í…ŒìŠ¤íŠ¸
            from integrated_api_module import IntegratedAPIModule
            api_module = IntegratedAPIModule()
            test_data = api_module.create_test_data()
            feature_tests['api_integration'] = 'SUCCESS' if test_data else 'FAIL'
            
            # ë©”ì‹œì§€ ìƒì„± í…ŒìŠ¤íŠ¸
            from news_message_generator import NewsMessageGenerator
            msg_generator = NewsMessageGenerator()
            test_message = msg_generator.generate_comprehensive_message(test_data)
            feature_tests['message_generation'] = 'SUCCESS' if test_message else 'FAIL'
            
            # ì›¹í›… í…ŒìŠ¤íŠ¸
            from webhook_sender import WebhookSender
            webhook = WebhookSender()
            webhook_result = webhook.validate_message_format(test_message)
            feature_tests['webhook_validation'] = 'SUCCESS' if webhook_result else 'FAIL'
            
        except Exception as e:
            feature_tests['error'] = str(e)
        
        return feature_tests
    
    def _verify_error_handling(self):
        """ì˜¤ë¥˜ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜ ê²€ì¦"""
        logger.info("ğŸ›¡ï¸ ì˜¤ë¥˜ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜ ê²€ì¦ ì¤‘...")
        
        try:
            error_scenarios = []
            
            # 1. API ì—°ê²° ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤
            error_scenarios.append(self._test_api_connection_failure())
            
            # 2. ì˜ëª»ëœ ë°ì´í„° ì²˜ë¦¬ ì‹œë‚˜ë¦¬ì˜¤
            error_scenarios.append(self._test_invalid_data_handling())
            
            # 3. ì›¹í›… ì „ì†¡ ì‹¤íŒ¨ ì‹œë‚˜ë¦¬ì˜¤
            error_scenarios.append(self._test_webhook_failure())
            
            # 4. ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œë‚˜ë¦¬ì˜¤
            error_scenarios.append(self._test_memory_pressure())
            
            passed_scenarios = sum(1 for scenario in error_scenarios if scenario['status'] == 'PASS')
            total_scenarios = len(error_scenarios)
            
            self.test_results['tests']['error_handling'] = {
                'status': 'PASS' if passed_scenarios >= total_scenarios * 0.8 else 'FAIL',
                'message': f'ì˜¤ë¥˜ ì²˜ë¦¬ ê²€ì¦: {passed_scenarios}/{total_scenarios} ì‹œë‚˜ë¦¬ì˜¤ í†µê³¼',
                'details': {
                    'scenarios': error_scenarios,
                    'pass_rate': (passed_scenarios / total_scenarios) * 100
                }
            }
            
            logger.info(f"âœ… ì˜¤ë¥˜ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜ ê²€ì¦ ì™„ë£Œ: {passed_scenarios}/{total_scenarios}")
            
        except Exception as e:
            self.test_results['tests']['error_handling'] = {
                'status': 'FAIL',
                'message': f'ì˜¤ë¥˜ ì²˜ë¦¬ ê²€ì¦ ì‹¤íŒ¨: {str(e)}'
            }
            logger.error(f"âŒ ì˜¤ë¥˜ ì²˜ë¦¬ ê²€ì¦ ì‹¤íŒ¨: {e}")
    
    def _test_api_connection_failure(self) -> Dict[str, Any]:
        """API ì—°ê²° ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸"""
        try:
            import sys
            import os
            current_dir = os.path.dirname(os.path.abspath(__file__))
            if current_dir not in sys.path:
                sys.path.insert(0, current_dir)
            
            from integrated_api_module import IntegratedAPIModule
            api_module = IntegratedAPIModule()
            
            # ì˜ëª»ëœ URLë¡œ í…ŒìŠ¤íŠ¸
            original_url = getattr(api_module, 'base_url', None)
            api_module.base_url = 'http://invalid-url-test.com'
            
            # ì—°ê²° ì‹¤íŒ¨ ì²˜ë¦¬ í™•ì¸
            result = api_module.handle_connection_error()
            
            # ì›ë˜ URL ë³µì›
            if original_url:
                api_module.base_url = original_url
            
            return {
                'name': 'API ì—°ê²° ì‹¤íŒ¨ ì²˜ë¦¬',
                'status': 'PASS' if result else 'FAIL',
                'details': 'API ì—°ê²° ì‹¤íŒ¨ ì‹œ ì ì ˆí•œ ì˜¤ë¥˜ ì²˜ë¦¬ í™•ì¸'
            }
        except Exception as e:
            return {
                'name': 'API ì—°ê²° ì‹¤íŒ¨ ì²˜ë¦¬',
                'status': 'FAIL',
                'details': f'í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}'
            }
    
    def _test_invalid_data_handling(self) -> Dict[str, Any]:
        """ì˜ëª»ëœ ë°ì´í„° ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        try:
            from integrated_news_parser import IntegratedNewsParser
            parser = IntegratedNewsParser()
            
            # ì˜ëª»ëœ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
            invalid_data = {'invalid': 'data', 'structure': None}
            result = parser.parse_news_data(invalid_data)
            
            return {
                'name': 'ì˜ëª»ëœ ë°ì´í„° ì²˜ë¦¬',
                'status': 'PASS' if result is not None else 'FAIL',
                'details': 'ì˜ëª»ëœ ë°ì´í„° ì…ë ¥ ì‹œ ì•ˆì „í•œ ì²˜ë¦¬ í™•ì¸'
            }
        except Exception as e:
            return {
                'name': 'ì˜ëª»ëœ ë°ì´í„° ì²˜ë¦¬',
                'status': 'PASS',  # ì˜ˆì™¸ ë°œìƒë„ ì ì ˆí•œ ì²˜ë¦¬ë¡œ ê°„ì£¼
                'details': f'ì˜ˆì™¸ ì²˜ë¦¬ í™•ì¸: {str(e)}'
            }
    
    def _test_webhook_failure(self) -> Dict[str, Any]:
        """ì›¹í›… ì „ì†¡ ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸"""
        try:
            from webhook_sender import WebhookSender
            webhook = WebhookSender()
            
            # ì˜ëª»ëœ ì›¹í›… URLë¡œ í…ŒìŠ¤íŠ¸
            result = webhook.send_webhook("í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€", "http://invalid-webhook-url.com")
            
            return {
                'name': 'ì›¹í›… ì „ì†¡ ì‹¤íŒ¨ ì²˜ë¦¬',
                'status': 'PASS' if not result else 'FAIL',  # ì‹¤íŒ¨ê°€ ì˜ˆìƒë˜ëŠ” ìƒí™©
                'details': 'ì˜ëª»ëœ ì›¹í›… URL ì²˜ë¦¬ í™•ì¸'
            }
        except Exception as e:
            return {
                'name': 'ì›¹í›… ì „ì†¡ ì‹¤íŒ¨ ì²˜ë¦¬',
                'status': 'PASS',  # ì˜ˆì™¸ ë°œìƒë„ ì ì ˆí•œ ì²˜ë¦¬ë¡œ ê°„ì£¼
                'details': f'ì˜ˆì™¸ ì²˜ë¦¬ í™•ì¸: {str(e)}'
            }
    
    def _test_memory_pressure(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì••ë°• ìƒí™© í…ŒìŠ¤íŠ¸"""
        try:
            # í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
            memory_before = psutil.virtual_memory().percent
            
            # ëŒ€ìš©ëŸ‰ ë°ì´í„° ìƒì„± ë° ì²˜ë¦¬
            large_data = ['test' * 1000] * 1000
            processed_data = [item.upper() for item in large_data]
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del large_data
            del processed_data
            
            memory_after = psutil.virtual_memory().percent
            memory_increase = memory_after - memory_before
            
            return {
                'name': 'ë©”ëª¨ë¦¬ ì••ë°• ìƒí™© ì²˜ë¦¬',
                'status': 'PASS' if memory_increase < 10 else 'FAIL',
                'details': f'ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰: {memory_increase:.1f}%'
            }
        except Exception as e:
            return {
                'name': 'ë©”ëª¨ë¦¬ ì••ë°• ìƒí™© ì²˜ë¦¬',
                'status': 'FAIL',
                'details': f'í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}'
            }
    
    def _verify_monitoring_system(self):
        """ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ê²€ì¦"""
        logger.info("ğŸ“¡ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ê²€ì¦ ì¤‘...")
        
        try:
            monitoring_results = {}
            
            # Git ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸
            try:
                from git_monitor import GitMonitor
                git_monitor = GitMonitor()
                git_status = git_monitor.check_git_status()
                monitoring_results['git_monitor'] = 'SUCCESS' if git_status else 'FAIL'
            except Exception as e:
                monitoring_results['git_monitor'] = f'FAIL: {str(e)}'
            
            # ì›Œì¹˜í–„ìŠ¤í„° ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸
            try:
                from watchhamster_monitor import WatchHamsterMonitor
                wh_monitor = WatchHamsterMonitor()
                wh_status = wh_monitor.check_system_status()
                monitoring_results['watchhamster_monitor'] = 'SUCCESS' if wh_status else 'FAIL'
            except Exception as e:
                monitoring_results['watchhamster_monitor'] = f'FAIL: {str(e)}'
            
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
            resource_monitoring = self._test_resource_monitoring()
            monitoring_results['resource_monitoring'] = resource_monitoring
            
            success_count = sum(1 for result in monitoring_results.values() 
                              if isinstance(result, str) and result == 'SUCCESS')
            total_count = len([r for r in monitoring_results.values() if isinstance(r, str)])
            
            self.test_results['tests']['monitoring_system'] = {
                'status': 'PASS' if success_count >= total_count * 0.8 else 'FAIL',
                'message': f'ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ: {success_count}/{total_count} í†µê³¼',
                'details': monitoring_results
            }
            
            logger.info(f"âœ… ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ê²€ì¦ ì™„ë£Œ: {success_count}/{total_count}")
            
        except Exception as e:
            self.test_results['tests']['monitoring_system'] = {
                'status': 'FAIL',
                'message': f'ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê²€ì¦ ì‹¤íŒ¨: {str(e)}'
            }
            logger.error(f"âŒ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ê²€ì¦ ì‹¤íŒ¨: {e}")
    
    def _test_resource_monitoring(self) -> str:
        """ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸"""
        try:
            # CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬ ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§
            cpu_usage = psutil.cpu_percent(interval=0.1)
            memory_usage = psutil.virtual_memory().percent
            disk_usage = psutil.disk_usage('/').percent
            
            # ì„ê³„ê°’ í™•ì¸
            if cpu_usage > 90 or memory_usage > 90 or disk_usage > 90:
                return 'WARNING: ë†’ì€ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥  ê°ì§€'
            
            return 'SUCCESS'
        except Exception as e:
            return f'FAIL: {str(e)}'
    
    def _run_load_test(self):
        """ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("âš¡ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        try:
            load_test_results = {}
            
            # ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            concurrent_results = self._test_concurrent_processing()
            load_test_results['concurrent_processing'] = concurrent_results
            
            # ì—°ì† ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            continuous_results = self._test_continuous_processing()
            load_test_results['continuous_processing'] = continuous_results
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
            memory_results = self._monitor_memory_during_load()
            load_test_results['memory_monitoring'] = memory_results
            
            # ì „ì²´ ë¶€í•˜ í…ŒìŠ¤íŠ¸ í‰ê°€
            overall_status = 'PASS'
            for result in load_test_results.values():
                if isinstance(result, dict) and result.get('status') == 'FAIL':
                    overall_status = 'FAIL'
                    break
            
            self.test_results['tests']['load_test'] = {
                'status': overall_status,
                'message': 'ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ',
                'details': load_test_results
            }
            
            logger.info(f"âœ… ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {overall_status}")
            
        except Exception as e:
            self.test_results['tests']['load_test'] = {
                'status': 'FAIL',
                'message': f'ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}'
            }
            logger.error(f"âŒ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _test_concurrent_processing(self) -> Dict[str, Any]:
        """ë™ì‹œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        try:
            from integrated_api_module import IntegratedAPIModule
            
            def process_data():
                api_module = IntegratedAPIModule()
                return api_module.create_test_data()
            
            # 10ê°œ ìŠ¤ë ˆë“œë¡œ ë™ì‹œ ì²˜ë¦¬
            threads = []
            results = []
            
            start_time = time.time()
            
            for i in range(10):
                thread = threading.Thread(target=lambda: results.append(process_data()))
                threads.append(thread)
                thread.start()
            
            for thread in threads:
                thread.join()
            
            end_time = time.time()
            processing_time = end_time - start_time
            
            success_count = sum(1 for result in results if result is not None)
            
            return {
                'status': 'PASS' if success_count >= 8 else 'FAIL',
                'processing_time': processing_time,
                'success_rate': (success_count / 10) * 100,
                'details': f'{success_count}/10 ì„±ê³µ, {processing_time:.2f}ì´ˆ'
            }
            
        except Exception as e:
            return {
                'status': 'FAIL',
                'details': f'ë™ì‹œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}'
            }
    
    def _test_continuous_processing(self) -> Dict[str, Any]:
        """ì—°ì† ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        try:
            from news_message_generator import NewsMessageGenerator
            from integrated_api_module import IntegratedAPIModule
            
            api_module = IntegratedAPIModule()
            msg_generator = NewsMessageGenerator()
            
            success_count = 0
            total_time = 0
            
            # 100íšŒ ì—°ì† ì²˜ë¦¬
            for i in range(100):
                start_time = time.time()
                
                test_data = api_module.create_test_data()
                message = msg_generator.generate_comprehensive_message(test_data)
                
                end_time = time.time()
                total_time += (end_time - start_time)
                
                if message:
                    success_count += 1
            
            avg_processing_time = total_time / 100
            success_rate = (success_count / 100) * 100
            
            return {
                'status': 'PASS' if success_rate >= 95 else 'FAIL',
                'success_rate': success_rate,
                'avg_processing_time': avg_processing_time,
                'details': f'{success_count}/100 ì„±ê³µ, í‰ê·  {avg_processing_time:.3f}ì´ˆ'
            }
            
        except Exception as e:
            return {
                'status': 'FAIL',
                'details': f'ì—°ì† ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}'
            }
    
    def _monitor_memory_during_load(self) -> Dict[str, Any]:
        """ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì¤‘ ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§"""
        try:
            memory_samples = []
            
            # 10ì´ˆê°„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
            for i in range(10):
                memory_percent = psutil.virtual_memory().percent
                memory_samples.append(memory_percent)
                time.sleep(1)
            
            avg_memory = sum(memory_samples) / len(memory_samples)
            max_memory = max(memory_samples)
            min_memory = min(memory_samples)
            
            return {
                'status': 'PASS' if max_memory < 80 else 'FAIL',
                'avg_memory_usage': avg_memory,
                'max_memory_usage': max_memory,
                'min_memory_usage': min_memory,
                'details': f'í‰ê·  {avg_memory:.1f}%, ìµœëŒ€ {max_memory:.1f}%'
            }
            
        except Exception as e:
            return {
                'status': 'FAIL',
                'details': f'ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {str(e)}'
            }
    
    def _verify_memory_stability(self):
        """ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê²€ì¦"""
        logger.info("ğŸ§  ë©”ëª¨ë¦¬ ì•ˆì •ì„± ê²€ì¦ ì¤‘...")
        
        try:
            # ì´ˆê¸° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            initial_memory = psutil.virtual_memory().percent
            
            # ë°˜ë³µ ì‘ì—… ìˆ˜í–‰
            from integrated_api_module import IntegratedAPIModule
            from news_message_generator import NewsMessageGenerator
            
            api_module = IntegratedAPIModule()
            msg_generator = NewsMessageGenerator()
            
            memory_samples = [initial_memory]
            
            # 50íšŒ ë°˜ë³µ ì²˜ë¦¬
            for i in range(50):
                test_data = api_module.create_test_data()
                message = msg_generator.generate_comprehensive_message(test_data)
                
                # ë§¤ 10íšŒë§ˆë‹¤ ë©”ëª¨ë¦¬ í™•ì¸
                if i % 10 == 0:
                    current_memory = psutil.virtual_memory().percent
                    memory_samples.append(current_memory)
            
            # ìµœì¢… ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            final_memory = psutil.virtual_memory().percent
            memory_increase = final_memory - initial_memory
            
            # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ íŒì • (5% ì´ìƒ ì¦ê°€ ì‹œ ëˆ„ìˆ˜ ì˜ì‹¬)
            has_memory_leak = memory_increase > 5
            
            self.test_results['tests']['memory_stability'] = {
                'status': 'FAIL' if has_memory_leak else 'PASS',
                'message': f'ë©”ëª¨ë¦¬ ì•ˆì •ì„±: {memory_increase:.1f}% ì¦ê°€',
                'details': {
                    'initial_memory': initial_memory,
                    'final_memory': final_memory,
                    'memory_increase': memory_increase,
                    'memory_samples': memory_samples,
                    'has_memory_leak': has_memory_leak
                }
            }
            
            logger.info(f"âœ… ë©”ëª¨ë¦¬ ì•ˆì •ì„± ê²€ì¦ ì™„ë£Œ: {memory_increase:.1f}% ì¦ê°€")
            
        except Exception as e:
            self.test_results['tests']['memory_stability'] = {
                'status': 'FAIL',
                'message': f'ë©”ëª¨ë¦¬ ì•ˆì •ì„± ê²€ì¦ ì‹¤íŒ¨: {str(e)}'
            }
            logger.error(f"âŒ ë©”ëª¨ë¦¬ ì•ˆì •ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
    
    def _run_long_term_stability_test(self):
        """ì¥ê¸° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (ë‹¨ì¶• ë²„ì „)"""
        logger.info("â° ì¥ê¸° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        
        try:
            # 5ë¶„ê°„ ì§€ì†ì ì¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            test_duration = 300  # 5ë¶„
            start_time = time.time()
            
            success_count = 0
            error_count = 0
            
            from integrated_api_module import IntegratedAPIModule
            api_module = IntegratedAPIModule()
            
            while time.time() - start_time < test_duration:
                try:
                    test_data = api_module.create_test_data()
                    if test_data:
                        success_count += 1
                    else:
                        error_count += 1
                except Exception:
                    error_count += 1
                
                time.sleep(10)  # 10ì´ˆ ê°„ê²©
            
            total_operations = success_count + error_count
            success_rate = (success_count / total_operations * 100) if total_operations > 0 else 0
            
            self.test_results['tests']['long_term_stability'] = {
                'status': 'PASS' if success_rate >= 90 else 'FAIL',
                'message': f'ì¥ê¸° ì•ˆì •ì„±: {success_rate:.1f}% ì„±ê³µë¥ ',
                'details': {
                    'test_duration_minutes': test_duration / 60,
                    'total_operations': total_operations,
                    'success_count': success_count,
                    'error_count': error_count,
                    'success_rate': success_rate
                }
            }
            
            logger.info(f"âœ… ì¥ê¸° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {success_rate:.1f}% ì„±ê³µë¥ ")
            
        except Exception as e:
            self.test_results['tests']['long_term_stability'] = {
                'status': 'FAIL',
                'message': f'ì¥ê¸° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}'
            }
            logger.error(f"âŒ ì¥ê¸° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _calculate_stability_score(self):
        """ìµœì¢… ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚°"""
        logger.info("ğŸ“Š ìµœì¢… ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚° ì¤‘...")
        
        try:
            # ê° í…ŒìŠ¤íŠ¸ë³„ ê°€ì¤‘ì¹˜
            weights = {
                'baseline_performance': 10,
                'feature_completeness': 25,
                'error_handling': 20,
                'monitoring_system': 15,
                'load_test': 15,
                'memory_stability': 10,
                'long_term_stability': 5
            }
            
            total_score = 0
            max_possible_score = 0
            
            for test_name, weight in weights.items():
                max_possible_score += weight
                
                if test_name in self.test_results['tests']:
                    test_result = self.test_results['tests'][test_name]
                    if test_result['status'] == 'PASS':
                        total_score += weight
                    elif test_result['status'] == 'PARTIAL':
                        total_score += weight * 0.5
            
            stability_score = (total_score / max_possible_score) * 100
            
            # ì•ˆì •ì„± ë“±ê¸‰ ê²°ì •
            if stability_score >= 95:
                grade = 'A+ (ìµœìš°ìˆ˜)'
            elif stability_score >= 90:
                grade = 'A (ìš°ìˆ˜)'
            elif stability_score >= 80:
                grade = 'B (ì–‘í˜¸)'
            elif stability_score >= 70:
                grade = 'C (ë³´í†µ)'
            else:
                grade = 'D (ê°œì„  í•„ìš”)'
            
            self.test_results['stability_score'] = stability_score
            self.test_results['stability_grade'] = grade
            
            # ê¶Œì¥ì‚¬í•­ ìƒì„±
            self._generate_recommendations()
            
            logger.info(f"âœ… ìµœì¢… ì•ˆì •ì„± ì ìˆ˜: {stability_score:.1f}ì  ({grade})")
            
        except Exception as e:
            logger.error(f"âŒ ì•ˆì •ì„± ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            self.test_results['stability_score'] = 0
            self.test_results['stability_grade'] = 'ERROR'
    
    def _generate_recommendations(self):
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ì— ëŒ€í•œ ê¶Œì¥ì‚¬í•­
        for test_name, test_result in self.test_results['tests'].items():
            if test_result['status'] == 'FAIL':
                if test_name == 'feature_completeness':
                    recommendations.append("ì¼ë¶€ ëª¨ë“ˆì˜ import ì˜¤ë¥˜ë¥¼ í•´ê²°í•˜ì—¬ ê¸°ëŠ¥ ì™„ì„±ë„ë¥¼ í–¥ìƒì‹œí‚¤ì„¸ìš”.")
                elif test_name == 'error_handling':
                    recommendations.append("ì˜¤ë¥˜ ì²˜ë¦¬ ë©”ì»¤ë‹ˆì¦˜ì„ ê°•í™”í•˜ì—¬ ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ ê°œì„ í•˜ì„¸ìš”.")
                elif test_name == 'memory_stability':
                    recommendations.append("ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ ì ê²€í•˜ê³  ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìµœì í™”í•˜ì„¸ìš”.")
                elif test_name == 'load_test':
                    recommendations.append("ë¶€í•˜ ì²˜ë¦¬ ì„±ëŠ¥ì„ ê°œì„ í•˜ì—¬ ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ì„¸ìš”.")
        
        # ì„±ëŠ¥ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if 'performance_metrics' in self.test_results:
            baseline = self.test_results['performance_metrics'].get('baseline', {})
            
            if baseline.get('cpu_usage_percent', 0) > 80:
                recommendations.append("CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
            
            if baseline.get('memory_usage_percent', 0) > 80:
                recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")
            
            if baseline.get('disk_usage_percent', 0) > 90:
                recommendations.append("ë””ìŠ¤í¬ ê³µê°„ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ íŒŒì¼ì„ ì •ë¦¬í•˜ì„¸ìš”.")
        
        # ì¼ë°˜ì ì¸ ê¶Œì¥ì‚¬í•­
        if self.test_results['stability_score'] < 90:
            recommendations.append("ì •ê¸°ì ì¸ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ê³¼ ìœ ì§€ë³´ìˆ˜ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.")
            recommendations.append("ë¡œê·¸ íŒŒì¼ì„ ì •ê¸°ì ìœ¼ë¡œ ê²€í† í•˜ì—¬ ì ì¬ì  ë¬¸ì œë¥¼ ì¡°ê¸°ì— ë°œê²¬í•˜ì„¸ìš”.")
        
        if not recommendations:
            recommendations.append("ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•˜ì„¸ìš”.")
        
        self.test_results['recommendations'] = recommendations
    
    def _save_results(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        try:
            self.test_results['end_time'] = datetime.now().isoformat()
            
            # JSON ê²°ê³¼ ì €ì¥
            result_file = f'recovery_config/final_stability_test_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(self.test_results, f, ensure_ascii=False, indent=2)
            
            # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
            self._generate_markdown_report()
            
            logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {result_file}")
            
        except Exception as e:
            logger.error(f"âŒ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _generate_markdown_report(self):
        """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            report_content = f"""# ğŸ† POSCO ì‹œìŠ¤í…œ ìµœì¢… ì•ˆì •ì„± ê²€ì¦ ë¦¬í¬íŠ¸

## ğŸ“Š ì¢…í•© ê²°ê³¼

**ìµœì¢… ì•ˆì •ì„± ì ìˆ˜**: {self.test_results.get('stability_score', 0):.1f}ì   
**ì•ˆì •ì„± ë“±ê¸‰**: {self.test_results.get('stability_grade', 'N/A')}  
**í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œê°„**: {self.test_results.get('start_time', '')} ~ {self.test_results.get('end_time', '')}

## ğŸ” ì„¸ë¶€ í…ŒìŠ¤íŠ¸ ê²°ê³¼

"""
            
            for test_name, test_result in self.test_results.get('tests', {}).items():
                status_emoji = 'âœ…' if test_result['status'] == 'PASS' else 'âŒ'
                report_content += f"### {status_emoji} {test_name.replace('_', ' ').title()}\n"
                report_content += f"- **ìƒíƒœ**: {test_result['status']}\n"
                report_content += f"- **ë©”ì‹œì§€**: {test_result['message']}\n"
                
                if 'details' in test_result:
                    report_content += f"- **ì„¸ë¶€ì‚¬í•­**: {test_result['details']}\n"
                
                report_content += "\n"
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­
            if 'performance_metrics' in self.test_results:
                report_content += "## ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­\n\n"
                baseline = self.test_results['performance_metrics'].get('baseline', {})
                
                for metric, value in baseline.items():
                    if isinstance(value, float):
                        report_content += f"- **{metric}**: {value:.2f}\n"
                    else:
                        report_content += f"- **{metric}**: {value}\n"
                
                report_content += "\n"
            
            # ê¶Œì¥ì‚¬í•­
            if 'recommendations' in self.test_results:
                report_content += "## ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­\n\n"
                for i, recommendation in enumerate(self.test_results['recommendations'], 1):
                    report_content += f"{i}. {recommendation}\n"
                
                report_content += "\n"
            
            report_content += f"""## ğŸ¯ ê²°ë¡ 

POSCO ì‹œìŠ¤í…œì˜ ìµœì¢… ì•ˆì •ì„± ê²€ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.  
ì•ˆì •ì„± ì ìˆ˜ {self.test_results.get('stability_score', 0):.1f}ì ìœ¼ë¡œ {self.test_results.get('stability_grade', 'N/A')} ë“±ê¸‰ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.

---
**ë¦¬í¬íŠ¸ ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            
            report_file = f'recovery_config/final_stability_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.md'
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            logger.info(f"âœ… ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_file}")
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” POSCO ì‹œìŠ¤í…œ ìµœì¢… ì•ˆì •ì„± ê²€ì¦ ì‹œì‘")
    print("=" * 60)
    
    tester = SystemStabilityTester()
    results = tester.run_comprehensive_stability_test()
    
    print("\n" + "=" * 60)
    print("ğŸ† ìµœì¢… ì•ˆì •ì„± ê²€ì¦ ì™„ë£Œ!")
    print(f"ğŸ“Š ì•ˆì •ì„± ì ìˆ˜: {results.get('stability_score', 0):.1f}ì ")
    print(f"ğŸ… ì•ˆì •ì„± ë“±ê¸‰: {results.get('stability_grade', 'N/A')}")
    
    if results.get('stability_score', 0) >= 90:
        print("ğŸ‰ ì‹œìŠ¤í…œì´ ë§¤ìš° ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤!")
    elif results.get('stability_score', 0) >= 80:
        print("âœ… ì‹œìŠ¤í…œì´ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("âš ï¸ ì‹œìŠ¤í…œ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    return results

if __name__ == "__main__":
    main()