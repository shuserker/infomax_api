#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì›ë³¸ ë¡œì§ ì¶”ì¶œ ì‹œìŠ¤í…œ

ì •ìƒ ì»¤ë°‹ a763ef84ì˜ Python íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ë¡œì§ì„ ì¶”ì¶œí•˜ê³ 
êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì €ì¥í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- Python íŒŒì¼ íŒŒì‹± ë° í•¨ìˆ˜/í´ë˜ìŠ¤ ì¶”ì¶œ
- ì„¤ì • íŒŒì¼ ë° í™˜ê²½ ë³€ìˆ˜ ì¶”ì¶œ
- ì˜ì¡´ì„± ê´€ê³„ ë¶„ì„ ë° ë§¤í•‘
- ì¶”ì¶œëœ ë¡œì§ì˜ êµ¬ì¡°í™”ëœ ì €ì¥

ì‘ì„±ì: AI Assistant
ìƒì„±ì¼: 2025-08-12
"""

import os
import ast
import json
import re
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Set, Any, Tuple
from datetime import datetime
import logging
from dataclasses import dataclass, asdict
import configparser

from git_commit_analyzer import GitCommitAnalyzer


@dataclass
class FunctionInfo:
    """í•¨ìˆ˜ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    name: str
    args: List[str]
    docstring: Optional[str]
    line_start: int
    line_end: int
    source_code: str
    decorators: List[str]
    is_async: bool


@dataclass
class ClassInfo:
    """í´ë˜ìŠ¤ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    name: str
    bases: List[str]
    docstring: Optional[str]
    line_start: int
    line_end: int
    methods: List[FunctionInfo]
    attributes: List[str]
    decorators: List[str]


@dataclass
class ModuleInfo:
    """ëª¨ë“ˆ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    file_path: str
    module_name: str
    docstring: Optional[str]
    imports: List[str]
    functions: List[FunctionInfo]
    classes: List[ClassInfo]
    global_variables: Dict[str, Any]
    dependencies: Set[str]


@dataclass
class ConfigInfo:
    """ì„¤ì • ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    file_path: str
    config_type: str  # 'python', 'json', 'ini', 'env'
    content: Dict[str, Any]
    variables: Dict[str, Any]


class PythonASTAnalyzer:
    """Python AST ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger("PythonASTAnalyzer")
    
    def parse_file(self, file_path: Path) -> Optional[ModuleInfo]:
        """
        Python íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ëª¨ë“ˆ ì •ë³´ ì¶”ì¶œ
        
        Args:
            file_path: ë¶„ì„í•  Python íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ModuleInfo ê°ì²´ ë˜ëŠ” None
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source_code = f.read()
            
            tree = ast.parse(source_code)
            
            module_info = ModuleInfo(
                file_path=str(file_path),
                module_name=file_path.stem,
                docstring=ast.get_docstring(tree),
                imports=[],
                functions=[],
                classes=[],
                global_variables={},
                dependencies=set()
            )
            
            # AST ë…¸ë“œ ìˆœíšŒí•˜ì—¬ ì •ë³´ ì¶”ì¶œ
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        module_info.imports.append(alias.name)
                        module_info.dependencies.add(alias.name.split('.')[0])
                
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        module_info.imports.append(f"from {node.module} import {', '.join(alias.name for alias in node.names)}")
                        module_info.dependencies.add(node.module.split('.')[0])
                
                elif isinstance(node, ast.FunctionDef):
                    if self._is_top_level_function(node, tree):
                        func_info = self._extract_function_info(node, source_code)
                        module_info.functions.append(func_info)
                
                elif isinstance(node, ast.ClassDef):
                    if self._is_top_level_class(node, tree):
                        class_info = self._extract_class_info(node, source_code)
                        module_info.classes.append(class_info)
                
                elif isinstance(node, ast.Assign):
                    if self._is_global_variable(node, tree):
                        var_info = self._extract_global_variable(node, source_code)
                        module_info.global_variables.update(var_info)
            
            return module_info
            
        except Exception as e:
            self.logger.error(f"Python íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨ {file_path}: {e}")
            return None
    
    def _is_top_level_function(self, node: ast.FunctionDef, tree: ast.AST) -> bool:
        """ìµœìƒìœ„ ë ˆë²¨ í•¨ìˆ˜ì¸ì§€ í™•ì¸"""
        for parent in ast.walk(tree):
            if hasattr(parent, 'body') and node in parent.body:
                return isinstance(parent, ast.Module)
        return False
    
    def _is_top_level_class(self, node: ast.ClassDef, tree: ast.AST) -> bool:
        """ìµœìƒìœ„ ë ˆë²¨ í´ë˜ìŠ¤ì¸ì§€ í™•ì¸"""
        for parent in ast.walk(tree):
            if hasattr(parent, 'body') and node in parent.body:
                return isinstance(parent, ast.Module)
        return False
    
    def _is_global_variable(self, node: ast.Assign, tree: ast.AST) -> bool:
        """ì „ì—­ ë³€ìˆ˜ì¸ì§€ í™•ì¸"""
        for parent in ast.walk(tree):
            if hasattr(parent, 'body') and node in parent.body:
                return isinstance(parent, ast.Module)
        return False
    
    def _extract_function_info(self, node: ast.FunctionDef, source_code: str) -> FunctionInfo:
        """í•¨ìˆ˜ ì •ë³´ ì¶”ì¶œ"""
        args = [arg.arg for arg in node.args.args]
        decorators = [ast.unparse(decorator) for decorator in node.decorator_list]
        
        # ì†ŒìŠ¤ ì½”ë“œì—ì„œ í•¨ìˆ˜ ë¶€ë¶„ ì¶”ì¶œ
        lines = source_code.split('\n')
        func_source = '\n'.join(lines[node.lineno-1:node.end_lineno])
        
        return FunctionInfo(
            name=node.name,
            args=args,
            docstring=ast.get_docstring(node),
            line_start=node.lineno,
            line_end=node.end_lineno or node.lineno,
            source_code=func_source,
            decorators=decorators,
            is_async=isinstance(node, ast.AsyncFunctionDef)
        )
    
    def _extract_class_info(self, node: ast.ClassDef, source_code: str) -> ClassInfo:
        """í´ë˜ìŠ¤ ì •ë³´ ì¶”ì¶œ"""
        bases = [ast.unparse(base) for base in node.bases]
        decorators = [ast.unparse(decorator) for decorator in node.decorator_list]
        
        methods = []
        attributes = []
        
        for item in node.body:
            if isinstance(item, ast.FunctionDef):
                method_info = self._extract_function_info(item, source_code)
                methods.append(method_info)
            elif isinstance(item, ast.Assign):
                for target in item.targets:
                    if isinstance(target, ast.Name):
                        attributes.append(target.id)
        
        return ClassInfo(
            name=node.name,
            bases=bases,
            docstring=ast.get_docstring(node),
            line_start=node.lineno,
            line_end=node.end_lineno or node.lineno,
            methods=methods,
            attributes=attributes,
            decorators=decorators
        )
    
    def _extract_global_variable(self, node: ast.Assign, source_code: str) -> Dict[str, Any]:
        """ì „ì—­ ë³€ìˆ˜ ì •ë³´ ì¶”ì¶œ"""
        variables = {}
        
        for target in node.targets:
            if isinstance(target, ast.Name):
                try:
                    # ê°’ì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                    value_str = ast.unparse(node.value)
                    variables[target.id] = value_str
                except:
                    variables[target.id] = "<ë³µì¡í•œ í‘œí˜„ì‹>"
        
        return variables


class ConfigExtractor:
    """ì„¤ì • íŒŒì¼ ì¶”ì¶œê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger("ConfigExtractor")
    
    def extract_config_files(self, file_paths: List[Path]) -> List[ConfigInfo]:
        """
        ì„¤ì • íŒŒì¼ë“¤ì—ì„œ ì„¤ì • ì •ë³´ ì¶”ì¶œ
        
        Args:
            file_paths: ì„¤ì • íŒŒì¼ ê²½ë¡œ ëª©ë¡
            
        Returns:
            ConfigInfo ê°ì²´ ëª©ë¡
        """
        config_infos = []
        
        for file_path in file_paths:
            config_info = self._extract_single_config(file_path)
            if config_info:
                config_infos.append(config_info)
        
        return config_infos
    
    def _extract_single_config(self, file_path: Path) -> Optional[ConfigInfo]:
        """ë‹¨ì¼ ì„¤ì • íŒŒì¼ ë¶„ì„"""
        try:
            suffix = file_path.suffix.lower()
            
            if suffix == '.py':
                return self._extract_python_config(file_path)
            elif suffix == '.json':
                return self._extract_json_config(file_path)
            elif suffix in ['.ini', '.cfg']:
                return self._extract_ini_config(file_path)
            elif suffix == '.env':
                return self._extract_env_config(file_path)
            else:
                return None
                
        except Exception as e:
            self.logger.error(f"ì„¤ì • íŒŒì¼ ì¶”ì¶œ ì‹¤íŒ¨ {file_path}: {e}")
            return None
    
    def _extract_python_config(self, file_path: Path) -> ConfigInfo:
        """Python ì„¤ì • íŒŒì¼ ë¶„ì„"""
        with open(file_path, 'r', encoding='utf-8') as f:
            source_code = f.read()
        
        tree = ast.parse(source_code)
        variables = {}
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Assign):
                for target in node.targets:
                    if isinstance(target, ast.Name):
                        try:
                            value_str = ast.unparse(node.value)
                            variables[target.id] = value_str
                        except:
                            variables[target.id] = "<ë³µì¡í•œ í‘œí˜„ì‹>"
        
        return ConfigInfo(
            file_path=str(file_path),
            config_type='python',
            content={'source_code': source_code},
            variables=variables
        )
    
    def _extract_json_config(self, file_path: Path) -> ConfigInfo:
        """JSON ì„¤ì • íŒŒì¼ ë¶„ì„"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = json.load(f)
        
        return ConfigInfo(
            file_path=str(file_path),
            config_type='json',
            content=content,
            variables=self._flatten_dict(content)
        )
    
    def _extract_ini_config(self, file_path: Path) -> ConfigInfo:
        """INI ì„¤ì • íŒŒì¼ ë¶„ì„"""
        config = configparser.ConfigParser()
        config.read(file_path, encoding='utf-8')
        
        content = {}
        variables = {}
        
        for section_name in config.sections():
            section = dict(config[section_name])
            content[section_name] = section
            
            for key, value in section.items():
                variables[f"{section_name}.{key}"] = value
        
        return ConfigInfo(
            file_path=str(file_path),
            config_type='ini',
            content=content,
            variables=variables
        )
    
    def _extract_env_config(self, file_path: Path) -> ConfigInfo:
        """í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ë¶„ì„"""
        variables = {}
        
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#'):
                    if '=' in line:
                        key, value = line.split('=', 1)
                        variables[key.strip()] = value.strip()
        
        return ConfigInfo(
            file_path=str(file_path),
            config_type='env',
            content={'raw_content': variables},
            variables=variables
        )
    
    def _flatten_dict(self, d: Dict, parent_key: str = '', sep: str = '.') -> Dict[str, Any]:
        """ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ë¥¼ í‰ë©´í™”"""
        items = []
        for k, v in d.items():
            new_key = f"{parent_key}{sep}{k}" if parent_key else k
            if isinstance(v, dict):
                items.extend(self._flatten_dict(v, new_key, sep=sep).items())
            else:
                items.append((new_key, v))
        return dict(items)


class DependencyAnalyzer:
    """ì˜ì¡´ì„± ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.logger = logging.getLogger("DependencyAnalyzer")
    
    def analyze_dependencies(self, modules: List[ModuleInfo]) -> Dict[str, Any]:
        """
        ëª¨ë“ˆ ê°„ ì˜ì¡´ì„± ê´€ê³„ ë¶„ì„
        
        Args:
            modules: ë¶„ì„í•  ëª¨ë“ˆ ëª©ë¡
            
        Returns:
            ì˜ì¡´ì„± ë¶„ì„ ê²°ê³¼
        """
        dependency_graph = {}
        external_dependencies = set()
        internal_dependencies = {}
        
        # ëª¨ë“ˆëª… ë§¤í•‘ ìƒì„±
        module_names = {module.module_name for module in modules}
        
        for module in modules:
            module_deps = set()
            
            for dep in module.dependencies:
                if dep in module_names:
                    # ë‚´ë¶€ ì˜ì¡´ì„±
                    module_deps.add(dep)
                else:
                    # ì™¸ë¶€ ì˜ì¡´ì„±
                    external_dependencies.add(dep)
            
            internal_dependencies[module.module_name] = list(module_deps)
            dependency_graph[module.module_name] = {
                'file_path': module.file_path,
                'internal_deps': list(module_deps),
                'external_deps': [dep for dep in module.dependencies if dep not in module_names]
            }
        
        # ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
        circular_deps = self._find_circular_dependencies(internal_dependencies)
        
        return {
            'dependency_graph': dependency_graph,
            'external_dependencies': list(external_dependencies),
            'internal_dependencies': internal_dependencies,
            'circular_dependencies': circular_deps,
            'dependency_count': {
                'total_modules': len(modules),
                'external_deps': len(external_dependencies),
                'internal_connections': sum(len(deps) for deps in internal_dependencies.values())
            }
        }
    
    def _find_circular_dependencies(self, deps: Dict[str, List[str]]) -> List[List[str]]:
        """ìˆœí™˜ ì˜ì¡´ì„± ì°¾ê¸°"""
        def dfs(node, path, visited, rec_stack):
            visited.add(node)
            rec_stack.add(node)
            path.append(node)
            
            for neighbor in deps.get(node, []):
                if neighbor not in visited:
                    result = dfs(neighbor, path, visited, rec_stack)
                    if result:
                        return result
                elif neighbor in rec_stack:
                    # ìˆœí™˜ ë°œê²¬
                    cycle_start = path.index(neighbor)
                    return path[cycle_start:] + [neighbor]
            
            path.pop()
            rec_stack.remove(node)
            return None
        
        visited = set()
        cycles = []
        
        for node in deps:
            if node not in visited:
                cycle = dfs(node, [], visited, set())
                if cycle:
                    cycles.append(cycle)
        
        return cycles


class LogicExtractor:
    """ì›ë³¸ ë¡œì§ ì¶”ì¶œ ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, target_commit: str = "a763ef84be08b5b1dab0c0ba20594b141baec7ab"):
        """
        ë¡œì§ ì¶”ì¶œê¸° ì´ˆê¸°í™”
        
        Args:
            target_commit: ë¶„ì„í•  ì»¤ë°‹ í•´ì‹œ
        """
        self.target_commit = target_commit
        self.git_analyzer = GitCommitAnalyzer()
        self.ast_analyzer = PythonASTAnalyzer()
        self.config_extractor = ConfigExtractor()
        self.dependency_analyzer = DependencyAnalyzer()
        
        self.logger = self._setup_logger()
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
        self.output_dir = Path("recovery_config/extracted_logic")
        self.output_dir.mkdir(exist_ok=True)
    
    def _setup_logger(self) -> logging.Logger:
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger("LogicExtractor")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    def extract_from_commit(self) -> Dict[str, Any]:
        """
        ì§€ì •ëœ ì»¤ë°‹ì—ì„œ ì›ë³¸ ë¡œì§ ì¶”ì¶œ
        
        Returns:
            ì¶”ì¶œëœ ë¡œì§ ì •ë³´
        """
        self.logger.info(f"ì»¤ë°‹ {self.target_commit}ì—ì„œ ì›ë³¸ ë¡œì§ ì¶”ì¶œ ì‹œì‘")
        
        # 1. ì»¤ë°‹ ì²´í¬ì•„ì›ƒ ë° íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        files = self.git_analyzer.get_files_in_commit(self.target_commit)
        if not files:
            return {'error': 'ì»¤ë°‹ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}
        
        # 2. í•µì‹¬ ë¡œì§ íŒŒì¼ ì‹ë³„
        core_files = self.git_analyzer.identify_core_logic_files(files)
        self.logger.info(f"í•µì‹¬ ë¡œì§ íŒŒì¼ {len(core_files)}ê°œ ì‹ë³„")
        
        # 3. Python íŒŒì¼ ë¶„ì„
        python_files = [f for f in core_files if f.endswith('.py')]
        modules = self._analyze_python_files(python_files)
        
        # 4. ì„¤ì • íŒŒì¼ ë¶„ì„
        config_files = self._identify_config_files(files)
        configs = self.config_extractor.extract_config_files(config_files)
        
        # 5. ì˜ì¡´ì„± ë¶„ì„
        dependency_analysis = self.dependency_analyzer.analyze_dependencies(modules)
        
        # 6. ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ë¶„ì„
        script_files = [f for f in core_files if f.endswith(('.sh', '.bat', '.command'))]
        scripts = self._analyze_script_files(script_files)
        
        extraction_result = {
            'extraction_info': {
                'target_commit': self.target_commit,
                'extraction_timestamp': datetime.now().isoformat(),
                'total_files': len(files),
                'core_files': len(core_files),
                'python_files': len(python_files),
                'config_files': len(config_files),
                'script_files': len(script_files)
            },
            'modules': [asdict(module) for module in modules],
            'configs': [asdict(config) for config in configs],
            'scripts': scripts,
            'dependency_analysis': dependency_analysis,
            'file_structure': self._analyze_file_structure(files)
        }
        
        self.logger.info("ì›ë³¸ ë¡œì§ ì¶”ì¶œ ì™„ë£Œ")
        return extraction_result
    
    def _analyze_python_files(self, python_files: List[str]) -> List[ModuleInfo]:
        """Python íŒŒì¼ë“¤ ë¶„ì„"""
        modules = []
        
        for file_path in python_files:
            # ì»¤ë°‹ì—ì„œ íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            content = self._get_file_content_from_commit(file_path)
            if content:
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ë¶„ì„
                temp_file = self.output_dir / f"temp_{Path(file_path).name}"
                with open(temp_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                module_info = self.ast_analyzer.parse_file(temp_file)
                if module_info:
                    # ì›ë³¸ ê²½ë¡œë¡œ ë³µì›
                    module_info.file_path = file_path
                    modules.append(module_info)
                
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                temp_file.unlink()
        
        self.logger.info(f"Python ëª¨ë“ˆ {len(modules)}ê°œ ë¶„ì„ ì™„ë£Œ")
        return modules
    
    def _identify_config_files(self, files: List[str]) -> List[Path]:
        """ì„¤ì • íŒŒì¼ë“¤ ì‹ë³„"""
        config_patterns = [
            r'.*config.*\.py$',
            r'.*settings.*\.py$',
            r'.*\.json$',
            r'.*\.ini$',
            r'.*\.cfg$',
            r'.*\.env$',
            r'requirements\.txt$'
        ]
        
        config_files = []
        for file_path in files:
            if any(re.match(pattern, file_path, re.IGNORECASE) for pattern in config_patterns):
                # ë°±ì—… íŒŒì¼ ì œì™¸
                if not any(exclude in file_path.lower() for exclude in ['backup', 'temp', 'test']):
                    config_files.append(Path(file_path))
        
        return config_files
    
    def _analyze_script_files(self, script_files: List[str]) -> List[Dict[str, Any]]:
        """ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ë“¤ ë¶„ì„"""
        scripts = []
        
        for file_path in script_files:
            content = self._get_file_content_from_commit(file_path)
            if content:
                script_info = {
                    'file_path': file_path,
                    'file_type': Path(file_path).suffix,
                    'content': content,
                    'commands': self._extract_commands_from_script(content),
                    'variables': self._extract_variables_from_script(content)
                }
                scripts.append(script_info)
        
        self.logger.info(f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ {len(scripts)}ê°œ ë¶„ì„ ì™„ë£Œ")
        return scripts
    
    def _extract_commands_from_script(self, content: str) -> List[str]:
        """ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ëª…ë ¹ì–´ ì¶”ì¶œ"""
        commands = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#') and not line.startswith('::'):
                # ì£¼ì„ì´ ì•„ë‹Œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë¼ì¸
                if any(cmd in line.lower() for cmd in ['python', 'pip', 'git', 'cd', 'echo', 'set']):
                    commands.append(line)
        
        return commands
    
    def _extract_variables_from_script(self, content: str) -> Dict[str, str]:
        """ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ë³€ìˆ˜ ì¶”ì¶œ"""
        variables = {}
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            # Windows batch ë³€ìˆ˜ (set VAR=value)
            if line.startswith('set ') and '=' in line:
                var_part = line[4:]  # 'set ' ì œê±°
                if '=' in var_part:
                    key, value = var_part.split('=', 1)
                    variables[key.strip()] = value.strip()
            
            # Shell ë³€ìˆ˜ (VAR=value)
            elif '=' in line and not line.startswith('#'):
                if not any(cmd in line.lower() for cmd in ['if', 'for', 'while', 'echo']):
                    key, value = line.split('=', 1)
                    if key.strip().isidentifier():
                        variables[key.strip()] = value.strip()
        
        return variables
    
    def _analyze_file_structure(self, files: List[str]) -> Dict[str, Any]:
        """íŒŒì¼ êµ¬ì¡° ë¶„ì„"""
        structure = {
            'directories': set(),
            'file_types': {},
            'depth_analysis': {},
            'naming_patterns': {}
        }
        
        for file_path in files:
            path_obj = Path(file_path)
            
            # ë””ë ‰í† ë¦¬ ì¶”ê°€
            for parent in path_obj.parents:
                if str(parent) != '.':
                    structure['directories'].add(str(parent))
            
            # íŒŒì¼ íƒ€ì… ë¶„ì„
            suffix = path_obj.suffix.lower()
            if suffix:
                structure['file_types'][suffix] = structure['file_types'].get(suffix, 0) + 1
            
            # ê¹Šì´ ë¶„ì„
            depth = len(path_obj.parts) - 1
            structure['depth_analysis'][depth] = structure['depth_analysis'].get(depth, 0) + 1
            
            # ë„¤ì´ë° íŒ¨í„´ ë¶„ì„
            name = path_obj.stem.lower()
            if 'posco' in name:
                structure['naming_patterns']['posco'] = structure['naming_patterns'].get('posco', 0) + 1
            if 'news' in name:
                structure['naming_patterns']['news'] = structure['naming_patterns'].get('news', 0) + 1
            if 'monitor' in name:
                structure['naming_patterns']['monitor'] = structure['naming_patterns'].get('monitor', 0) + 1
        
        # setì„ listë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ë¥¼ ìœ„í•´)
        structure['directories'] = sorted(list(structure['directories']))
        
        return structure
    
    def _get_file_content_from_commit(self, file_path: str) -> Optional[str]:
        """ì»¤ë°‹ì—ì„œ íŠ¹ì • íŒŒì¼ì˜ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        success, stdout, stderr = self.git_analyzer.execute_git_command([
            'git', 'show', f'{self.target_commit}:{file_path}'
        ])
        
        if success:
            return stdout
        else:
            self.logger.warning(f"íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ {file_path}: {stderr}")
            return None
    
    def save_extracted_logic(self, extraction_result: Dict[str, Any]) -> None:
        """ì¶”ì¶œëœ ë¡œì§ì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON ì§ë ¬í™”ë¥¼ ìœ„í•´ setì„ listë¡œ ë³€í™˜
        def convert_sets_to_lists(obj):
            if isinstance(obj, dict):
                return {k: convert_sets_to_lists(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_sets_to_lists(item) for item in obj]
            elif isinstance(obj, set):
                return list(obj)
            else:
                return obj
        
        serializable_result = convert_sets_to_lists(extraction_result)
        
        # 1. ì „ì²´ ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        main_output = self.output_dir / f"extracted_logic_{timestamp}.json"
        with open(main_output, 'w', encoding='utf-8') as f:
            json.dump(serializable_result, f, ensure_ascii=False, indent=2)
        
        # 2. ëª¨ë“ˆë³„ë¡œ ê°œë³„ íŒŒì¼ë¡œ ì €ì¥
        modules_dir = self.output_dir / "modules"
        modules_dir.mkdir(exist_ok=True)
        
        for module_data in serializable_result['modules']:
            module_file = modules_dir / f"{module_data['module_name']}.json"
            with open(module_file, 'w', encoding='utf-8') as f:
                json.dump(module_data, f, ensure_ascii=False, indent=2)
        
        # 3. ì„¤ì • íŒŒì¼ë“¤ ì €ì¥
        configs_dir = self.output_dir / "configs"
        configs_dir.mkdir(exist_ok=True)
        
        for config_data in serializable_result['configs']:
            config_name = Path(config_data['file_path']).stem
            config_file = configs_dir / f"{config_name}.json"
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)
        
        # 4. ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ë“¤ ì €ì¥
        scripts_dir = self.output_dir / "scripts"
        scripts_dir.mkdir(exist_ok=True)
        
        for script_data in serializable_result['scripts']:
            script_name = Path(script_data['file_path']).stem
            script_file = scripts_dir / f"{script_name}.json"
            with open(script_file, 'w', encoding='utf-8') as f:
                json.dump(script_data, f, ensure_ascii=False, indent=2)
        
        # 5. ì˜ì¡´ì„± ë¶„ì„ ê²°ê³¼ ì €ì¥
        dependency_file = self.output_dir / f"dependency_analysis_{timestamp}.json"
        with open(dependency_file, 'w', encoding='utf-8') as f:
            json.dump(serializable_result['dependency_analysis'], f, ensure_ascii=False, indent=2)
        
        # 6. ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
        self._generate_extraction_summary(serializable_result, timestamp)
        
        self.logger.info(f"ì¶”ì¶œëœ ë¡œì§ ì €ì¥ ì™„ë£Œ: {self.output_dir}")
    
    def _generate_extraction_summary(self, extraction_result: Dict[str, Any], timestamp: str) -> None:
        """ì¶”ì¶œ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        summary_file = self.output_dir / f"extraction_summary_{timestamp}.md"
        
        info = extraction_result['extraction_info']
        modules = extraction_result['modules']
        configs = extraction_result['configs']
        scripts = extraction_result['scripts']
        deps = extraction_result['dependency_analysis']
        
        summary_content = f"""# ì›ë³¸ ë¡œì§ ì¶”ì¶œ ìš”ì•½ ë³´ê³ ì„œ

## ì¶”ì¶œ ì •ë³´
- **ëŒ€ìƒ ì»¤ë°‹**: {info['target_commit']}
- **ì¶”ì¶œ ì‹œê°„**: {info['extraction_timestamp']}
- **ì´ íŒŒì¼ ìˆ˜**: {info['total_files']}ê°œ
- **í•µì‹¬ íŒŒì¼ ìˆ˜**: {info['core_files']}ê°œ

## ë¶„ì„ ê²°ê³¼

### Python ëª¨ë“ˆ ({len(modules)}ê°œ)
"""
        
        for module in modules:
            summary_content += f"""
#### {module['module_name']}
- **íŒŒì¼ ê²½ë¡œ**: {module['file_path']}
- **í•¨ìˆ˜ ìˆ˜**: {len(module['functions'])}ê°œ
- **í´ë˜ìŠ¤ ìˆ˜**: {len(module['classes'])}ê°œ
- **ì˜ì¡´ì„±**: {len(module['dependencies'])}ê°œ
"""
            
            if module['functions']:
                summary_content += "- **ì£¼ìš” í•¨ìˆ˜**:\n"
                for func in module['functions'][:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                    summary_content += f"  - `{func['name']}({', '.join(func['args'])})`\n"
            
            if module['classes']:
                summary_content += "- **í´ë˜ìŠ¤**:\n"
                for cls in module['classes']:
                    summary_content += f"  - `{cls['name']}` (ë©”ì„œë“œ {len(cls['methods'])}ê°œ)\n"
        
        summary_content += f"""

### ì„¤ì • íŒŒì¼ ({len(configs)}ê°œ)
"""
        
        for config in configs:
            summary_content += f"""
#### {Path(config['file_path']).name}
- **íƒ€ì…**: {config['config_type']}
- **ë³€ìˆ˜ ìˆ˜**: {len(config['variables'])}ê°œ
- **ê²½ë¡œ**: {config['file_path']}
"""
        
        summary_content += f"""

### ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ({len(scripts)}ê°œ)
"""
        
        for script in scripts:
            summary_content += f"""
#### {Path(script['file_path']).name}
- **íƒ€ì…**: {script['file_type']}
- **ëª…ë ¹ì–´ ìˆ˜**: {len(script['commands'])}ê°œ
- **ë³€ìˆ˜ ìˆ˜**: {len(script['variables'])}ê°œ
"""
        
        summary_content += f"""

### ì˜ì¡´ì„± ë¶„ì„
- **ì´ ëª¨ë“ˆ ìˆ˜**: {deps['dependency_count']['total_modules']}ê°œ
- **ì™¸ë¶€ ì˜ì¡´ì„±**: {deps['dependency_count']['external_deps']}ê°œ
- **ë‚´ë¶€ ì—°ê²°**: {deps['dependency_count']['internal_connections']}ê°œ
- **ìˆœí™˜ ì˜ì¡´ì„±**: {len(deps['circular_dependencies'])}ê°œ

#### ì™¸ë¶€ ì˜ì¡´ì„± ëª©ë¡
"""
        
        for dep in sorted(deps['external_dependencies']):
            summary_content += f"- {dep}\n"
        
        if deps['circular_dependencies']:
            summary_content += "\n#### ìˆœí™˜ ì˜ì¡´ì„± ê²½ê³ \n"
            for cycle in deps['circular_dependencies']:
                summary_content += f"- {' â†’ '.join(cycle)}\n"
        
        summary_content += f"""

## íŒŒì¼ êµ¬ì¡° ë¶„ì„
- **ë””ë ‰í† ë¦¬ ìˆ˜**: {len(extraction_result['file_structure']['directories'])}ê°œ
- **íŒŒì¼ íƒ€ì…ë³„ ë¶„í¬**:
"""
        
        for file_type, count in sorted(extraction_result['file_structure']['file_types'].items()):
            summary_content += f"  - {file_type}: {count}ê°œ\n"
        
        summary_content += """

## ë‹¤ìŒ ë‹¨ê³„
1. ì¶”ì¶œëœ ë¡œì§ì„ ê¸°ë°˜ìœ¼ë¡œ í•µì‹¬ ëª¨ë“ˆ ë³µì›
2. ì„¤ì • íŒŒì¼ë“¤ì„ í˜„ì¬ í™˜ê²½ì— ë§ê²Œ ì¡°ì •
3. ì˜ì¡´ì„± ë¬¸ì œ í•´ê²°
4. í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰

---
*ì´ ë³´ê³ ì„œëŠ” ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
"""
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(summary_content)
        
        self.logger.info(f"ì¶”ì¶œ ìš”ì•½ ë³´ê³ ì„œ ìƒì„±: {summary_file}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” ì›ë³¸ ë¡œì§ ì¶”ì¶œ ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 50)
    
    extractor = LogicExtractor()
    
    try:
        # 1. ì›ë³¸ ë¡œì§ ì¶”ì¶œ
        print("ğŸ“‹ 1ë‹¨ê³„: ì •ìƒ ì»¤ë°‹ì—ì„œ ì›ë³¸ ë¡œì§ ì¶”ì¶œ")
        extraction_result = extractor.extract_from_commit()
        
        if 'error' in extraction_result:
            print(f"âŒ ì˜¤ë¥˜: {extraction_result['error']}")
            return
        
        info = extraction_result['extraction_info']
        print(f"âœ… ë¡œì§ ì¶”ì¶œ ì™„ë£Œ:")
        print(f"   - ì´ íŒŒì¼: {info['total_files']}ê°œ")
        print(f"   - í•µì‹¬ íŒŒì¼: {info['core_files']}ê°œ")
        print(f"   - Python ëª¨ë“ˆ: {info['python_files']}ê°œ")
        print(f"   - ì„¤ì • íŒŒì¼: {info['config_files']}ê°œ")
        print(f"   - ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼: {info['script_files']}ê°œ")
        
        # 2. ì˜ì¡´ì„± ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        print("\nğŸ”— 2ë‹¨ê³„: ì˜ì¡´ì„± ë¶„ì„ ê²°ê³¼")
        deps = extraction_result['dependency_analysis']
        print(f"âœ… ì˜ì¡´ì„± ë¶„ì„ ì™„ë£Œ:")
        print(f"   - ì™¸ë¶€ ì˜ì¡´ì„±: {deps['dependency_count']['external_deps']}ê°œ")
        print(f"   - ë‚´ë¶€ ì—°ê²°: {deps['dependency_count']['internal_connections']}ê°œ")
        
        if deps['circular_dependencies']:
            print(f"   âš ï¸ ìˆœí™˜ ì˜ì¡´ì„±: {len(deps['circular_dependencies'])}ê°œ ë°œê²¬")
        
        # 3. ì¶”ì¶œëœ ë¡œì§ ì €ì¥
        print("\nğŸ’¾ 3ë‹¨ê³„: ì¶”ì¶œëœ ë¡œì§ ì €ì¥")
        extractor.save_extracted_logic(extraction_result)
        print("âœ… ë¡œì§ ì €ì¥ ì™„ë£Œ")
        
        print("\n" + "=" * 50)
        print("ğŸ‰ ì›ë³¸ ë¡œì§ ì¶”ì¶œ ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ!")
        print("\nğŸ“ ì¶œë ¥ íŒŒì¼:")
        print(f"   - ì¶”ì¶œëœ ë¡œì§: {extractor.output_dir}")
        print(f"   - ëª¨ë“ˆë³„ ë¶„ì„: {extractor.output_dir}/modules/")
        print(f"   - ì„¤ì • íŒŒì¼: {extractor.output_dir}/configs/")
        print(f"   - ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼: {extractor.output_dir}/scripts/")
        
    except Exception as e:
        print(f"âŒ ì›ë³¸ ë¡œì§ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()