# -*- coding: utf-8 -*-
"""
í†µí•© API ëª¨ë“ˆ

INFOMAX API ì—°ë™ì˜ ëª¨ë“  ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ì œê³µí•˜ëŠ” ë©”ì¸ ëª¨ë“ˆì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- API í´ë¼ì´ì–¸íŠ¸ ê´€ë¦¬
- ë°ì´í„° íŒŒì‹± ë° ê²€ì¦
- ì—°ê²° ê´€ë¦¬ ë° ì¬ì‹œë„
- ìƒíƒœ ëª¨ë‹ˆí„°ë§
- ìºì‹± ë° ì„±ëŠ¥ ìµœì í™”

ì‘ì„±ì: AI Assistant
ë³µì› ì¼ì‹œ: 2025-08-12
ê¸°ë°˜ ì»¤ë°‹: a763ef84be08b5b1dab0c0ba20594b141baec7ab
"""

import json
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List, Callable
import logging
from pathlib import Path

from recovery_config.infomax_api_client import InfomaxAPIClient
from recovery_config.api_data_parser import APIDataParser
from recovery_config.api_connection_manager import APIConnectionManager, ConnectionStatus


class IntegratedAPIModule:
    """
    í†µí•© API ëª¨ë“ˆ í´ë˜ìŠ¤
    
    INFOMAX APIì™€ì˜ ëª¨ë“  ìƒí˜¸ì‘ìš©ì„ ê´€ë¦¬í•˜ëŠ” ë©”ì¸ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    
    def __init__(self, api_config: Dict[str, Any], cache_config: Optional[Dict[str, Any]] = None):
        """
        í†µí•© API ëª¨ë“ˆ ì´ˆê¸°í™”
        
        Args:
            api_config (dict): API ì„¤ì • ì •ë³´
            cache_config (dict, optional): ìºì‹œ ì„¤ì • ì •ë³´
        """
        self.logger = logging.getLogger(__name__)
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.api_client = InfomaxAPIClient(api_config)
        self.data_parser = APIDataParser()
        self.connection_manager = APIConnectionManager(self.api_client)
        
        # ìºì‹œ ì„¤ì •
        default_cache_config = {
            'enabled': True,
            'cache_file': 'posco_news_cache.json',
            'cache_duration': 300,  # 5ë¶„
            'max_cache_size': 1000
        }
        self.cache_config = {**default_cache_config, **(cache_config or {})}
        
        # ìºì‹œ ë°ì´í„°
        self.cache_data = {}
        self.cache_timestamps = {}
        self.cache_lock = threading.RLock()
        
        # ì½œë°± í•¨ìˆ˜ë“¤
        self.on_data_update: Optional[Callable[[Dict[str, Any]], None]] = None
        self.on_connection_issue: Optional[Callable[[str], None]] = None
        self.on_parsing_error: Optional[Callable[[Exception], None]] = None
        
        # ì—°ê²° ê´€ë¦¬ì ì½œë°± ì„¤ì •
        self.connection_manager.on_status_change = self._on_connection_status_change
        self.connection_manager.on_failure = self._on_connection_failure
        self.connection_manager.on_recovery = self._on_connection_recovery
        
        # ìºì‹œ íŒŒì¼ ë¡œë“œ
        self._load_cache()
        
        self.logger.info("í†µí•© API ëª¨ë“ˆ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_latest_news_data(self, use_cache: bool = True) -> Optional[Dict[str, Any]]:
        """
        ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ
        
        Args:
            use_cache (bool): ìºì‹œ ì‚¬ìš© ì—¬ë¶€
        
        Returns:
            dict: íŒŒì‹±ëœ ë‰´ìŠ¤ ë°ì´í„°
        """
        cache_key = 'latest_news'
        
        # ìºì‹œ í™•ì¸
        if use_cache and self._is_cache_valid(cache_key):
            self.logger.info("ìºì‹œì—ì„œ ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° ë°˜í™˜")
            return self.cache_data.get(cache_key)
        
        try:
            # APIì—ì„œ ë°ì´í„° ì¡°íšŒ
            self.logger.info("APIì—ì„œ ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì¤‘...")
            raw_data = self.connection_manager.execute_with_retry(
                self.api_client.get_news_data
            )
            
            if not raw_data:
                self.logger.warning("APIì—ì„œ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í•¨")
                return None
            
            # ë°ì´í„° íŒŒì‹±
            parsed_data = self.data_parser.parse_news_data(raw_data)
            
            # ë°ì´í„° ê²€ì¦
            is_valid, errors = self.data_parser.validate_parsed_data(parsed_data)
            if not is_valid:
                self.logger.error(f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {errors}")
                if self.on_parsing_error:
                    self.on_parsing_error(Exception(f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {errors}"))
                return None
            
            # ìºì‹œ ì €ì¥
            if use_cache:
                self._update_cache(cache_key, parsed_data)
            
            # ì½œë°± í˜¸ì¶œ
            if self.on_data_update:
                try:
                    self.on_data_update(parsed_data)
                except Exception as e:
                    self.logger.error(f"ë°ì´í„° ì—…ë°ì´íŠ¸ ì½œë°± ì˜¤ë¥˜: {e}")
            
            self.logger.info(f"ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì„±ê³µ: {len(parsed_data)}ê°œ íƒ€ì…")
            return parsed_data
            
        except Exception as e:
            self.logger.error(f"ìµœì‹  ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def get_historical_data(self, start_date: str, end_date: str, use_cache: bool = True) -> Dict[str, Any]:
        """
        ê¸°ê°„ë³„ ê³¼ê±° ë°ì´í„° ì¡°íšŒ
        
        Args:
            start_date (str): ì‹œì‘ ë‚ ì§œ (YYYYMMDD)
            end_date (str): ì¢…ë£Œ ë‚ ì§œ (YYYYMMDD)
            use_cache (bool): ìºì‹œ ì‚¬ìš© ì—¬ë¶€
        
        Returns:
            dict: ë‚ ì§œë³„ íŒŒì‹±ëœ ë‰´ìŠ¤ ë°ì´í„°
        """
        cache_key = f'historical_{start_date}_{end_date}'
        
        # ìºì‹œ í™•ì¸
        if use_cache and self._is_cache_valid(cache_key):
            self.logger.info(f"ìºì‹œì—ì„œ ê³¼ê±° ë°ì´í„° ë°˜í™˜: {start_date} ~ {end_date}")
            return self.cache_data.get(cache_key, {})
        
        try:
            self.logger.info(f"APIì—ì„œ ê³¼ê±° ë°ì´í„° ì¡°íšŒ ì¤‘: {start_date} ~ {end_date}")
            
            # APIì—ì„œ ê³¼ê±° ë°ì´í„° ì¡°íšŒ
            raw_historical_data = self.connection_manager.execute_with_retry(
                self.api_client.get_historical_data,
                start_date,
                end_date
            )
            
            if not raw_historical_data:
                self.logger.warning("ê³¼ê±° ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í•¨")
                return {}
            
            # ë‚ ì§œë³„ ë°ì´í„° íŒŒì‹±
            parsed_historical_data = {}
            for date_str, raw_data in raw_historical_data.items():
                parsed_data = self.data_parser.parse_news_data(raw_data)
                if parsed_data:
                    parsed_historical_data[date_str] = parsed_data
            
            # ìºì‹œ ì €ì¥
            if use_cache:
                self._update_cache(cache_key, parsed_historical_data)
            
            self.logger.info(f"ê³¼ê±° ë°ì´í„° ì¡°íšŒ ì„±ê³µ: {len(parsed_historical_data)}ì¼ì¹˜ ë°ì´í„°")
            return parsed_historical_data
            
        except Exception as e:
            self.logger.error(f"ê³¼ê±° ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_news_by_date(self, date: str, use_cache: bool = True) -> Optional[Dict[str, Any]]:
        """
        íŠ¹ì • ë‚ ì§œì˜ ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ
        
        Args:
            date (str): ì¡°íšŒí•  ë‚ ì§œ (YYYYMMDD)
            use_cache (bool): ìºì‹œ ì‚¬ìš© ì—¬ë¶€
        
        Returns:
            dict: íŒŒì‹±ëœ ë‰´ìŠ¤ ë°ì´í„°
        """
        cache_key = f'news_{date}'
        
        # ìºì‹œ í™•ì¸
        if use_cache and self._is_cache_valid(cache_key):
            self.logger.info(f"ìºì‹œì—ì„œ {date} ë‰´ìŠ¤ ë°ì´í„° ë°˜í™˜")
            return self.cache_data.get(cache_key)
        
        try:
            self.logger.info(f"APIì—ì„œ {date} ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì¤‘...")
            
            # APIì—ì„œ ë°ì´í„° ì¡°íšŒ
            raw_data = self.connection_manager.execute_with_retry(
                self.api_client.get_news_data,
                date
            )
            
            if not raw_data:
                self.logger.warning(f"{date} ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í•¨")
                return None
            
            # ë°ì´í„° íŒŒì‹±
            parsed_data = self.data_parser.parse_news_data(raw_data)
            
            # ìºì‹œ ì €ì¥
            if use_cache:
                self._update_cache(cache_key, parsed_data)
            
            self.logger.info(f"{date} ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì„±ê³µ")
            return parsed_data
            
        except Exception as e:
            self.logger.error(f"{date} ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def get_status_summary(self) -> Dict[str, Any]:
        """
        ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½ ë°˜í™˜
        
        Returns:
            dict: ìƒíƒœ ìš”ì•½ ì •ë³´
        """
        # ì—°ê²° ìƒíƒœ
        connection_status = self.connection_manager.get_status()
        
        # ìµœì‹  ë°ì´í„° ìƒíƒœ
        latest_data = self.get_latest_news_data(use_cache=True)
        data_summary = None
        if latest_data:
            data_summary = self.data_parser.get_status_summary(latest_data)
        
        # ìºì‹œ ìƒíƒœ
        cache_status = {
            'enabled': self.cache_config['enabled'],
            'cache_entries': len(self.cache_data),
            'cache_size_kb': len(json.dumps(self.cache_data, default=str)) / 1024
        }
        
        return {
            'timestamp': datetime.now().isoformat(),
            'connection': connection_status,
            'data': data_summary,
            'cache': cache_status,
            'overall_health': self._calculate_overall_health(connection_status, data_summary)
        }
    
    def _calculate_overall_health(self, connection_status: Dict[str, Any], data_summary: Optional[Dict[str, Any]]) -> str:
        """ì „ì²´ ì‹œìŠ¤í…œ ê±´ê°•ë„ ê³„ì‚°"""
        if connection_status['status'] == 'failed':
            return 'critical'
        elif connection_status['status'] == 'degraded':
            return 'warning'
        elif data_summary and data_summary.get('overall_status') == 'all_latest':
            return 'healthy'
        elif data_summary and data_summary.get('overall_status') in ['partial_latest', 'has_delayed']:
            return 'warning'
        else:
            return 'unknown'
    
    def test_connection(self) -> bool:
        """API ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            return self.connection_manager.execute_with_retry(
                self.api_client.test_connection
            )
        except Exception as e:
            self.logger.error(f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def start_monitoring(self):
        """ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.connection_manager.start_monitoring()
    
    def stop_monitoring(self):
        """ì—°ê²° ìƒíƒœ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.connection_manager.stop_monitoring()
    
    def clear_cache(self):
        """ìºì‹œ ë°ì´í„° ì‚­ì œ"""
        with self.cache_lock:
            self.cache_data.clear()
            self.cache_timestamps.clear()
            self._save_cache()
            self.logger.info("ìºì‹œ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
    
    def _is_cache_valid(self, cache_key: str) -> bool:
        """ìºì‹œ ìœ íš¨ì„± í™•ì¸"""
        if not self.cache_config['enabled']:
            return False
        
        if cache_key not in self.cache_data:
            return False
        
        if cache_key not in self.cache_timestamps:
            return False
        
        cache_time = self.cache_timestamps[cache_key]
        cache_duration = self.cache_config['cache_duration']
        
        return (datetime.now() - cache_time).total_seconds() < cache_duration
    
    def _update_cache(self, cache_key: str, data: Any):
        """ìºì‹œ ë°ì´í„° ì—…ë°ì´íŠ¸"""
        if not self.cache_config['enabled']:
            return
        
        with self.cache_lock:
            self.cache_data[cache_key] = data
            self.cache_timestamps[cache_key] = datetime.now()
            
            # ìºì‹œ í¬ê¸° ì œí•œ
            max_size = self.cache_config['max_cache_size']
            if len(self.cache_data) > max_size:
                # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                oldest_key = min(self.cache_timestamps.keys(), key=lambda k: self.cache_timestamps[k])
                del self.cache_data[oldest_key]
                del self.cache_timestamps[oldest_key]
            
            self._save_cache()
    
    def _load_cache(self):
        """ìºì‹œ íŒŒì¼ ë¡œë“œ"""
        if not self.cache_config['enabled']:
            return
        
        cache_file = Path(self.cache_config['cache_file'])
        
        try:
            if cache_file.exists():
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cache_content = json.load(f)
                    
                self.cache_data = cache_content.get('data', {})
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ ë³µì›
                timestamps = cache_content.get('timestamps', {})
                self.cache_timestamps = {
                    k: datetime.fromisoformat(v) for k, v in timestamps.items()
                }
                
                self.logger.info(f"ìºì‹œ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(self.cache_data)}ê°œ í•­ëª©")
        except Exception as e:
            self.logger.warning(f"ìºì‹œ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.cache_data = {}
            self.cache_timestamps = {}
    
    def _save_cache(self):
        """ìºì‹œ íŒŒì¼ ì €ì¥"""
        if not self.cache_config['enabled']:
            return
        
        cache_file = Path(self.cache_config['cache_file'])
        
        try:
            cache_content = {
                'data': self.cache_data,
                'timestamps': {
                    k: v.isoformat() for k, v in self.cache_timestamps.items()
                }
            }
            
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_content, f, ensure_ascii=False, indent=2, default=str)
                
        except Exception as e:
            self.logger.error(f"ìºì‹œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _on_connection_status_change(self, old_status: ConnectionStatus, new_status: ConnectionStatus):
        """ì—°ê²° ìƒíƒœ ë³€ê²½ ì½œë°±"""
        self.logger.info(f"API ì—°ê²° ìƒíƒœ ë³€ê²½: {old_status.value} â†’ {new_status.value}")
        
        if self.on_connection_issue and new_status == ConnectionStatus.FAILED:
            try:
                self.on_connection_issue(f"API ì—°ê²° ì‹¤íŒ¨: {old_status.value} â†’ {new_status.value}")
            except Exception as e:
                self.logger.error(f"ì—°ê²° ì´ìŠˆ ì½œë°± ì˜¤ë¥˜: {e}")
    
    def _on_connection_failure(self, exception: Exception):
        """ì—°ê²° ì‹¤íŒ¨ ì½œë°±"""
        self.logger.error(f"API ì—°ê²° ì‹¤íŒ¨: {exception}")
    
    def _on_connection_recovery(self):
        """ì—°ê²° ë³µêµ¬ ì½œë°±"""
        self.logger.info("API ì—°ê²° ë³µêµ¬ë¨")
    
    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        self.start_monitoring()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ"""
        self.stop_monitoring()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    import sys
    import os
    
    # ì„¤ì • ë¡œë“œ
    sys.path.append(os.path.dirname(os.path.dirname(__file__)))
    
    try:
        from recovery_config.environment_settings import load_environment_settings
        
        settings = load_environment_settings()
        api_config = settings.get('API_CONFIG', {})
        
        if api_config:
            # í†µí•© API ëª¨ë“ˆ ìƒì„±
            api_module = IntegratedAPIModule(api_config)
            
            # ì½œë°± í•¨ìˆ˜ ì„¤ì •
            def on_data_update(data):
                print(f"ğŸ“Š ë°ì´í„° ì—…ë°ì´íŠ¸: {len(data)}ê°œ ë‰´ìŠ¤ íƒ€ì…")
            
            def on_connection_issue(message):
                print(f"âš ï¸ ì—°ê²° ì´ìŠˆ: {message}")
            
            api_module.on_data_update = on_data_update
            api_module.on_connection_issue = on_connection_issue
            
            print("=== í†µí•© API ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ===")
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            print("1. ì—°ê²° í…ŒìŠ¤íŠ¸...")
            if api_module.test_connection():
                print("âœ… ì—°ê²° ì„±ê³µ")
            else:
                print("âŒ ì—°ê²° ì‹¤íŒ¨")
            
            # ìµœì‹  ë°ì´í„° ì¡°íšŒ
            print("\n2. ìµœì‹  ë°ì´í„° ì¡°íšŒ...")
            latest_data = api_module.get_latest_news_data()
            if latest_data:
                print("âœ… ìµœì‹  ë°ì´í„° ì¡°íšŒ ì„±ê³µ")
                for news_type, news_item in latest_data.items():
                    print(f"  - {news_type}: {news_item.get('status_description', 'N/A')}")
            else:
                print("âŒ ìµœì‹  ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
            
            # ìƒíƒœ ìš”ì•½
            print("\n3. ì‹œìŠ¤í…œ ìƒíƒœ ìš”ì•½:")
            status = api_module.get_status_summary()
            print(f"  ì „ì²´ ê±´ê°•ë„: {status['overall_health']}")
            print(f"  ì—°ê²° ìƒíƒœ: {status['connection']['status']}")
            if status['data']:
                print(f"  ë°ì´í„° ìƒíƒœ: {status['data']['overall_status']}")
            print(f"  ìºì‹œ í•­ëª©: {status['cache']['cache_entries']}ê°œ")
            
            print("\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        else:
            print("âŒ API ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
    except ImportError as e:
        print(f"âŒ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("í•„ìš”í•œ ëª¨ë“ˆì´ ì—†ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")