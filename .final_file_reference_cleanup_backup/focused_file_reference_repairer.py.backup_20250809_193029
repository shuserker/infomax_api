#!/usr/bin/env python3
"""
POSCO ì‹œìŠ¤í…œ íŒŒì¼ ì°¸ì¡° ë¬´ê²°ì„± ì§‘ì¤‘ ë³µêµ¬ ë„êµ¬

Task 4: íŒŒì¼ ì°¸ì¡° ë¬´ê²°ì„± ì™„ì „ ë³µêµ¬
- í•µì‹¬ Python íŒŒì¼ì˜ ê¹¨ì§„ import ìˆ˜ì •
- ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ì˜ íŒŒì¼ ì°¸ì¡° ìˆ˜ì •
- ì¤‘ìš” ì„¤ì • íŒŒì¼ì˜ ê²½ë¡œ ì°¸ì¡° ìˆ˜ì •
"""

import os
import re
import json
import shutil
import ast
from pathlib import Path
from typing import Dict, List, Set, Optional
from dataclasses import dataclass
import logging
from datetime import datetime

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class CriticalFileReference:
    """ì¤‘ìš”í•œ íŒŒì¼ ì°¸ì¡° ë¬¸ì œ"""
    source_file: str
    referenced_path: str
    line_number: int
    issue_type: str
    suggested_fix: Optional[str] = None

class FocusedFileReferenceRepairer:
    """ì§‘ì¤‘ì ì¸ íŒŒì¼ ì°¸ì¡° ë³µêµ¬ í´ë˜ìŠ¤"""
    
    def __init__(self, root_path: str = "."):
        self.root_path = Path(root_path).resolve()
        self.critical_issues: List[CriticalFileReference] = []
        self.existing_files: Dict[str, str] = {}
        self.backup_dir = Path(".focused_file_reference_backup")
        
        # í•µì‹¬ íŒŒì¼ë“¤ë§Œ ëŒ€ìƒìœ¼ë¡œ í•¨
        self.critical_files = [
            "file_renaming_system.py",
            "filename_standardizer.py", 
            "naming_convention_manager.py",
            "python_naming_standardizer.py",
            "shell_batch_script_standardizer.py",
            "documentation_standardizer.py",
            "config_data_standardizer.py",
            "system_output_message_standardizer.py",
            "folder_structure_reorganizer.py",
            "naming_standardization_verification_system.py",
            "POSCO_News_250808.py",
            "final_integration_test_system.py",
            "system_functionality_verification.py"
        ]
        
        self._build_file_index()

    def _build_file_index(self):
        """í•µì‹¬ íŒŒì¼ë“¤ì˜ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        logger.info("í•µì‹¬ íŒŒì¼ ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
        
        for file_path in self.root_path.rglob("*.py"):
            if (file_path.is_file() and 
                not file_path.name.startswith('.') and
                not any(exclude in str(file_path) for exclude in ['.git', '__pycache__', 'backup'])):
                
                filename = file_path.name
                stem = file_path.stem
                relative_path = str(file_path.relative_to(self.root_path))
                
                self.existing_files[filename] = relative_path
                self.existing_files[stem] = relative_path

    def scan_critical_references(self) -> List[CriticalFileReference]:
        """í•µì‹¬ íŒŒì¼ë“¤ì˜ ì°¸ì¡° ìŠ¤ìº”"""
        logger.info("í•µì‹¬ íŒŒì¼ ì°¸ì¡° ìŠ¤ìº” ì‹œì‘...")
        
        for critical_file in self.critical_files:
            file_paths = list(self.root_path.rglob(critical_file))
            for file_path in file_paths:
                if file_path.is_file():
                    self._scan_critical_file(file_path)
        
        logger.info(f"ì´ {len(self.critical_issues)}ê°œì˜ í•µì‹¬ ì°¸ì¡° ë¬¸ì œ ë°œê²¬")
        return self.critical_issues

    def _scan_critical_file(self, file_path: Path):
        """í•µì‹¬ íŒŒì¼ ìŠ¤ìº”"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            lines = content.split('\n')
            
            # import ë¬¸ ê²€ì‚¬
            for line_num, line in enumerate(lines, 1):
                if 'import ' in line and not line.strip().startswith('#'):
                    self._check_import_line(line, file_path, line_num)
                
                # íŒŒì¼ ê²½ë¡œ ì°¸ì¡° ê²€ì‚¬
                self._check_file_path_line(line, file_path, line_num)
                
        except Exception as e:
            logger.error(f"í•µì‹¬ íŒŒì¼ ìŠ¤ìº” ì˜¤ë¥˜ {file_path}: {e}")

    def _check_import_line(self, line: str, source_file: Path, line_num: int):
        """import ë¼ì¸ ê²€ì‚¬"""
        # ëª…í™•í•œ ê¹¨ì§„ importë§Œ ì°¾ê¸°
        broken_imports = [
            'test_config.json',
            'posco_news_250808_monitor.log',
            'verify_folder_reorganization.py',
            'glob',
            'datetime'
        ]
        
        for broken_import in broken_imports:
            if broken_import in line:
                suggested_fix = self._get_import_fix(broken_import)
                if suggested_fix:
                    issue = CriticalFileReference(
                        source_file=str(source_file.relative_to(self.root_path)),
                        referenced_path=broken_import,
                        line_number=line_num,
                        issue_type='broken_import',
                        suggested_fix=suggested_fix
                    )
                    self.critical_issues.append(issue)

    def _check_file_path_line(self, line: str, source_file: Path, line_num: int):
        """íŒŒì¼ ê²½ë¡œ ë¼ì¸ ê²€ì‚¬"""
        # ëª…í™•í•œ íŒŒì¼ ê²½ë¡œ íŒ¨í„´
        patterns = [
            r'[\'"]([^\'"\s]+\.py)[\'"]',
            r'[\'"]([^\'"\s]+\.json)[\'"]',
            r'[\'"]([^\'"\s]+\.log)[\'"]'
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, line)
            for match in matches:
                file_ref = match.group(1)
                if not self._file_exists_simple(file_ref) and self._is_fixable(file_ref):
                    suggested_fix = self._get_file_fix(file_ref)
                    if suggested_fix:
                        issue = CriticalFileReference(
                            source_file=str(source_file.relative_to(self.root_path)),
                            referenced_path=file_ref,
                            line_number=line_num,
                            issue_type='missing_file',
                            suggested_fix=suggested_fix
                        )
                        self.critical_issues.append(issue)

    def _get_import_fix(self, broken_import: str) -> Optional[str]:
        """import ìˆ˜ì • ë°©ì•ˆ"""
        fixes = {
            'test_config.json': '',  # ì œê±°
            'posco_news_250808_monitor.log': '',  # ì œê±°
            'verify_folder_reorganization.py': '',  # ì œê±°
            'glob': 'import glob',  # í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
            'datetime': 'from datetime import datetime'  # í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
        }
        return fixes.get(broken_import)

    def _get_file_fix(self, file_ref: str) -> Optional[str]:
        """íŒŒì¼ ê²½ë¡œ ìˆ˜ì • ë°©ì•ˆ"""
        filename = Path(file_ref).name
        
        # ì§ì ‘ ë§¤ì¹­
        if filename in self.existing_files:
            return self.existing_files[filename]
        
        # ìœ ì‚¬í•œ íŒŒì¼ ì°¾ê¸°
        for existing_file, path in self.existing_files.items():
            if (filename.lower() in existing_file.lower() or
                existing_file.lower() in filename.lower()):
                return path
        
        return None

    def _file_exists_simple(self, file_ref: str) -> bool:
        """ê°„ë‹¨í•œ íŒŒì¼ ì¡´ì¬ í™•ì¸"""
        # ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ
        root_path = self.root_path / file_ref
        if root_path.exists():
            return True
        
        # íŒŒì¼ëª…ë§Œìœ¼ë¡œ í™•ì¸
        filename = Path(file_ref).name
        return filename in self.existing_files

    def _is_fixable(self, file_ref: str) -> bool:
        """ìˆ˜ì • ê°€ëŠ¥í•œ ì°¸ì¡°ì¸ì§€ í™•ì¸"""
        # íŠ¹ì • íŒ¨í„´ì€ ì œì™¸
        exclude_patterns = [
            'http://', 'https://', 'file://',
            '__pycache__', '.git/', 'backup',
            '*.', '{', '}', '$'
        ]
        
        for pattern in exclude_patterns:
            if pattern in file_ref:
                return False
        
        return True

    def repair_critical_references(self) -> Dict:
        """í•µì‹¬ ì°¸ì¡° ìˆ˜ë¦¬"""
        logger.info("í•µì‹¬ íŒŒì¼ ì°¸ì¡° ìˆ˜ë¦¬ ì‹œì‘...")
        
        repair_results = []
        
        # íŒŒì¼ë³„ë¡œ ê·¸ë£¹í™”
        files_to_repair = {}
        for issue in self.critical_issues:
            if issue.source_file not in files_to_repair:
                files_to_repair[issue.source_file] = []
            files_to_repair[issue.source_file].append(issue)
        
        # ê° íŒŒì¼ ìˆ˜ë¦¬
        for file_path, issues in files_to_repair.items():
            result = self._repair_file(file_path, issues)
            repair_results.append(result)
        
        logger.info(f"ì´ {len(repair_results)}ê°œ íŒŒì¼ ìˆ˜ë¦¬ ì™„ë£Œ")
        return {
            "repaired_files": len(repair_results),
            "successful_repairs": len([r for r in repair_results if r['success']]),
            "total_changes": sum(len(r['changes']) for r in repair_results if r['success']),
            "results": repair_results
        }

    def _repair_file(self, file_path: str, issues: List[CriticalFileReference]) -> Dict:
        """ê°œë³„ íŒŒì¼ ìˆ˜ë¦¬"""
        full_path = self.root_path / file_path
        changes = []
        
        try:
            # ë°±ì—… ìƒì„±
            self._create_backup(full_path)
            
            # íŒŒì¼ ì½ê¸°
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            # ë¼ì¸ë³„ ìˆ˜ì •
            for issue in sorted(issues, key=lambda x: x.line_number, reverse=True):
                if issue.line_number <= len(lines) and issue.suggested_fix is not None:
                    old_line = lines[issue.line_number - 1]
                    
                    if issue.suggested_fix == '':  # ì œê±°
                        # ë¼ì¸ì„ ì£¼ì„ ì²˜ë¦¬
                        if not old_line.strip().startswith('#'):
                            lines[issue.line_number - 1] = f"# REMOVED: {old_line}"
                            changes.append(f"Line {issue.line_number}: ì œê±° - {issue.referenced_path}")
                    else:  # êµì²´
                        new_line = old_line.replace(issue.referenced_path, issue.suggested_fix)
                        if new_line != old_line:
                            lines[issue.line_number - 1] = new_line
                            changes.append(f"Line {issue.line_number}: {issue.referenced_path} â†’ {issue.suggested_fix}")
            
            # íŒŒì¼ ì“°ê¸°
            if changes:
                with open(full_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines)
            
            return {
                "file_path": file_path,
                "success": True,
                "changes": changes
            }
            
        except Exception as e:
            return {
                "file_path": file_path,
                "success": False,
                "error": str(e),
                "changes": []
            }

    def _create_backup(self, file_path: Path):
        """ë°±ì—… ìƒì„±"""
        try:
            if not self.backup_dir.exists():
                self.backup_dir.mkdir(parents=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = self.backup_dir / f"{file_path.name}.backup_{timestamp}"
            shutil.copy2(file_path, backup_path)
        except Exception as e:
            logger.error(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨ {file_path}: {e}")

    def generate_focused_report(self) -> Dict:
        """ì§‘ì¤‘ ë³´ê³ ì„œ ìƒì„±"""
        report = {
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "summary": {
                "critical_files_scanned": len(self.critical_files),
                "critical_issues_found": len(self.critical_issues),
                "broken_imports": len([i for i in self.critical_issues if i.issue_type == 'broken_import']),
                "missing_files": len([i for i in self.critical_issues if i.issue_type == 'missing_file'])
            },
            "critical_issues": [
                {
                    "source_file": issue.source_file,
                    "referenced_path": issue.referenced_path,
                    "line_number": issue.line_number,
                    "issue_type": issue.issue_type,
                    "suggested_fix": issue.suggested_fix
                }
                for issue in self.critical_issues
            ]
        }
        
        return report

    def save_report(self, report: Dict, filename: str = "focused_file_reference_repair_report.json"):
        """ë³´ê³ ì„œ ì €ì¥"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        logger.info(f"ë³´ê³ ì„œ ì €ì¥: {filename}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ POSCO ì‹œìŠ¤í…œ í•µì‹¬ íŒŒì¼ ì°¸ì¡° ì§‘ì¤‘ ë³µêµ¬ ë„êµ¬")
    print("=" * 60)
    
    repairer = FocusedFileReferenceRepairer()
    
    # 1. í•µì‹¬ íŒŒì¼ ì°¸ì¡° ìŠ¤ìº”
    print("\n1ï¸âƒ£ í•µì‹¬ íŒŒì¼ ì°¸ì¡° ìŠ¤ìº” ì¤‘...")
    critical_issues = repairer.scan_critical_references()
    
    if critical_issues:
        print(f"   âš ï¸  {len(critical_issues)}ê°œì˜ í•µì‹¬ ì°¸ì¡° ë¬¸ì œ ë°œê²¬")
        
        # ë¬¸ì œ ìœ í˜•ë³„ ë¶„ì„
        broken_imports = [i for i in critical_issues if i.issue_type == 'broken_import']
        missing_files = [i for i in critical_issues if i.issue_type == 'missing_file']
        
        print(f"   â€¢ ê¹¨ì§„ import: {len(broken_imports)}ê°œ")
        print(f"   â€¢ ëˆ„ë½ëœ íŒŒì¼: {len(missing_files)}ê°œ")
        
        # 2. í•µì‹¬ ì°¸ì¡° ìˆ˜ë¦¬
        print(f"\n2ï¸âƒ£ {len(critical_issues)}ê°œì˜ í•µì‹¬ ì°¸ì¡° ìˆ˜ë¦¬ ì¤‘...")
        repair_result = repairer.repair_critical_references()
        print(f"   âœ… {repair_result['successful_repairs']}/{repair_result['repaired_files']}ê°œ íŒŒì¼ ìˆ˜ë¦¬ ì™„ë£Œ")
        print(f"   ğŸ“ ì´ {repair_result['total_changes']}ê°œ ë³€ê²½ ì‚¬í•­ ì ìš©")
        
        # 3. ì§‘ì¤‘ ë³´ê³ ì„œ ìƒì„±
        print("\n3ï¸âƒ£ ì§‘ì¤‘ ìˆ˜ë¦¬ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        report = repairer.generate_focused_report()
        report['repair_results'] = repair_result
        repairer.save_report(report)
        print("   âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“Š í•µì‹¬ ìˆ˜ë¦¬ ê²°ê³¼:")
        print(f"   â€¢ ìŠ¤ìº”ëœ í•µì‹¬ íŒŒì¼: {len(repairer.critical_files)}ê°œ")
        print(f"   â€¢ ë°œê²¬ëœ ë¬¸ì œ: {len(critical_issues)}ê°œ")
        print(f"   â€¢ ìˆ˜ë¦¬ëœ íŒŒì¼: {repair_result['successful_repairs']}ê°œ")
        print(f"   â€¢ ì ìš©ëœ ë³€ê²½: {repair_result['total_changes']}ê°œ")
        print(f"   â€¢ ë°±ì—… ë””ë ‰í† ë¦¬: {repairer.backup_dir}")
        
        # ì£¼ìš” ìˆ˜ë¦¬ ë‚´ìš©
        if repair_result['successful_repairs'] > 0:
            print(f"\nğŸ‰ ì£¼ìš” ìˆ˜ë¦¬ ì„±ê³¼:")
            for result in repair_result['results']:
                if result['success'] and result['changes']:
                    print(f"   â€¢ {result['file_path']}: {len(result['changes'])}ê°œ ìˆ˜ì •")
    else:
        print("   âœ… í•µì‹¬ íŒŒì¼ ì°¸ì¡° ë¬¸ì œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    
    return len(critical_issues) == 0 or repair_result.get('successful_repairs', 0) > 0

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)