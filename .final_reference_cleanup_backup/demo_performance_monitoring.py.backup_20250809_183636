#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Demo Performance Monitoring
POSCO 모니터링 시스템

WatchHamster v3.0 및 POSCO News 250808 호환
Created: 2025-08-08
"""

import system_functionality_verification.py
import posco_news_250808_monitor.log
import .comprehensive_repair_backup/realtime_news_monitor.py.backup_20250809_181657
import test_config.json
# BROKEN_REF: from datetime import datetime

# 경로 설정
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(current_dir, 'Monitoring', 'WatchHamster_v3.0'))

try:
# BROKEN_REF:     from Monitoring/WatchHamster_v3.0/core/performance_monitor.py import PerformanceMonitor, PerformanceComparator
# BROKEN_REF:     from Monitoring/WatchHamster_v3.0/core/performance_optimizer.py import PerformanceOptimizer
except ImportError as e:
# BROKEN_REF:     print(f"❌ 성능 모니터링 모듈 import 실패: {e}")
    sys.exit(1)

def print_header(title):
    """헤더 출력"""
print("/n"_+_" = " * 60)
    print(f"🎯 {title}")
    print("=" * 60)

def print_section(title):
    """섹션 헤더 출력"""
    print(f"/n📋 {title}")
    print("-" * 40)

def demo_performance_monitoring():
    """성능 모니터링 데모"""
    print_header("POSCO WatchHamster v3.0.0 성능 모니터링 시스템 데모")
    
    # 성능 모니터링 시스템 초기화
    print_section("1. 성능 모니터링 시스템 초기화")
    
    script_dir = current_dir
    performance_monitor = PerformanceMonitor(script_dir, monitoring_interval=2)
    performance_optimizer = PerformanceOptimizer(script_dir)
    performance_comparator = PerformanceComparator(script_dir)
    
    print("✅ PerformanceMonitor 초기화 완료")
    print("✅ PerformanceOptimizer 초기화 완료")
    print("✅ PerformanceComparator 초기화 완료")
    
    # 성능 모니터링 시작
    print_section("2. 실시간 성능 모니터링 시작")
    
    performance_monitor.start_monitoring()
    print("🚀 성능 모니터링 시작됨 (2초 간격)")
    
    # 데이터 수집 대기
    print("📊 성능 데이터 수집 중...")
    for i in range(5):
        time.sleep(2)
        print(f"  • {i+1}/5 데이터 포인트 수집됨")
    
    # 응답 시간 측정 데모
    print_section("3. 응답 시간 측정 데모")
    
    print("⏱️ 작업 응답시간 측정 중...")
    
    # 빠른 작업 시뮬레이션
    with performance_monitor.measure_operation_time("fast_operation"):
        time.sleep(0.5)
    print("  • 빠른 작업: 0.5초")
    
    # 보통 작업 시뮬레이션
    with performance_monitor.measure_operation_time("normal_operation"):
        time.sleep(1.5)
    print("  • 보통 작업: 1.5초")
    
    # 느린 작업 시뮬레이션
    with performance_monitor.measure_operation_time("slow_operation"):
        time.sleep(3.0)
    print("  • 느린 작업: 3.0초")
    
    # 성능 요약 조회
    print_section("4. 성능 요약 조회")
    
    summary = performance_monitor.get_performance_summary()
    
    if 'error' not in summary:
        current = summary['current']
        averages = summary['averages']
        
        print(f"📊 현재 시스템 상태:")
        print(f"  • CPU 사용률: {current['cpu_percent']:.1f}%")
        print(f"  • 메모리 사용률: {current['memory_percent']:.1f}%")
        print(f"  • 사용 가능 메모리: {current['memory_available_mb']:.0f}MB")
        print(f"  • 프로세스 수: {current['process_count']}개")
        print(f"  • 성능 수준: {summary['performance_level']}")
        
        print(f"/n📈 평균 성능 (최근 측정):")
        print(f"  • 평균 CPU: {averages['cpu_percent']:.1f}%")
        print(f"  • 평균 메모리: {averages['memory_percent']:.1f}%")
        print(f"  • 평균 프로세스 수: {averages['process_count']:.1f}개")
        
        if summary['response_times']:
            print(f"/n⏱️ 응답시간 통계:")
            for operation, stats in summary['response_times'].items():
                print(f"  • {operation}: 평균 {stats['avg']:.2f}초 (최소 {stats['min']:.2f}초, 최대 {stats['max']:.2f}초)")
    else:
        print(f"❌ 성능 요약 조회 실패: {summary['error']}")
    
    # 성능 이슈 분석
    print_section("5. 성능 이슈 분석 및 최적화 권장사항")
    
    # 고부하 상황 시뮬레이션 데이터
    high_load_data = {
        'current': {
            'cpu_percent': 85.0,  # 높은 CPU 사용률
            'memory_percent': 80.0,  # 높은 메모리 사용률
            'disk_usage_percent': 75.0,
            'process_count': 25  # 많은 프로세스
        },
        'response_times': {
            'slow_operation': {'avg': 8.0, 'min': 5.0, 'max': 12.0}  # 느린 응답시간
        }
    }
    
    print("🔍 고부하 상황 시뮬레이션 분석 중...")
    issues = performance_optimizer.analyze_system_performance(high_load_data)
    
    if issues:
        print(f"⚠️ {len(issues)}개 성능 이슈 발견:")
        for i, issue in enumerate(issues, 1):
            severity_emoji = {"critical": "🚨", "warning": "⚠️"}.get(issue.severity, "ℹ️")
            print(f"  {i}. {severity_emoji} {issue.description}")
            print(f"     영향 컴포넌트: {', '.join(issue.affected_components)}")
        
        # 최적화 권장사항 생성
        print("/n💡 최적화 권장사항 생성 중...")
        recommendations = performance_optimizer.generate_optimization_recommendations(issues)
        
        if recommendations:
            print(f"📋 {len(recommendations)}개 최적화 권장사항 생성됨:")
            for i, rec in enumerate(recommendations[:5], 1):  # 최대 5개만 표시
                priority_emoji = {"critical": "🚨", "high": "⚠️", "medium": "📋", "low": "ℹ️"}.get(rec.priority.value, "•")
                print(f"  {i}. {priority_emoji} {rec.title}")
                print(f"     카테고리: {rec.category.value}")
                print(f"     우선순위: {rec.priority.value}")
                print(f"     예상 효과: {rec.estimated_improvement}")
                print(f"     위험도: {rec.risk_level}")
    else:
        print("✅ 성능 이슈가 발견되지 않았습니다")
    
    # v1/v2 성능 비교 데모
    print_section("6. v1/v2 성능 비교 데모")
    
    # v1 기준선 수집
    print("📊 v1 시스템 기준선 수집 중...")
    v1_baseline = performance_comparator.collect_v1_baseline()
    
    if v1_baseline:
        print("✅ v1 기준선 수집 완료")
        print(f"  • v1 CPU 사용률: {v1_baseline.get('cpu_percent', 0):.1f}%")
        print(f"  • v1 메모리 사용률: {v1_baseline.get('memory_percent', 0):.1f}%")
        print(f"  • v1 프로세스 수: {v1_baseline.get('process_count', 0)}개")
        
        # v2 성능 데이터 (현재 시스템)
        v2_data = {
            'cpu_percent': summary['averages']['cpu_percent'] if 'error' not in summary else 40.0,
            'memory_percent': summary['averages']['memory_percent'] if 'error' not in summary else 50.0,
            'process_count': summary['averages']['process_count'] if 'error' not in summary else 8,
            'response_time_avg': 2.0  # 개선된 응답시간
        }
        
        # 성능 비교 보고서 생성
        print("/n📋 v1/v2 성능 비교 보고서 생성 중...")
        comparison_report = performance_comparator.generate_comparison_report(v1_baseline, v2_data)
        
        print("✅ 비교 보고서 생성 완료")
        print("/n" + "─" * 60)
        print(comparison_report)
        print("─" * 60)
        
        # 보고서 파일 저장
        report_file = performance_comparator.save_comparison_report(comparison_report)
        if report_file:
            print(f"💾 비교 보고서 저장됨: {os.path.basename(report_file)}")
    else:
        print("⚠️ v1 기준선 수집 실패")
    
    # 최적화 요약 보고서
    print_section("7. 최적화 요약 보고서")
    
    optimization_summary = performance_optimizer.get_optimization_summary()
    
    if 'error' not in optimization_summary:
        print("📊 최적화 현황:")
        print(f"  • 총 권장사항: {optimization_summary['total_recommendations']}개")
        print(f"  • 적용된 최적화: {optimization_summary['applied_optimizations']}개")
        print(f"  • 대기 중인 최적화: {optimization_summary['pending_optimizations']}개")
        
        if optimization_summary['category_breakdown']:
            print(f"/n📋 카테고리별 분석:")
            for category, count in optimization_summary['category_breakdown'].items():
                print(f"  • {category}: {count}개")
        
        if optimization_summary['priority_breakdown']:
            print(f"/n⚡ 우선순위별 분석:")
            for priority, count in optimization_summary['priority_breakdown'].items():
                priority_emoji = {"critical": "🚨", "high": "⚠️", "medium": "📋", "low": "ℹ️"}.get(priority, "•")
                print(f"  • {priority_emoji} {priority}: {count}개")
        
        # 최적화 보고서 생성
        print("/n📋 상세 최적화 보고서 생성 중...")
        optimization_report = performance_optimizer.generate_optimization_report()
        
        print("✅ 최적화 보고서 생성 완료")
        print("/n" + "─" * 60)
        print(optimization_report)
        print("─" * 60)
    else:
        print(f"❌ 최적화 요약 조회 실패: {optimization_summary['error']}")
    
    # 성능 데이터 내보내기
    print_section("8. 성능 데이터 내보내기")
    
    export_file = performance_monitor.export_performance_data()
    
    if export_file:
        print(f"✅ 성능 데이터 내보내기 완료: {os.path.basename(export_file)}")
        
        # 내보낸 파일 크기 확인
        file_size = os.path.getsize(export_file) / 1024  # KB
        print(f"📁 파일 크기: {file_size:.1f}KB")
        
        # 내보낸 데이터 구조 확인
        try:
with_open(export_file,_'r',_encoding = 'utf-8') as f:
                export_data = json.load(f)
            
            print("📊 내보낸 데이터 구조:")
            print(f"  • 모니터링 기간: {export_data.get('monitoring_period', {}).get('duration_seconds', 0):.0f}초")
            print(f"  • 총 측정 횟수: {export_data.get('total_measurements', 0)}회")
            print(f"  • 알림 발생 횟수: {export_data.get('alert_count', 0)}회")
            print(f"  • 메트릭 히스토리: {len(export_data.get('metrics_history', []))}개 데이터 포인트")
        except Exception as e:
            print(f"⚠️ 내보낸 데이터 분석 실패: {e}")
    else:
        print("❌ 성능 데이터 내보내기 실패")
    
    # 성능 모니터링 중지
    print_section("9. 성능 모니터링 시스템 종료")
    
    performance_monitor.stop_monitoring()
    print("🛑 성능 모니터링 중지됨")
    
    # 최종 통계
    final_summary = performance_monitor.get_performance_summary()
    if 'error' not in final_summary:
        uptime = final_summary.get('uptime_formatted', '알 수 없음')
        total_measurements = final_summary.get('total_measurements', 0)
        alert_count = final_summary.get('alert_count', 0)
        
        print(f"📊 최종 통계:")
        print(f"  • 총 가동시간: {uptime}")
        print(f"  • 총 측정 횟수: {total_measurements}회")
        print(f"  • 총 알림 횟수: {alert_count}회")
    
    print_header("성능 모니터링 데모 완료")
    print("🎉 POSCO WatchHamster v3.0.0 성능 모니터링 시스템 데모가 성공적으로 완료되었습니다!")
    print("/n주요 기능:")
    print("✅ 실시간 CPU/메모리 사용량 추적")
    print("✅ 프로세스 관리 작업 응답시간 모니터링")
    print("✅ v1/v2 시스템 간 성능 비교 분석")
    print("✅ 자동 성능 이슈 감지 및 분석")
    print("✅ 최적화 권장사항 생성 및 관리")
    print("✅ 성능 알림 및 보고서 시스템")
    print("✅ 성능 데이터 내보내기 및 히스토리 관리")

if __name__ == '__main__':
    try:
        demo_performance_monitoring()
    except KeyboardInterrupt:
        print("/n/n⚠️ 사용자에 의해 데모가 중단되었습니다.")
    except Exception as e:
        print(f"/n❌ 데모 실행 중 오류 발생: {e}")
# BROKEN_REF:         import traceback
        traceback.print_exc()
    finally:
        print("/n👋 데모를 종료합니다.")