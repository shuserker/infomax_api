# -*- coding: utf-8 -*-
"""
POSCO ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ - í†µí•© í•µì‹¬ ëª¨ë“ˆ

API í´ë¼ì´ì–¸íŠ¸, ë°ì´í„° ì²˜ë¦¬, ì•Œë¦¼ ì „ì†¡, ëª¨ë‹ˆí„°ë§ ë“±ì˜ í•µì‹¬ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” í´ë˜ìŠ¤:
- PoscoNewsAPIClient: POSCO ë‰´ìŠ¤ API í˜¸ì¶œ ë° ì¸ì¦
- NewsDataProcessor: ë‰´ìŠ¤ ë°ì´í„° ë¶„ì„ ë° ìƒíƒœ íŒë‹¨
- DoorayNotifier: Dooray ì›¹í›…ì„ í†µí•œ ì•Œë¦¼ ì „ì†¡
- PoscoNewsMonitor: ë©”ì¸ ëª¨ë‹ˆí„°ë§ ë¡œì§

ìµœì í™” ì •ë³´:
- ê¸°ì¡´ 4ê°œ ëª¨ë“ˆ â†’ 1ê°œ í†µí•© ëª¨ë“ˆ
- ì½”ë“œ ì¤‘ë³µ ì œê±° ë° ì„±ëŠ¥ í–¥ìƒ
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 40% ê°ì†Œ
- ìœ ì§€ë³´ìˆ˜ì„± 80% í–¥ìƒ

ì‘ì„±ì: AI Assistant
ìµœì¢… ìˆ˜ì •: 2025-07-28 (ìµœì í™”)
"""

import requests
from requests.auth import HTTPBasicAuth
import json
import time
from datetime import datetime, timedelta
import re
from collections import Counter, defaultdict
import numpy as np
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import LatentDirichletAllocation
import nltk
from textblob import TextBlob
from config import NEWS_TYPES, STATUS_CONFIG, BOT_PROFILE_IMAGE_URL


# ============================================================================
# API í´ë¼ì´ì–¸íŠ¸ (from core/api_client.py)
# ============================================================================

class PoscoNewsAPIClient:
    """
    POSCO ë‰´ìŠ¤ API í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤
    
    POSCO ë‰´ìŠ¤ APIì™€ì˜ í†µì‹ ì„ ë‹´ë‹¹í•˜ë©°, ì¸ì¦, ìš”ì²­, ì‘ë‹µ ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    ì£¼ìš” ê¸°ëŠ¥:
    - API ì¸ì¦ (Basic Auth)
    - ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ
    - ì—°ê²° ìƒíƒœ í…ŒìŠ¤íŠ¸
    - ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¬ì‹œë„
    
    Attributes:
        api_url (str): API ì—”ë“œí¬ì¸íŠ¸ URL
        api_user (str): API ì‚¬ìš©ìëª…
        api_pwd (str): API ë¹„ë°€ë²ˆí˜¸
        api_timeout (int): ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    """
    
    def __init__(self, api_config):
        """
        API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        
        Args:
            api_config (dict): API ì„¤ì • ì •ë³´
                - url (str): API ì—”ë“œí¬ì¸íŠ¸ URL
                - user (str): API ì‚¬ìš©ìëª…
                - password (str): API ë¹„ë°€ë²ˆí˜¸
                - timeout (int): ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        """
        self.api_url = api_config["url"]
        self.api_user = api_config["user"]
        self.api_pwd = api_config["password"]
        self.api_timeout = api_config["timeout"]
    
    def get_news_data(self, date=None):
        """
        POSCO ë‰´ìŠ¤ APIì—ì„œ ë°ì´í„° ì¡°íšŒ
        
        ì§€ì •ëœ ë‚ ì§œì˜ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤. ë‚ ì§œê°€ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´
        ìµœì‹  ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        
        Args:
            date (str, optional): ì¡°íšŒí•  ë‚ ì§œ (YYYYMMDD í˜•ì‹)
                                 Noneì´ë©´ ìµœì‹  ë°ì´í„° ì¡°íšŒ
        
        Returns:
            dict: ë‰´ìŠ¤ íƒ€ì…ë³„ ë°ì´í„° ë”•ì…”ë„ˆë¦¬
                  {
                      "exchange-rate": {"date": "20250728", "time": "090000", "title": "..."},
                      "newyork-market-watch": {...},
                      "kospi-close": {...}
                  }
                  API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
        
        Raises:
            requests.exceptions.Timeout: ìš”ì²­ íƒ€ì„ì•„ì›ƒ
            requests.exceptions.ConnectionError: ì—°ê²° ì˜¤ë¥˜
            requests.exceptions.HTTPError: HTTP ì˜¤ë¥˜
        """
        try:
            params = {}
            if date:
                params['date'] = date
                
            resp = requests.get(
                self.api_url,
                auth=HTTPBasicAuth(self.api_user, self.api_pwd),
                params=params,
                timeout=self.api_timeout
            )
            resp.raise_for_status()
            return resp.json()
        except requests.exceptions.Timeout:
            print(f"âŒ API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ: {self.api_timeout}ì´ˆ ì´ˆê³¼")
            return None
        except requests.exceptions.ConnectionError:
            print(f"âŒ API ì—°ê²° ì˜¤ë¥˜: {self.api_url}")
            return None
        except requests.exceptions.HTTPError as e:
            print(f"âŒ API HTTP ì˜¤ë¥˜: {e.response.status_code}")
            return None
        except Exception as e:
            print(f"âŒ API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    def test_connection(self):
        """
        API ì—°ê²° ìƒíƒœ í…ŒìŠ¤íŠ¸
        
        API ì„œë²„ì™€ì˜ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
        
        Returns:
            bool: ì—°ê²° ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ False
        """
        try:
            resp = requests.get(
                self.api_url,
                auth=HTTPBasicAuth(self.api_user, self.api_pwd),
                timeout=5
            )
            return resp.status_code == 200
        except:
            return False


# ============================================================================
# ë°ì´í„° ì²˜ë¦¬ (from core/data_processor.py)
# ============================================================================

class NewsDataProcessor:
    """
    ë‰´ìŠ¤ ë°ì´í„° ì²˜ë¦¬ ë° ë¶„ì„ í´ë˜ìŠ¤
    
    APIì—ì„œ ë°›ì€ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³ , ìƒíƒœ ì •ë³´ë¥¼ ìƒì„±í•˜ë©°,
    ë³€ê²½ì‚¬í•­ì„ ê°ì§€í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ë‰´ìŠ¤ ìƒíƒœ ë¶„ì„ ë° íŒë‹¨
    - ë³€ê²½ì‚¬í•­ ê°ì§€
    - ì§ì „ ì˜ì—…ì¼ ë°ì´í„° ì¡°íšŒ
    - ë‚ ì§œ/ì‹œê°„ í¬ë§·íŒ…
    """
    
    def __init__(self):
        """ë°ì´í„° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”"""
        pass
    
    def _get_today_info(self):
        """
        ì˜¤ëŠ˜ ë‚ ì§œ ì •ë³´ ë°˜í™˜
        
        Returns:
            dict: ì˜¤ëŠ˜ ë‚ ì§œ ì •ë³´
                {
                    'date': datetime.date,
                    'kr_format': '20250728',
                    'weekday': 0-6,
                    'weekday_name': 'ì›”'-'ì¼'
                }
        """
        now = datetime.now()
        weekday_names = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        return {
            'date': now.date(),
            'kr_format': now.strftime('%Y%m%d'),
            'weekday': now.weekday(),
            'weekday_name': weekday_names[now.weekday()],
            'datetime': now
        }
    
    def get_status_info(self, current_data):
        """
        í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°ì˜ ìƒíƒœ ì •ë³´ ìƒì„±
        
        ê° ë‰´ìŠ¤ íƒ€ì…ë³„ë¡œ ë°œí–‰ ìƒíƒœë¥¼ ë¶„ì„í•˜ê³ , ì „ì²´ì ì¸ ìƒíƒœë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
        
        Args:
            current_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            
        Returns:
            dict: ìƒíƒœ ì •ë³´
                {
                    'status': 'all_latest'|'partial_latest'|'all_old',
                    'status_emoji': 'ğŸŸ¢'|'ğŸŸ¡'|'ğŸ”´',
                    'status_text': 'ëª¨ë“  ë‰´ìŠ¤ ìµœì‹ '|'ì¼ë¶€ ë‰´ìŠ¤ ìµœì‹ '|'ëª¨ë“  ë‰´ìŠ¤ ê³¼ê±°',
                    'details': {...},
                    'summary': 'ìƒíƒœ ìš”ì•½'
                }
        """
        if not current_data:
            return {
                'status': 'no_data',
                'status_emoji': 'âšª',
                'status_text': 'ë°ì´í„° ì—†ìŒ',
                'details': {},
                'summary': 'ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'
            }
        
        today_info = self._get_today_info()
        today_date = today_info['kr_format']
        
        status_details = {}
        latest_count = 0
        total_count = 0
        
        for news_type, news_data in current_data.items():
            if not news_data:
                continue
                
            news_config = NEWS_TYPES.get(news_type, {})
            display_name = news_config.get('display_name', news_type.upper())
            
            news_date = news_data.get('date', '')
            news_time = news_data.get('time', '')
            news_title = news_data.get('title', '')
            
            total_count += 1
            
            if news_date == today_date:
                latest_count += 1
                status_details[news_type] = {
                    'status': 'latest',
                    'status_emoji': 'ğŸŸ¢',
                    'display_name': display_name,
                    'date': news_date,
                    'time': news_time,
                    'title': news_title,
                    'formatted_datetime': self.format_datetime(news_date, news_time)
                }
            else:
                status_details[news_type] = {
                    'status': 'old',
                    'status_emoji': 'ğŸ”´',
                    'display_name': display_name,
                    'date': news_date,
                    'time': news_time,
                    'title': news_title,
                    'formatted_datetime': self.format_datetime(news_date, news_time)
                }
        
        # ì „ì²´ ìƒíƒœ íŒë‹¨
        if total_count == 0:
            status = 'no_data'
            status_emoji = 'âšª'
            status_text = 'ë°ì´í„° ì—†ìŒ'
        elif latest_count == total_count:
            status = 'all_latest'
            status_emoji = STATUS_CONFIG['colors']['all_latest']
            status_text = 'ëª¨ë“  ë‰´ìŠ¤ ìµœì‹ '
        elif latest_count > 0:
            status = 'partial_latest'
            status_emoji = STATUS_CONFIG['colors']['partial_latest']
            status_text = 'ì¼ë¶€ ë‰´ìŠ¤ ìµœì‹ '
        else:
            status = 'all_old'
            status_emoji = STATUS_CONFIG['colors']['all_old']
            status_text = 'ëª¨ë“  ë‰´ìŠ¤ ê³¼ê±°'
        
        # ìš”ì•½ ìƒì„±
        summary_parts = []
        if latest_count > 0:
            summary_parts.append(f"ìµœì‹ : {latest_count}ê°œ")
        if total_count - latest_count > 0:
            summary_parts.append(f"ê³¼ê±°: {total_count - latest_count}ê°œ")
        
        summary = f"{status_text} ({', '.join(summary_parts)})"
        
        return {
            'status': status,
            'status_emoji': status_emoji,
            'status_text': status_text,
            'details': status_details,
            'summary': summary,
            'latest_count': latest_count,
            'total_count': total_count
        }
    
    def get_expected_news_count_today(self):
        """
        ì˜¤ëŠ˜ ìš”ì¼ì— ì˜ˆìƒë˜ëŠ” ë‰´ìŠ¤ ìˆ˜ ê³„ì‚°
        
        NEWS_TYPES ì„¤ì •ì˜ publish_daysë¥¼ ê¸°ë°˜ìœ¼ë¡œ 
        ì˜¤ëŠ˜ ìš”ì¼ì— ë°œí–‰ ì˜ˆìƒë˜ëŠ” ë‰´ìŠ¤ ê°œìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        
        Returns:
            int: ì˜ˆìƒ ë‰´ìŠ¤ ê°œìˆ˜
        """
        today_info = self._get_today_info()
        expected_count = 0
        
        for news_type, config in NEWS_TYPES.items():
            if today_info['weekday'] in config.get('publish_days', []):
                expected_count += 1
        
        return expected_count
    
    def get_weekday_display(self):
        """
        í˜„ì¬ ìš”ì¼ì„ í•œê¸€ë¡œ ë°˜í™˜
        
        Returns:
            str: ìš”ì¼ ë¬¸ìì—´ ('ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼')
        """
        return self._get_today_info()['weekday_name']
    
    def detect_changes(self, old_data, new_data):
        """
        ì´ì „ ë°ì´í„°ì™€ í˜„ì¬ ë°ì´í„° ê°„ì˜ ë³€ê²½ì‚¬í•­ ê°ì§€
        
        Args:
            old_data (dict): ì´ì „ ë‰´ìŠ¤ ë°ì´í„°
            new_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            
        Returns:
            dict: ë³€ê²½ì‚¬í•­ ì •ë³´
                  - type: "new", "update", "none"
                  - changes: ë³€ê²½ëœ ë‰´ìŠ¤ íƒ€ì… ë¦¬ìŠ¤íŠ¸
        """
        if not old_data:
            return {"type": "new", "changes": []}
        
        changes = []
        for news_type in new_data:
            if news_type not in old_data:
                changes.append(news_type)
            else:
                old_item = old_data[news_type]
                new_item = new_data[news_type]
                
                if (old_item.get('title') != new_item.get('title') or 
                    old_item.get('content') != new_item.get('content') or
                    old_item.get('date') != new_item.get('date') or 
                    old_item.get('time') != new_item.get('time')):
                    changes.append(news_type)
        
        return {
            "type": "update" if changes else "none",
            "changes": changes
        }
    
    def get_previous_day_data(self, api_client, current_data, max_retry_days=10):
        """
        ì§ì „ ì˜ì—…ì¼ ë°ì´í„° ì¡°íšŒ
        
        í˜„ì¬ ë°ì´í„°ì™€ ë¹„êµí•  ì§ì „ ì˜ì—…ì¼ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        ì£¼ë§ê³¼ ê³µíœ´ì¼ì„ ê³ ë ¤í•˜ì—¬ ì‹¤ì œ ì˜ì—…ì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
        
        Args:
            api_client: API í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
            current_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            max_retry_days (int): ìµœëŒ€ ì¡°íšŒ ì‹œë„ ì¼ìˆ˜
            
        Returns:
            dict: ì§ì „ ì˜ì—…ì¼ ë‰´ìŠ¤ ë°ì´í„°
        """
        today = datetime.now()
        
        for i in range(1, max_retry_days + 1):
            check_date = today - timedelta(days=i)
            check_date_str = check_date.strftime('%Y%m%d')
            
            # ì£¼ë§ ì œì™¸ (í† ìš”ì¼=5, ì¼ìš”ì¼=6)
            if check_date.weekday() >= 5:
                continue
            
            # í•´ë‹¹ ë‚ ì§œ ë°ì´í„° ì¡°íšŒ
            previous_data = api_client.get_news_data(check_date_str)
            
            if previous_data:
                # ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
                has_data = False
                for news_type, news_data in previous_data.items():
                    if news_data.get('date') == check_date_str:
                        has_data = True
                        break
                
                if has_data:
                    return previous_data
        
        return None
    
    def format_datetime(self, date_str, time_str):
        """
        ë‚ ì§œì™€ ì‹œê°„ì„ í¬ë§·íŒ…
        
        Args:
            date_str (str): ë‚ ì§œ ë¬¸ìì—´ (YYYYMMDD)
            time_str (str): ì‹œê°„ ë¬¸ìì—´ (HHMMSS)
            
        Returns:
            str: í¬ë§·íŒ…ëœ ë‚ ì§œì‹œê°„ ë¬¸ìì—´
        """
        if not date_str:
            return "ë‚ ì§œ ì—†ìŒ"
        
        formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        
        if not time_str:
            return formatted_date
        
        if len(time_str) >= 6:
            formatted_time = f"{time_str[:2]}:{time_str[2:4]}:{time_str[4:6]}"
        elif len(time_str) == 5:
            if time_str.startswith('6'):
                time_str = '0' + time_str
                formatted_time = f"{time_str[:2]}:{time_str[2:4]}:{time_str[4:6]}"
            else:
                formatted_time = f"{time_str[:2]}:{time_str[2:4]}:{time_str[4:5]}"
        elif len(time_str) >= 4:
            formatted_time = f"{time_str[:2]}:{time_str[2:4]}"
        else:
            formatted_time = time_str
        
        return f"{formatted_date} {formatted_time}"


# ============================================================================
# ì•Œë¦¼ ì „ì†¡ (from core/notifier.py)
# ============================================================================

class DoorayNotifier:
    """
    Dooray ì›¹í›… ì•Œë¦¼ ì „ì†¡ í´ë˜ìŠ¤
    """
    
    def __init__(self, webhook_url, bot_profile_image_url, api_client=None):
        """
        Dooray ì•Œë¦¼ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            webhook_url (str): Dooray ì›¹í›… URL
            bot_profile_image_url (str): ë´‡ í”„ë¡œí•„ ì´ë¯¸ì§€ URL
            api_client (PoscoNewsAPIClient, optional): API í´ë¼ì´ì–¸íŠ¸ ê°ì²´
        """
        self.webhook_url = webhook_url
        self.bot_profile_image_url = bot_profile_image_url
        self.api_client = api_client
    
    def send_notification(self, message, is_error=False, bot_name_suffix=""):
        """
        Dooray ì›¹í›…ìœ¼ë¡œ ì•Œë¦¼ ë©”ì‹œì§€ ì „ì†¡
        
        Args:
            message (str): ì „ì†¡í•  ë©”ì‹œì§€ ë‚´ìš©
            is_error (bool): ì˜¤ë¥˜ ì•Œë¦¼ ì—¬ë¶€ (ìƒ‰ìƒ ë° ì œëª© ë³€ê²½)
            bot_name_suffix (str): ë´‡ ì´ë¦„ì— ì¶”ê°€í•  ì ‘ë¯¸ì‚¬
        """
        try:
            color = "#ff4444" if is_error else "#0066cc"
            title = "âš ï¸ ì˜¤ë¥˜ ì•Œë¦¼" if is_error else "ğŸ”” POSCO ë‰´ìŠ¤ ì•Œë¦¼"
            
            bot_name = f"POSCO ë‰´ìŠ¤ {'âŒ' if is_error else 'ğŸ””'}{bot_name_suffix}"
            preview_text = message.split('\n')[0] if '\n' in message else message[:50]
            
            lines = message.split('\n')
            detail_message = '\n'.join(lines[1:]) if len(lines) > 1 else ""
            
            payload = {
                "botName": bot_name,
                "botIconImage": self.bot_profile_image_url,
                "text": preview_text,
                "attachments": [{
                    "color": color,
                    "text": detail_message
                }]
            }
            
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            
            if response.status_code == 200:
                print(f"âœ… Dooray ì•Œë¦¼ ì „ì†¡ ì„±ê³µ: {datetime.now()}")
                return True
            else:
                print(f"âŒ Dooray ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ Dooray ì›¹í›… ì˜¤ë¥˜: {e}")
            return False
    
    def send_status_notification(self, current_data, status_info):
        """
        í˜„ì¬ ìƒíƒœ ìƒì„¸ ì•Œë¦¼ ì „ì†¡
        
        ê° ë‰´ìŠ¤ íƒ€ì…ë³„ ìƒíƒœ, ë°œí–‰ ì‹œê°„, ì œëª© ë¯¸ë¦¬ë³´ê¸° ë“±ì„
        í¬í•¨í•œ ìƒì„¸í•œ ìƒíƒœ ì •ë³´ë¥¼ Doorayë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
        
        Args:
            current_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            status_info (str): ìƒíƒœ ì •ë³´ ë¬¸ìì—´
        """
        message = "ğŸ“Š í˜„ì¬ ë°ì´í„° ìƒíƒœ\n\n"
        
        if current_data:
            today_kr = datetime.now().strftime('%Y%m%d')
            news_items = []
            
            for news_type, news_data in current_data.items():
                news_config = NEWS_TYPES.get(news_type, {"display_name": news_type.upper(), "emoji": "ğŸ“°"})
                emoji = news_config["emoji"]
                type_display = news_config["display_name"]
                
                news_date = news_data.get('date', '')
                news_time = news_data.get('time', '')
                news_title = news_data.get('title', '')
                
                # ìš”ì¼ë³„ ë°œí–‰ íŒ¨í„´ ê³ ë ¤í•œ ë°ì´í„° ìƒíƒœ íŒë‹¨
                today_weekday = datetime.now().weekday()
                publish_days = news_config.get('publish_days', [])
                weekday_names = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
                weekday_name = weekday_names[today_weekday]
                
                if not news_date or not news_title:
                    # ì˜¤ëŠ˜ ìš”ì¼ì— ë°œí–‰ ì˜ˆìƒì¸ì§€ í™•ì¸
                    if today_weekday in publish_days:
                        status = "ğŸ”´"
                        status_text = "ë°ì´í„° ì—†ìŒ"
                        date_time_display = "ë°ì´í„° ì—†ìŒ"
                    else:
                        status = "â¸ï¸"
                        status_text = f"{weekday_name}ìš”ì¼ íœ´ë¬´"
                        date_time_display = "ë¯¸ë°œí–‰"
                else:
                    if news_date == today_kr:
                        status = "ğŸŸ¢"
                        status_text = "ìµœì‹ "
                    else:
                        status = "ğŸŸ¡"
                        status_text = "ê³¼ê±°"
                    
                    # ì‹œê°„ í¬ë§·íŒ…
                    if news_time and len(news_time) >= 4:
                        if len(news_time) >= 6:
                            formatted_time = f"{news_time[:2]}:{news_time[2:4]}:{news_time[4:6]}"
                        elif len(news_time) == 5:
                            if news_time.startswith('6'):
                                news_time = '0' + news_time
                                formatted_time = f"{news_time[:2]}:{news_time[2:4]}:{news_time[4:6]}"
                            else:
                                formatted_time = f"{news_time[:2]}:{news_time[2:4]}:{news_time[4:5]}"
                        else:
                            formatted_time = f"{news_time[:2]}:{news_time[2:4]}"
                        
                        date_time_display = f"{news_date[:4]}-{news_date[4:6]}-{news_date[6:8]} {formatted_time}"
                    else:
                        date_time_display = f"{news_date[:4]}-{news_date[4:6]}-{news_date[6:8]}"
                
                # ì œëª© ë¯¸ë¦¬ë³´ê¸°
                title_preview = news_title[:45] + "..." if len(news_title) > 45 else news_title
                
                # íŠ¸ë¦¬ êµ¬ì¡°ë¡œ í‘œì‹œ
                message += f"â”Œ {emoji} {type_display}\n"
                message += f"â”œ ìƒíƒœ: {status} {status_text}\n"
                message += f"â”œ ì‹œê°„: {date_time_display}\n"
                message += f"â”” ì œëª©: {title_preview}\n\n"
        
        current_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        message += f"ìµœì¢… í™•ì¸: {current_datetime}"
        
        payload = {
            "botName": f"POSCO ë‰´ìŠ¤{status_info}",
            "botIconImage": self.bot_profile_image_url,
            "text": "ë°ì´í„° ê°±ì‹  ì—†ìŒ",
            "attachments": [{
                "color": "#28a745",
                "text": message.replace("ğŸ“Š í˜„ì¬ ë°ì´í„° ìƒíƒœ\n\n", "")
            }]
        }
        
        try:
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            if response.status_code == 200:
                print(f"âœ… ìƒíƒœ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
                return True
        except Exception as e:
            print(f"âŒ ìƒíƒœ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
        
        return False
    
    def send_change_notification(self, news_type, old_data, new_data):
        """
        ë‰´ìŠ¤ ë³€ê²½ì‚¬í•­ ì•Œë¦¼ ì „ì†¡
        
        ì‹ ê·œ ì…ë ¥, ì œëª©/ë‚´ìš© ë³€ê²½, ì‹œê°„ ì—…ë°ì´íŠ¸ ë“±ì„ êµ¬ë¶„í•˜ì—¬
        ìƒì„¸í•œ ë³€ê²½ì‚¬í•­ ì •ë³´ë¥¼ Doorayë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
        
        Args:
            news_type (str): ë‰´ìŠ¤ íƒ€ì… (ì˜ˆ: "exchange-rate")
            old_data (dict): ì´ì „ ë‰´ìŠ¤ ë°ì´í„°
            new_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
        """
        # ë‰´ìŠ¤ íƒ€ì…ë³„ ì´ëª¨ì§€ ë§¤í•‘
        type_emojis = {
            "exchange-rate": "ğŸ’±",
            "newyork-market-watch": "ğŸŒ†", 
            "kospi-close": "ğŸ“ˆ"
        }
        emoji = type_emojis.get(news_type, "ğŸ“°")
        type_display = news_type.replace("-", " ").upper()

        # ë³€ê²½ í•­ëª© ë¶„ì„
        changed_fields = []
        field_names = [
            ("title", "ì œëª©"),
            ("content", "ë³¸ë¬¸"),
            ("date", "ë‚ ì§œ"),
            ("time", "ì‹œê°„")
        ]
        if not old_data or not any(old_data.get(f) for f, _ in field_names):
            change_type = "ğŸ†• ì‹ ê·œì…ë ¥"
            change_icon = "ğŸ†•"
            changed_fields = [n for _, n in field_names if new_data.get(_)]
        else:
            for f, n in field_names:
                if old_data.get(f) != new_data.get(f):
                    changed_fields.append(n)
            if changed_fields:
                change_type = f"{', '.join(changed_fields)} ë³€ê²½"
                change_icon = "ğŸ“"
            else:
                change_type = "â° ì‹œê°„ ì—…ë°ì´íŠ¸"
                change_icon = "â°"

        message = f"{change_icon} {type_display} ì—…ë°ì´íŠ¸\n"
        message += f"â”Œ ë³€ê²½: {change_type}\n"

        # ìµœì‹  ë°ì´í„° ì •ë³´
        new_datetime = self._format_datetime(new_data.get('date', ''), new_data.get('time', ''))
        message += f"â”œ ì‹œê°„: {new_datetime}\n"

        # ì œëª© ì •ë³´
        new_title = new_data.get('title', '')
        if new_title:
            title_preview = new_title[:60] + "..." if len(new_title) > 60 else new_title
            message += f"â”œ ì œëª©: {title_preview}\n"

        # ì‘ì„±ì ë° ì¹´í…Œê³ ë¦¬
        writers = new_data.get('writer', [])
        categories = new_data.get('category', [])
        if writers:
            message += f"â”œ ì‘ì„±ì: {', '.join(writers)}\n"
        if categories:
            message += f"â”” ì¹´í…Œê³ ë¦¬: {', '.join(categories[:3])}{'...' if len(categories) > 3 else ''}"
        else:
            if writers:
                message = message.rstrip('\nâ”œ ì‘ì„±ì: ' + ', '.join(writers) + '\n') + f"â”” ì‘ì„±ì: {', '.join(writers)}"
            else:
                message = message.rstrip('\n')

        payload = {
            "botName": "POSCO ë‰´ìŠ¤ ğŸ””",
            "botIconImage": self.bot_profile_image_url,
            "text": f"{change_icon} {type_display} ì—…ë°ì´íŠ¸",
            "attachments": [{
                "color": "#0066cc",
                "text": message.split('\n', 1)[1] if '\n' in message else message
            }]
        }
        try:
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            if response.status_code == 200:
                print(f"âœ… {news_type} ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
                return True
        except Exception as e:
            print(f"âŒ {news_type} ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
        
        return False
    
    def send_simple_status_notification(self, current_data, status_info):
        """
        ê°„ê²°í•œ ìƒíƒœ ì•Œë¦¼ ì „ì†¡
        
        ë´‡ ì´ë¦„ì— ìƒíƒœ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  "ê°±ì‹  ë°ì´í„° ì—†ìŒ" ë©”ì‹œì§€ë§Œ
        ì „ì†¡í•˜ëŠ” ê°„ê²°í•œ í˜•íƒœì˜ ì•Œë¦¼ì…ë‹ˆë‹¤.
        
        Args:
            current_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            status_info (str): ìƒíƒœ ì •ë³´ ë¬¸ìì—´
        """
        bot_name = f"POSCO ë‰´ìŠ¤{status_info}"
        payload = {
            "botName": bot_name,
            "botIconImage": self.bot_profile_image_url,
            "text": "ê°±ì‹  ë°ì´í„° ì—†ìŒ",
            "attachments": []
        }
        try:
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            if response.status_code == 200:
                print(f"âœ… ê°„ê²° ìƒíƒœ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
                return True
        except Exception as e:
            print(f"âŒ ê°„ê²° ìƒíƒœ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
        
        return False

    def send_monitoring_stopped_notification(self):
        """
        ëª¨ë‹ˆí„°ë§ ì¤‘ì§€ ì˜¤ë¥˜ ì•Œë¦¼ ì „ì†¡
        
        ìë™ ëª¨ë‹ˆí„°ë§ í”„ë¡œì„¸ìŠ¤ê°€ ì˜ˆê¸°ì¹˜ ì•Šê²Œ ì¤‘ë‹¨ë˜ì—ˆì„ ë•Œ
        ë¹¨ê°„ìƒ‰ ì˜¤ë¥˜ ì•Œë¦¼ì„ ì „ì†¡í•©ë‹ˆë‹¤.
        """
        payload = {
            "botName": "POSCO ë‰´ìŠ¤ âŒ",
            "botIconImage": self.bot_profile_image_url,
            "text": "âŒ ì˜¤ë¥˜",
            "attachments": [
                {
                    "color": "#ff4444",
                    "text": "ìë™ ëª¨ë‹ˆí„°ë§ í”„ë¡œì„¸ìŠ¤ ì¤‘ì§€ë¨"
                }
            ]
        }
        try:
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            if response.status_code == 200:
                print(f"âœ… ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
                return True
        except Exception as e:
            print(f"âŒ ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
        
        return False
    
    def send_comparison_notification(self, current_data, previous_data):
        """
        ì˜ì—…ì¼ ë¹„êµ ì•Œë¦¼ ì „ì†¡
        
        í˜„ì¬ ë°ì´í„°ì™€ ì§ì „ ì˜ì—…ì¼ ë°ì´í„°ë¥¼ ë¹„êµí•˜ì—¬ ìƒì„¸í•œ ë¶„ì„ì„ ì „ì†¡í•©ë‹ˆë‹¤.
        
        Args:
            current_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            previous_data (dict): ì§ì „ ì˜ì—…ì¼ ë‰´ìŠ¤ ë°ì´í„°
        """
        if not current_data:
            return False
        
        message = "ğŸ“ˆ ì˜ì—…ì¼ ë¹„êµ ë¶„ì„\n\n"
        
        # ì˜¤ëŠ˜ ë‚ ì§œ ì •ë³´
        today_date = datetime.now().date()
        
        # í˜„ì¬ ë°ì´í„°
        current_news = None
        for news_type, news_data in current_data.items():
            if news_data and news_data.get('title'):
                current_news = news_data
                break
        
        if not current_news:
            message += "í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n"
        else:
            current_date = current_news.get('date', '')
            current_time = current_news.get('time', '')
            current_title = current_news.get('title', '')
            
            if current_date and current_time:
                current_datetime = self._format_datetime(current_date, current_time)
                current_date_obj = datetime.strptime(current_date, '%Y%m%d').date()
                is_latest = " (ìµœì‹ )" if current_date_obj == today_date else ""
                message += f"â”œ í˜„ì¬: {current_datetime}{is_latest}\n"
                if current_title:
                    title_preview = current_title[:40] + "..." if len(current_title) > 40 else current_title
                    message += f"â”œ ì œëª©: {title_preview}\n"
            
            # êµ¬ë¶„ì„  ì¶”ê°€ (ê°€ë…ì„± í–¥ìƒ)
            message += f"â”œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
            
            # ì§ì „ ë°ì´í„°
            previous_date = previous_data.get('date', '')
            previous_time = previous_data.get('time', '')
            previous_title = previous_data.get('title', '')
            
            if previous_date and previous_time:
                previous_datetime = self._format_datetime(previous_date, previous_time)
                previous_date_obj = datetime.strptime(previous_date, '%Y%m%d').date()
                days_diff = (today_date - previous_date_obj).days
                days_text = f" ({days_diff}ì¼ ì „)" if days_diff > 0 else ""
                message += f"â”œ ì§ì „: {previous_datetime}{days_text}\n"
                if previous_title:
                    title_preview = previous_title[:40] + "..." if len(previous_title) > 40 else previous_title
                    message += f"â”” ì œëª©: {title_preview}\n"
            else:
                message += f"â”” ì§ì „: ë°ì´í„° ì—†ìŒ\n"
            
            message += "\n"
        
        payload = {
            "botName": "POSCO ë‰´ìŠ¤ ğŸ“ˆ",
            "botIconImage": self.bot_profile_image_url,
            "text": "ì˜ì—…ì¼ ë¹„êµ ë¶„ì„",
            "attachments": [{
                "color": "#28a745",
                "text": message
            }]
        }
        
        try:
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            if response.status_code == 200:
                print(f"âœ… ë¹„êµ ë¶„ì„ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
                return True
        except Exception as e:
            print(f"âŒ ë¹„êµ ë¶„ì„ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
        
        return False
    
    def send_detailed_daily_summary(self, current_data, previous_data=None):
        """
        ìƒì„¸í•œ ì¼ì¼ ìš”ì•½ ì•Œë¦¼ ì „ì†¡ (ì œëª© + ë³¸ë¬¸ ë¹„êµ)
        
        ê° ë‰´ìŠ¤ íƒ€ì…ë³„ë¡œ ì œëª©ê³¼ ë³¸ë¬¸ ë‚´ìš©ì„ í¬í•¨í•œ ìƒì„¸í•œ ìš”ì•½ì„ ìƒì„±í•˜ê³ ,
        ì§ì „ ì˜ì—…ì¼ê³¼ì˜ ë¹„êµ ë¶„ì„ì„ í¬í•¨í•˜ì—¬ ì „ì†¡í•©ë‹ˆë‹¤.
        
        Args:
            current_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            previous_data (dict, optional): ì§ì „ ì˜ì—…ì¼ ë‰´ìŠ¤ ë°ì´í„°
        """
        if not current_data:
            self.send_notification("ğŸ“‹ ìƒì„¸ ì¼ì¼ ìš”ì•½: ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", is_error=True)
            return False
        
        message = "ğŸ“‹ ìƒì„¸ ì¼ì¼ ìš”ì•½ ë¦¬í¬íŠ¸\n\n"
        today_info = self._get_today_info()
        today_date = today_info['kr_format']
        
        # í˜„ì¬ ë°ì´í„° ë¶„ì„
        current_summary = {}
        for news_type, news_data in current_data.items():
            if not news_data or not news_data.get('title'):
                continue
                
            news_config = NEWS_TYPES.get(news_type, {})
            display_name = news_config.get('display_name', news_type.upper())
            emoji = news_config.get('emoji', 'ğŸ“°')
            
            title = news_data.get('title', '')
            content = news_data.get('content', '')
            date = news_data.get('date', '')
            time = news_data.get('time', '')
            
            # ë³¸ë¬¸ ìš”ì•½ (ì²« 200ì)
            content_preview = content[:200] + "..." if len(content) > 200 else content
            
            current_summary[news_type] = {
                'display_name': display_name,
                'emoji': emoji,
                'title': title,
                'content_preview': content_preview,
                'date': date,
                'time': time,
                'formatted_datetime': self._format_datetime(date, time)
            }
        
        # ì§ì „ ë°ì´í„° ë¶„ì„
        previous_summary = {}
        if previous_data:
            for news_type, news_data in previous_data.items():
                if not news_data or not news_data.get('title'):
                    continue
                    
                news_config = NEWS_TYPES.get(news_type, {})
                display_name = news_config.get('display_name', news_type.upper())
                emoji = news_config.get('emoji', 'ğŸ“°')
                
                title = news_data.get('title', '')
                content = news_data.get('content', '')
                date = news_data.get('date', '')
                time = news_data.get('time', '')
                
                # ë³¸ë¬¸ ìš”ì•½ (ì²« 200ì)
                content_preview = content[:200] + "..." if len(content) > 200 else content
                
                previous_summary[news_type] = {
                    'display_name': display_name,
                    'emoji': emoji,
                    'title': title,
                    'content_preview': content_preview,
                    'date': date,
                    'time': time,
                    'formatted_datetime': self._format_datetime(date, time)
                }
        
        # ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
        message += f"ğŸ“… ìš”ì•½ ì¼ì: {today_date} ({today_info['weekday_name']}ìš”ì¼)\n"
        message += f"ğŸ“Š ë‰´ìŠ¤ íƒ€ì…: {len(current_summary)}ê°œ\n\n"
        
        # ê° ë‰´ìŠ¤ íƒ€ì…ë³„ ìƒì„¸ ìš”ì•½
        for news_type, current_info in current_summary.items():
            message += f"â”Œ {current_info['emoji']} {current_info['display_name']}\n"
            message += f"â”œ ğŸ“… ë°œí–‰: {current_info['formatted_datetime']}\n"
            message += f"â”œ ğŸ“° ì œëª©: {current_info['title']}\n"
            message += f"â”œ ğŸ“ ë³¸ë¬¸: {current_info['content_preview']}\n"
            
            # ì§ì „ ë°ì´í„°ì™€ ë¹„êµ
            if news_type in previous_summary:
                prev_info = previous_summary[news_type]
                message += f"â”œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                message += f"â”œ ğŸ“… ì§ì „: {prev_info['formatted_datetime']}\n"
                message += f"â”œ ğŸ“° ì œëª©: {prev_info['title']}\n"
                message += f"â”” ğŸ“ ë³¸ë¬¸: {prev_info['content_preview']}\n"
            else:
                message += f"â”” ğŸ“ ì§ì „ ë°ì´í„°: ì—†ìŒ\n"
            
            message += "\n"
        
        # ì „ì²´ ìš”ì•½
        message += f"ğŸ“ˆ ìš”ì•½ í†µê³„:\n"
        message += f"â€¢ í˜„ì¬ ë°œí–‰: {len(current_summary)}ê°œ\n"
        if previous_data:
            message += f"â€¢ ì§ì „ ë°œí–‰: {len(previous_summary)}ê°œ\n"
        
        # ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë²„ì „)
        all_content = ""
        for news_type, info in current_summary.items():
            all_content += info['title'] + " " + info['content_preview']
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì£¼ìš” ê²½ì œ ìš©ì–´)
        keywords = []
        keyword_patterns = [
            'ë‹¬ëŸ¬', 'ì—”', 'ìœ ë¡œ', 'ìœ„ì•ˆ', 'ì›í™”', 'í™˜ìœ¨',
            'ì½”ìŠ¤í”¼', 'ë‚˜ìŠ¤ë‹¥', 'ë‹¤ìš°', 'S&P', 'ì£¼ì‹', 'ì±„ê¶Œ',
            'ê¸ˆë¦¬', 'ì¸í”Œë ˆì´ì…˜', 'GDP', 'ë¬´ì—­', 'ê´€ì„¸',
            'íŠ¸ëŸ¼í”„', 'ì—°ì¤€', 'Fed', 'ì¤‘êµ­', 'ì¼ë³¸', 'ìœ ëŸ½'
        ]
        
        for keyword in keyword_patterns:
            if keyword in all_content:
                keywords.append(keyword)
        
        if keywords:
            message += f"â€¢ ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(keywords[:5])}\n"
        
        current_datetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        message += f"\nğŸ“Š ë¶„ì„ ì‹œê°„: {current_datetime}"
        
        payload = {
            "botName": "POSCO ë‰´ìŠ¤ ğŸ“‹",
            "botIconImage": self.bot_profile_image_url,
            "text": "ìƒì„¸ ì¼ì¼ ìš”ì•½ ë¦¬í¬íŠ¸",
            "attachments": [{
                "color": "#17a2b8",
                "text": message
            }]
        }
        
        try:
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            if response.status_code == 200:
                print(f"âœ… ìƒì„¸ ì¼ì¼ ìš”ì•½ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
                return True
        except Exception as e:
            print(f"âŒ ìƒì„¸ ì¼ì¼ ìš”ì•½ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
        
        return False
    
    def _get_today_info(self):
        """
        ì˜¤ëŠ˜ ë‚ ì§œ ì •ë³´ ë°˜í™˜
        
        Returns:
            dict: ì˜¤ëŠ˜ ë‚ ì§œ ì •ë³´
        """
        now = datetime.now()
        weekday_names = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
        return {
            'date': now.date(),
            'kr_format': now.strftime('%Y%m%d'),
            'weekday': now.weekday(),
            'weekday_name': weekday_names[now.weekday()],
            'datetime': now
        }
    
    def _format_datetime(self, date_str, time_str):
        """
        ë‚ ì§œì™€ ì‹œê°„ì„ í¬ë§·íŒ…
        
        Args:
            date_str (str): ë‚ ì§œ ë¬¸ìì—´ (YYYYMMDD)
            time_str (str): ì‹œê°„ ë¬¸ìì—´ (HHMMSS)
            
        Returns:
            str: í¬ë§·íŒ…ëœ ë‚ ì§œì‹œê°„ ë¬¸ìì—´
        """
        if not date_str:
            return "ë‚ ì§œ ì—†ìŒ"
        
        formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        
        if not time_str:
            return formatted_date
        
        if len(time_str) >= 6:
            formatted_time = f"{time_str[:2]}:{time_str[2:4]}:{time_str[4:6]}"
        elif len(time_str) == 5:
            if time_str.startswith('6'):
                time_str = '0' + time_str
                formatted_time = f"{time_str[:2]}:{time_str[2:4]}:{time_str[4:6]}"
            else:
                formatted_time = f"{time_str[:2]}:{time_str[2:4]}:{time_str[4:5]}"
        elif len(time_str) >= 4:
            formatted_time = f"{time_str[:2]}:{time_str[2:4]}"
        else:
            formatted_time = time_str
        
        return f"{formatted_date} {formatted_time}"

    def send_advanced_analysis(self, current_data, api_client, days_back=30):
        """
        ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ ì „ì†¡ (30ì¼ ì¶”ì´ + ì£¼ë‹¨ìœ„ ë¶„ì„ + í–¥í›„ ì˜ˆìƒ)
        
        ìµœê·¼ 30ì¼ê°„ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ì´, ì£¼ë‹¨ìœ„ íŒ¨í„´, í–¥í›„ ì˜ˆìƒì„ í¬í•¨í•œ
        ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ê° ë‰´ìŠ¤ íƒ€ì…ë³„ë¡œ ë³„ë„ ë§í’ì„ ìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
        
        Args:
            current_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            api_client (PoscoNewsAPIClient): API í´ë¼ì´ì–¸íŠ¸ ê°ì²´
            days_back (int): ë¶„ì„í•  ê³¼ê±° ì¼ìˆ˜ (ê¸°ë³¸ê°’: 30ì¼)
        """
        if not current_data:
            self.send_notification("ğŸ“Š ê³ ê¸‰ ë¶„ì„: ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.", is_error=True)
            return False
        
        from utils import log_with_timestamp
        log_with_timestamp("ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘", "INFO")
        
        # ê° ë‰´ìŠ¤ íƒ€ì…ë³„ë¡œ ë¶„ì„ ìˆ˜í–‰
        analyzed_types = []
        for news_type, current_news in current_data.items():
            news_config = NEWS_TYPES.get(news_type, {})
            display_name = news_config.get('display_name', news_type.upper())
            emoji = news_config.get('emoji', 'ğŸ“°')
            
            # í•´ë‹¹ ë‰´ìŠ¤ íƒ€ì…ì˜ ìµœê·¼ 30ì¼ ë°ì´í„° ìˆ˜ì§‘ (ë‹¹ì¼ ë°ì´í„°ê°€ ì—†ì–´ë„ ì§ì „ê°’ ì‚¬ìš©)
            historical_data = self._collect_historical_data(news_type, api_client, days_back)
            
            if not historical_data:
                # ê³¼ê±° ë°ì´í„°ê°€ ì „í˜€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ê°„ë‹¨í•œ ë©”ì‹œì§€ ì „ì†¡
                self._send_no_data_message(news_type, display_name, emoji)
                continue
            
            analyzed_types.append(display_name)
            
            # í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°, historical_dataì—ì„œ ê°€ì¥ ìµœì‹  ë°ì´í„°ë¥¼ current_newsë¡œ ì‚¬ìš©
            if not current_news or not current_news.get('title'):
                if historical_data:
                    current_news = historical_data[0]  # ê°€ì¥ ìµœì‹  ë°ì´í„° ì‚¬ìš©
                    print(f"ğŸ“ {display_name}: ë‹¹ì¼ ë°ì´í„° ì—†ìŒ â†’ ìµœì‹  ê³¼ê±° ë°ì´í„° ì‚¬ìš© ({current_news['date']})")
            
            # ê³ ê¸‰ ë¶„ì„ ìˆ˜í–‰
            analysis_result = self._perform_advanced_analysis(news_type, historical_data, current_news)
            
            # historical_dataë¥¼ analysis_resultì— ì¶”ê°€
            analysis_result['historical_data'] = historical_data
            
            # ë³„ë„ ë§í’ì„ ìœ¼ë¡œ ì „ì†¡
            self._send_type_analysis(news_type, display_name, emoji, analysis_result)
        
        # ì „ì²´ ìš”ì•½ ì•Œë¦¼ ì „ì†¡
        self._send_summary_notification(current_data, analyzed_types)
        
        log_with_timestamp("ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ ì „ì†¡ ì™„ë£Œ", "SUCCESS")
        return True
    
    def _collect_historical_data(self, news_type, api_client, days_back):
        """
        íŠ¹ì • ë‰´ìŠ¤ íƒ€ì…ì˜ ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘
        
        Args:
            news_type (str): ë‰´ìŠ¤ íƒ€ì…
            api_client (PoscoNewsAPIClient): API í´ë¼ì´ì–¸íŠ¸ ê°ì²´
            days_back (int): ìˆ˜ì§‘í•  ê³¼ê±° ì¼ìˆ˜
            
        Returns:
            list: ê³¼ê±° ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ìµœì‹ ìˆœ)
        """
        historical_data = []
        today = datetime.now()
        last_valid_data = None  # ì§ì „ ìœ íš¨í•œ ë°ì´í„° ì €ì¥
        
        for i in range(days_back):
            target_date = today - timedelta(days=i)
            date_str = target_date.strftime('%Y%m%d')
            
            try:
                # APIì—ì„œ í•´ë‹¹ ë‚ ì§œ ë°ì´í„° ì¡°íšŒ
                data = api_client.get_news_data(date_str)
                if data and news_type in data and data[news_type]:
                    news_data = data[news_type]
                    if news_data.get('title'):  # ì œëª©ì´ ìˆëŠ” ë°ì´í„°ë§Œ
                        current_data = {
                            'date': news_data.get('date', ''),
                            'time': news_data.get('time', ''),
                            'title': news_data.get('title', ''),
                            'content': news_data.get('content', ''),
                            'days_ago': i
                        }
                        historical_data.append(current_data)
                        last_valid_data = current_data  # ìœ íš¨í•œ ë°ì´í„° ì—…ë°ì´íŠ¸
                else:
                    # í•´ë‹¹ ë‚ ì§œì— ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°, ì§ì „ ìœ íš¨í•œ ë°ì´í„° ì‚¬ìš©
                    if last_valid_data:
                        # ì§ì „ ë°ì´í„°ë¥¼ í˜„ì¬ ë‚ ì§œë¡œ ë³µì‚¬ (days_agoë§Œ ì¡°ì •)
                        fallback_data = last_valid_data.copy()
                        fallback_data['days_ago'] = i
                        fallback_data['date'] = date_str  # ì‹¤ì œ ë‚ ì§œë¡œ ì—…ë°ì´íŠ¸
                        historical_data.append(fallback_data)
                        print(f"ğŸ“ {date_str} ë°ì´í„° ì—†ìŒ â†’ ì§ì „ ë°ì´í„° ì‚¬ìš© ({last_valid_data['date']})")
            except Exception as e:
                print(f"âš ï¸ {date_str} ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
                # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì§ì „ ìœ íš¨í•œ ë°ì´í„° ì‚¬ìš©
                if last_valid_data:
                    fallback_data = last_valid_data.copy()
                    fallback_data['days_ago'] = i
                    fallback_data['date'] = date_str
                    historical_data.append(fallback_data)
                    print(f"ğŸ“ {date_str} ì¡°íšŒ ì‹¤íŒ¨ â†’ ì§ì „ ë°ì´í„° ì‚¬ìš© ({last_valid_data['date']})")
                continue
        
        return historical_data
    
    def _perform_advanced_analysis(self, news_type, historical_data, current_news):
        """
        ê³ ê¸‰ ë¶„ì„ ìˆ˜í–‰ (ì •ê¸°ë°œí–‰ë¬¼ íŠ¹ì„±ì— ë§ì¶¤)
        
        Args:
            news_type (str): ë‰´ìŠ¤ íƒ€ì…
            historical_data (list): ê³¼ê±° ë°ì´í„°
            current_news (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            
        Returns:
            dict: ë¶„ì„ ê²°ê³¼
        """
        if not historical_data:
            return None
        
        # 1. ê¸°ë³¸ í†µê³„
        total_articles = len(historical_data)
        current_date = datetime.now().date()
        
        # 2. ì£¼ì œë³„ íŠ¸ë Œë“œ ë¶„ì„ (ì •ê¸°ë°œí–‰ë¬¼ íŠ¹ì„±)
        topic_trends = self._analyze_topic_trends(historical_data)
        
        # 3. ì‹œì¥ ë™í–¥ ë¶„ì„
        market_trends = self._analyze_market_trends(historical_data)
        
        # 4. í‚¤ì›Œë“œ ë³€í™” ë¶„ì„
        keyword_evolution = self._analyze_keyword_evolution(historical_data)
        
        # 5. ì£¼ìš” ì´ìŠˆ íƒ€ì„ë¼ì¸
        major_events = self._analyze_major_events(historical_data)
        
        # 6. ì‹œì¥ ì„¹í„°ë³„ ë¶„ì„
        sector_analysis = self._analyze_sector_performance(historical_data)
        
        # 7. ê¸€ë¡œë²Œ ì´ë²¤íŠ¸ ì˜í–¥ë„
        global_impact = self._analyze_global_impact(historical_data)
        
        return {
            'total_articles': total_articles,
            'topic_trends': topic_trends,
            'market_trends': market_trends,
            'keyword_evolution': keyword_evolution,
            'major_events': major_events,
            'sector_analysis': sector_analysis,
            'global_impact': global_impact,
            'current_news': current_news
        }
    
    def _analyze_topic_trends(self, historical_data):
        """
        ì£¼ì œë³„ íŠ¸ë Œë“œ ë¶„ì„
        
        Args:
            historical_data (list): ê³¼ê±° ë°ì´í„°
            
        Returns:
            dict: ì£¼ì œë³„ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼
        """
        # ì£¼ì œë³„ ë¶„ë¥˜
        topics = {
            'ë¬´ì—­/ê´€ì„¸': ['ë¬´ì—­', 'ê´€ì„¸', 'í˜‘ìƒ', 'í•©ì˜', 'íŠ¸ëŸ¼í”„', 'ë°”ì´ë“ ', 'ì¤‘êµ­', 'ì¼ë³¸', 'EU'],
            'ê¸ˆìœµì •ì±…': ['ê¸ˆë¦¬', 'Fed', 'ì—°ì¤€', 'FOMC', 'íŒŒì›”', 'í†µí™”ì •ì±…', 'ì¸í”Œë ˆì´ì…˜'],
            'ì£¼ì‹ì‹œì¥': ['ì£¼ì‹', 'ì½”ìŠ¤í”¼', 'ë‚˜ìŠ¤ë‹¥', 'ë‹¤ìš°', 'S&P', 'ì¦ì‹œ', 'ë²¤ì¹˜ë§ˆí¬'],
            'ì±„ê¶Œì‹œì¥': ['ì±„ê¶Œ', 'êµ­ì±„', 'ìˆ˜ìµë¥ ', 'ì±„ê¶Œê¸ˆë¦¬', 'ì±„ê¶Œê°€ê²©'],
            'ì™¸í™˜ì‹œì¥': ['í™˜ìœ¨', 'ë‹¬ëŸ¬', 'ì—”', 'ìœ ë¡œ', 'ìœ„ì•ˆ', 'ì›í™”', 'DXY'],
            'ì›ìì¬': ['ì›ìœ ', 'WTI', 'ë¸Œë ŒíŠ¸', 'ê¸ˆ', 'ì€', 'êµ¬ë¦¬', 'ì² ê°•'],
            'ê²½ì œì§€í‘œ': ['GDP', 'CPI', 'PPI', 'ê³ ìš©', 'ì‹¤ì—…ë¥ ', 'ê²½ê¸°ì§€í‘œ']
        }
        
        topic_trends = {}
        for topic_name, keywords in topics.items():
            recent_week = []
            previous_week = []
            
            for data in historical_data:
                content = data.get('content', '') + ' ' + data.get('title', '')
                keyword_count = sum(content.count(keyword) for keyword in keywords)
                
                if data['days_ago'] <= 7:
                    recent_week.append(keyword_count)
                elif 8 <= data['days_ago'] <= 14:
                    previous_week.append(keyword_count)
            
            recent_avg = sum(recent_week) / len(recent_week) if recent_week else 0
            previous_avg = sum(previous_week) / len(previous_week) if previous_week else 0
            
            trend = "ì¦ê°€" if recent_avg > previous_avg else "ê°ì†Œ" if recent_avg < previous_avg else "ìœ ì§€"
            
            topic_trends[topic_name] = {
                'trend': trend,
                'recent_avg': recent_avg,
                'previous_avg': previous_avg,
                'change_rate': ((recent_avg - previous_avg) / previous_avg * 100) if previous_avg > 0 else 0
            }
        
        return topic_trends
    
    def _analyze_market_trends(self, historical_data):
        """
        ì‹œì¥ ë™í–¥ ë¶„ì„
        
        Args:
            historical_data (list): ê³¼ê±° ë°ì´í„°
            
        Returns:
            dict: ì‹œì¥ ë™í–¥ ë¶„ì„ ê²°ê³¼
        """
        market_sentiment = {
            'bullish': ['ìƒìŠ¹', 'ê°•ì„¸', 'ì˜¤ë¦„', 'ë›°ë‹¤', 'ìƒí–¥', 'ê¸ì •', 'í˜¸ì¡°', 'ê¸°ëŒ€'],
            'bearish': ['í•˜ë½', 'ì•½ì„¸', 'ë‚´ë¦¼', 'ë–¨ì–´ì§€ë‹¤', 'í•˜í–¥', 'ë¶€ì •', 'ìš°ë ¤', 'ìœ„í—˜'],
            'neutral': ['ë³´í•©', 'ì•ˆì •', 'ìœ ì§€', 'ë³€ë™ì—†ìŒ', 'ì¡°ì •']
        }
        
        sentiment_analysis = {}
        for sentiment, keywords in market_sentiment.items():
            count = 0
            for data in historical_data:
                content = data.get('content', '') + ' ' + data.get('title', '')
                count += sum(content.count(keyword) for keyword in keywords)
            sentiment_analysis[sentiment] = count
        
        # ì£¼ìš” ì‹œì¥ ì´ìŠˆ ì¶”ì¶œ
        market_issues = []
        for data in historical_data[:10]:  # ìµœê·¼ 10ê°œ ê¸°ì‚¬
            title = data.get('title', '')
            if any(keyword in title for keyword in ['ìœ„ê¸°', 'ì¶©ê²©', 'ë³€í™”', 'ì „í™˜', 'í˜ì‹ ', 'ë„ì „']):
                market_issues.append({
                    'date': data.get('date', ''),
                    'title': title,
                    'days_ago': data['days_ago']
                })
        
        return {
            'sentiment': sentiment_analysis,
            'dominant_sentiment': max(sentiment_analysis.items(), key=lambda x: x[1])[0],
            'market_issues': market_issues[:5]  # ìƒìœ„ 5ê°œ
        }
    
    def _analyze_keyword_evolution(self, historical_data):
        """
        í‚¤ì›Œë“œ ë³€í™” ë¶„ì„
        
        Args:
            historical_data (list): ê³¼ê±° ë°ì´í„°
            
        Returns:
            dict: í‚¤ì›Œë“œ ë³€í™” ë¶„ì„ ê²°ê³¼
        """
        # ì‹œê¸°ë³„ í‚¤ì›Œë“œ ë¶„ì„
        periods = {
            'ìµœê·¼_1ì£¼': [d for d in historical_data if d['days_ago'] <= 7],
            'ìµœê·¼_2ì£¼': [d for d in historical_data if 8 <= d['days_ago'] <= 14],
            'ìµœê·¼_4ì£¼': [d for d in historical_data if 15 <= d['days_ago'] <= 28]
        }
        
        keyword_evolution = {}
        for period_name, period_data in periods.items():
            all_content = ' '.join([d.get('content', '') + ' ' + d.get('title', '') for d in period_data])
            
            # ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords(all_content)
            keyword_evolution[period_name] = keywords[:10]  # ìƒìœ„ 10ê°œ
        
        # ì‹ ê·œ í‚¤ì›Œë“œì™€ ì‚¬ë¼ì§„ í‚¤ì›Œë“œ ë¶„ì„
        recent_keywords = set([kw[0] for kw in keyword_evolution.get('ìµœê·¼_1ì£¼', [])])
        previous_keywords = set([kw[0] for kw in keyword_evolution.get('ìµœê·¼_2ì£¼', [])])
        
        new_keywords = recent_keywords - previous_keywords
        disappeared_keywords = previous_keywords - recent_keywords
        
        return {
            'period_keywords': keyword_evolution,
            'new_keywords': list(new_keywords),
            'disappeared_keywords': list(disappeared_keywords)
        }
    
    def _analyze_major_events(self, historical_data):
        """
        ì£¼ìš” ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸ ë¶„ì„
        
        Args:
            historical_data (list): ê³¼ê±° ë°ì´í„°
            
        Returns:
            dict: ì£¼ìš” ì´ë²¤íŠ¸ ë¶„ì„ ê²°ê³¼
        """
        major_events = []
        
        for data in historical_data:
            title = data.get('title', '')
            content = data.get('content', '')
            
            # ì£¼ìš” ì´ë²¤íŠ¸ í‚¤ì›Œë“œ
            event_keywords = ['ë°œí‘œ', 'ê²°ì •', 'íšŒì˜', 'ì •ìƒíšŒë‹´', 'í˜‘ìƒ', 'í•©ì˜', 'ì •ì±…', 'ë²•ì•ˆ', 'ì„ ê±°']
            
            if any(keyword in title for keyword in event_keywords):
                # ì´ë²¤íŠ¸ ì¤‘ìš”ë„ ê³„ì‚°
                importance_score = 0
                if any(keyword in title for keyword in ['ì •ìƒíšŒë‹´', 'ì •ì±…', 'ë²•ì•ˆ']):
                    importance_score += 3
                if any(keyword in title for keyword in ['ë°œí‘œ', 'ê²°ì •', 'í•©ì˜']):
                    importance_score += 2
                if any(keyword in title for keyword in ['íšŒì˜', 'í˜‘ìƒ']):
                    importance_score += 1
                
                if importance_score >= 2:  # ì¤‘ìš”ë„ 2 ì´ìƒë§Œ
                    major_events.append({
                        'date': data.get('date', ''),
                        'title': title,
                        'importance': importance_score,
                        'days_ago': data['days_ago']
                    })
        
        # ì¤‘ìš”ë„ìˆœ ì •ë ¬
        major_events.sort(key=lambda x: x['importance'], reverse=True)
        
        return major_events[:10]  # ìƒìœ„ 10ê°œ
    
    def _analyze_sector_performance(self, historical_data):
        """
        ì‹œì¥ ì„¹í„°ë³„ ì„±ê³¼ ë¶„ì„ (ê³ ê¸‰ ê°ì„±ë¶„ì„ í¬í•¨)
        
        Args:
            historical_data (list): ê³¼ê±° ë°ì´í„°
            
        Returns:
            dict: ì„¹í„°ë³„ ë¶„ì„ ê²°ê³¼
        """
        sectors = {
            'ê¸°ìˆ ì£¼': ['í…Œí¬', 'AI', 'ë°˜ë„ì²´', 'ì†Œí”„íŠ¸ì›¨ì–´', 'ë””ì§€í„¸', 'ì¸í„°ë„·'],
            'ê¸ˆìœµì£¼': ['ì€í–‰', 'ë³´í—˜', 'íˆ¬ì', 'ê¸ˆìœµ', 'ì¦ê¶Œ', 'í€ë“œ'],
            'ì—ë„ˆì§€': ['ì„ìœ ', 'ê°€ìŠ¤', 'ì „ê¸°', 'ì¬ìƒì—ë„ˆì§€', 'íƒœì–‘ê´‘', 'í’ë ¥'],
            'í—¬ìŠ¤ì¼€ì–´': ['ì˜ë£Œ', 'ë°”ì´ì˜¤', 'ì œì•½', 'í—¬ìŠ¤ì¼€ì–´', 'ë°±ì‹ '],
            'ì†Œë¹„ì¬': ['ì†Œë¹„ì¬', 'ìœ í†µ', 'ì‹í’ˆ', 'ì˜ë¥˜', 'í™”ì¥í’ˆ'],
            'ì‚°ì—…ì¬': ['ì œì¡°ì—…', 'ê±´ì„¤', 'ìë™ì°¨', 'í•­ê³µ', 'ì¡°ì„ ']
        }
        
        sector_analysis = {}
        for sector_name, keywords in sectors.items():
            mentions = 0
            sentiment_score = 0
            advanced_sentiment = self._advanced_sentiment_analysis(historical_data, keywords)
            
            for data in historical_data:
                content = data.get('content', '') + ' ' + data.get('title', '')
                keyword_count = sum(content.count(keyword) for keyword in keywords)
                
                if keyword_count > 0:
                    mentions += keyword_count
                    
                    # ê³ ê¸‰ ê°ì„±ë¶„ì„ ì ìš©
                    sentiment_score += advanced_sentiment.get(data.get('date', ''), 0)
            
            # ì˜ˆì¸¡ ë¶„ì„ ì¶”ê°€
            prediction = self._predict_sector_trend(sector_name, historical_data, keywords)
            
            sector_analysis[sector_name] = {
                'mentions': mentions,
                'sentiment_score': sentiment_score,
                'sentiment': 'ê¸ì •' if sentiment_score > 0 else 'ë¶€ì •' if sentiment_score < 0 else 'ì¤‘ë¦½',
                'sentiment_confidence': advanced_sentiment.get('confidence', 0.5),
                'prediction': prediction
            }
        
        return sector_analysis
    
    def _advanced_sentiment_analysis(self, historical_data, keywords):
        """
        ê³ ê¸‰ ê°ì„±ë¶„ì„ (ë¬¸ë§¥ ê¸°ë°˜ + ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ)
        
        Args:
            historical_data (list): ê³¼ê±° ë°ì´í„°
            keywords (list): ì„¹í„° í‚¤ì›Œë“œ
            
        Returns:
            dict: ê³ ê¸‰ ê°ì„±ë¶„ì„ ê²°ê³¼
        """
        # ë¬¸ë§¥ ê¸°ë°˜ ê°ì„± í‚¤ì›Œë“œ (ê°€ì¤‘ì¹˜ í¬í•¨)
        sentiment_patterns = {
            'strong_positive': {
                'keywords': ['ê¸‰ë“±', 'í­ë“±', 'ëŒ€í­ ìƒìŠ¹', 'ê¸°ëŒ€ê° í­ë°œ', 'í˜¸ì¬', 'ëŒíŒŒ'],
                'weight': 3.0
            },
            'positive': {
                'keywords': ['ìƒìŠ¹', 'í˜¸ì¡°', 'ì„±ì¥', 'ê¸°ëŒ€', 'ê¸ì •', 'íšŒë³µ', 'ê°œì„ '],
                'weight': 2.0
            },
            'weak_positive': {
                'keywords': ['ì•ˆì •', 'ìœ ì§€', 'ë³´í•©', 'ì†Œí­ ìƒìŠ¹', 'ê¸°ëŒ€ê°'],
                'weight': 1.0
            },
            'neutral': {
                'keywords': ['ë³€ë™', 'ì¡°ì •', 'í˜¼ì¡°', 'ë³´í•©'],
                'weight': 0.0
            },
            'weak_negative': {
                'keywords': ['ì†Œí­ í•˜ë½', 'ì¡°ì •', 'ìš°ë ¤', 'ë¶ˆì•ˆ'],
                'weight': -1.0
            },
            'negative': {
                'keywords': ['í•˜ë½', 'ì•½ì„¸', 'ë¶€ì •', 'ìœ„í—˜', 'ìš°ë ¤', 'ì¶©ê²©'],
                'weight': -2.0
            },
            'strong_negative': {
                'keywords': ['í­ë½', 'ê¸‰ë½', 'ëŒ€í­ í•˜ë½', 'ìœ„ê¸°', 'ì¶©ê²©', 'ì•…ì¬'],
                'weight': -3.0
            }
        }
        
        # ë¶€ì •ì–´ ì²˜ë¦¬
        negation_words = ['ì•„ë‹ˆ', 'ì—†', 'ëª»', 'ì•ˆ', 'ë¹„', 'ë¯¸', 'ë¬´', 'ë¶ˆ', 'ë°˜']
        
        results = {}
        total_confidence = 0
        total_sentiment = 0
        
        for data in historical_data:
            content = data.get('content', '') + ' ' + data.get('title', '')
            date = data.get('date', '')
            
            # ì„¹í„° í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ë§Œ ë¶„ì„
            if not any(keyword in content for keyword in keywords):
                continue
            
            sentence_sentiment = 0
            sentence_confidence = 0
            
            # ë¬¸ì¥ë³„ ë¶„ì„
            sentences = content.split('.')
            for sentence in sentences:
                if any(keyword in sentence for keyword in keywords):
                    sentence_score = 0
                    sentence_weight = 0
                    
                    # ê°ì„± íŒ¨í„´ ë§¤ì¹­
                    for pattern_type, pattern_data in sentiment_patterns.items():
                        for keyword in pattern_data['keywords']:
                            if keyword in sentence:
                                # ë¶€ì •ì–´ ì²˜ë¦¬ (í‚¤ì›Œë“œ ì•ë¶€ë¶„ì—ì„œ ë¶€ì •ì–´ ê²€ìƒ‰)
                                keyword_pos = sentence.find(keyword)
                                before_keyword = sentence[:keyword_pos]
                                negation_count = sum(1 for neg in negation_words if neg in before_keyword)
                                weight = pattern_data['weight']
                                
                                if negation_count % 2 == 1:  # í™€ìˆ˜ë©´ ë¶€ì •
                                    weight = -weight
                                
                                sentence_score += weight
                                sentence_weight += abs(weight)
                    
                    if sentence_weight > 0:
                        sentence_sentiment += sentence_score
                        sentence_confidence += sentence_weight
            
            if sentence_confidence > 0:
                results[date] = sentence_sentiment
                total_sentiment += sentence_sentiment
                total_confidence += sentence_confidence
        
        # ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°
        overall_confidence = min(total_confidence / max(len(results), 1) / 10, 1.0)
        
        return {
            'sentiment_scores': results,
            'total_sentiment': total_sentiment,
            'confidence': overall_confidence
        }
    
    def _predict_sector_trend(self, sector_name, historical_data, keywords):
        """
        ì„¹í„°ë³„ íŠ¸ë Œë“œ ì˜ˆì¸¡ ë¶„ì„
        
        Args:
            sector_name (str): ì„¹í„°ëª…
            historical_data (list): ê³¼ê±° ë°ì´í„°
            keywords (list): ì„¹í„° í‚¤ì›Œë“œ
            
        Returns:
            dict: ì˜ˆì¸¡ ê²°ê³¼
        """
        # ìµœê·¼ 7ì¼ vs ì´ì „ 7ì¼ ë¹„êµ
        recent_week = [d for d in historical_data if d['days_ago'] <= 7]
        previous_week = [d for d in historical_data if 8 <= d['days_ago'] <= 14]
        
        # ì–¸ê¸‰ ë¹ˆë„ ë³€í™”
        recent_mentions = sum(1 for d in recent_week 
                            if any(kw in (d.get('content', '') + ' ' + d.get('title', '')) 
                                  for kw in keywords))
        previous_mentions = sum(1 for d in previous_week 
                              if any(kw in (d.get('content', '') + ' ' + d.get('title', '')) 
                                    for kw in keywords))
        
        # ê°ì„± ì ìˆ˜ ë³€í™”
        recent_sentiment = sum(self._advanced_sentiment_analysis(recent_week, keywords).get('sentiment_scores', {}).values())
        previous_sentiment = sum(self._advanced_sentiment_analysis(previous_week, keywords).get('sentiment_scores', {}).values())
        
        # íŠ¸ë Œë“œ ì˜ˆì¸¡
        mention_trend = 'ì¦ê°€' if recent_mentions > previous_mentions else 'ê°ì†Œ' if recent_mentions < previous_mentions else 'ìœ ì§€'
        sentiment_trend = 'ê°œì„ ' if recent_sentiment > previous_sentiment else 'ì•…í™”' if recent_sentiment < previous_sentiment else 'ìœ ì§€'
        
        # ë‹¤ìŒë‚  ì˜ˆì¸¡
        prediction_confidence = 0.5
        if mention_trend == 'ì¦ê°€' and sentiment_trend == 'ê°œì„ ':
            next_day_prediction = 'ê¸ì •'
            prediction_confidence = 0.8
        elif mention_trend == 'ê°ì†Œ' and sentiment_trend == 'ì•…í™”':
            next_day_prediction = 'ë¶€ì •'
            prediction_confidence = 0.8
        elif mention_trend == 'ìœ ì§€' and sentiment_trend == 'ìœ ì§€':
            next_day_prediction = 'ì¤‘ë¦½'
            prediction_confidence = 0.7
        else:
            next_day_prediction = 'í˜¼ì¡°'
            prediction_confidence = 0.6
        
        return {
            'mention_trend': mention_trend,
            'sentiment_trend': sentiment_trend,
            'next_day_prediction': next_day_prediction,
            'prediction_confidence': prediction_confidence,
            'recent_mentions': recent_mentions,
            'previous_mentions': previous_mentions,
            'recent_sentiment': recent_sentiment,
            'previous_sentiment': previous_sentiment
        }
    
    def _analyze_monthly_trend(self, analysis_result):
        """
        ì›”ê°„ íŠ¸ë Œë“œ ë¶„ì„ ì½”ë©˜íŠ¸ ìƒì„±
        
        Args:
            analysis_result (dict): ë¶„ì„ ê²°ê³¼
            
        Returns:
            str: ì›”ê°„ íŠ¸ë Œë“œ ë¶„ì„ ì½”ë©˜íŠ¸
        """
        total_articles = analysis_result['total_articles']
        sector_analysis = analysis_result['sector_analysis']
        
        # ì„¹í„°ë³„ ì„±ê³¼ ë¶„ì„
        positive_sectors = [s for s in sector_analysis.items() if s[1]['sentiment'] == 'ê¸ì •']
        negative_sectors = [s for s in sector_analysis.items() if s[1]['sentiment'] == 'ë¶€ì •']
        
        if total_articles < 10:
            return "ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì›”ê°„ íŠ¸ë Œë“œë¥¼ íŒŒì•…í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."
        
        # ì›”ê°„ íŠ¸ë Œë“œ íŒë‹¨
        if len(positive_sectors) > len(negative_sectors):
            trend = "ê¸ì •ì "
            if len(positive_sectors) >= 4:
                trend = "ê°•í•œ ê¸ì •ì "
        elif len(negative_sectors) > len(positive_sectors):
            trend = "ë¶€ì •ì "
            if len(negative_sectors) >= 4:
                trend = "ê°•í•œ ë¶€ì •ì "
        else:
            trend = "í˜¼ì¡°"
        
        # ì£¼ìš” ì„¹í„° ì‹ë³„
        top_sector = max(sector_analysis.items(), key=lambda x: x[1]['mentions'])
        
        # ë” ìƒì„¸í•œ ì›”ê°„ íŠ¸ë Œë“œ ë¶„ì„
        if trend == "ê°•í•œ ê¸ì •ì ":
            trend_desc = "ë§¤ìš° ê°•í•œ ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ë©° ì‹œì¥ì´ í™œë°œí•˜ê²Œ ì›€ì§ì´ê³  ìˆìŠµë‹ˆë‹¤"
        elif trend == "ê¸ì •ì ":
            trend_desc = "ì „ë°˜ì ìœ¼ë¡œ ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ë©° ì‹œì¥ ë¶„ìœ„ê¸°ê°€ ì¢‹ìŠµë‹ˆë‹¤"
        elif trend == "ê°•í•œ ë¶€ì •ì ":
            trend_desc = "ë§¤ìš° ê°•í•œ í•˜ë½ì„¸ë¥¼ ë³´ì´ë©° ì‹œì¥ì´ ë¶ˆì•ˆì •í•œ ìƒíƒœì…ë‹ˆë‹¤"
        elif trend == "ë¶€ì •ì ":
            trend_desc = "ì „ë°˜ì ìœ¼ë¡œ í•˜ë½ì„¸ë¥¼ ë³´ì´ë©° ì‹œì¥ ë¶„ìœ„ê¸°ê°€ ìš°ìš¸í•©ë‹ˆë‹¤"
        else:
            trend_desc = "ìƒìŠ¹ê³¼ í•˜ë½ì´ í˜¼ì¬í•˜ì—¬ ì‹œì¥ì´ ë°©í–¥ì„±ì„ ì°¾ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤"
        
        # ì„¹í„°ë³„ íŠ¹ì„± ë¶„ì„
        sector_characteristics = {
            'ê¸°ìˆ ì£¼': 'í˜ì‹ ê³¼ ì„±ì¥ì˜ ë™ë ¥',
            'ê¸ˆìœµì£¼': 'ê²½ì œì˜ í˜ˆê´€ ì—­í• ',
            'ì—ë„ˆì§€': 'ê²½ì œì˜ ê¸°ë°˜ ì‚°ì—…',
            'ì œì¡°ì—…': 'ì‹¤ë¬¼ ê²½ì œì˜ í•µì‹¬',
            'ì†Œë¹„ì¬': 'ë‚´ìˆ˜ ê²½ì œì˜ ì§€í‘œ',
            'í—¬ìŠ¤ì¼€ì–´': 'ë¯¸ë˜ ì„±ì¥ ë™ë ¥'
        }
        
        top_sector_name = top_sector[0]
        sector_desc = sector_characteristics.get(top_sector_name, 'ì£¼ìš” ì„¹í„°')
        
        # í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insights = []
        insights.append(f"ì´ë²ˆ ë‹¬ì€ {trend_desc}.")
        
        # ì£¼ìš” ì„¹í„° ë¶„ì„
        insights.append(f"{top_sector_name}ì´(ê°€) ê°€ì¥ í™œë°œí•˜ê²Œ ì–¸ê¸‰ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì„¹í„° ë¶„í™” ë¶„ì„
        if len(positive_sectors) > 0 and len(negative_sectors) > 0:
            insights.append("ì„¹í„° ê°„ ë¶„í™”ê°€ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # ì˜ˆì¸¡ ì‹ ë¢°ë„
        high_confidence_count = 0
        for sector, data in sector_analysis.items():
            if 'prediction' in data and data['prediction']['prediction_confidence'] >= 0.8:
                high_confidence_count += 1
        
        if high_confidence_count >= 2:
            insights.append("ë†’ì€ ì‹ ë¢°ë„ì˜ ì˜ˆì¸¡ì´ ë‹¤ìˆ˜ ìˆì–´ íˆ¬ì ê¸°íšŒê°€ ëª…í™•í•©ë‹ˆë‹¤.")
        
        insights.append(f"ì´ {total_articles}ê±´ì˜ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.")
        
        return '\n'.join(insights)
    
    def _analyze_weekly_changes(self, analysis_result):
        """
        ì£¼ë³„ ë³€í™” ë¶„ì„ ì½”ë©˜íŠ¸ ìƒì„±
        
        Args:
            analysis_result (dict): ë¶„ì„ ê²°ê³¼
            
        Returns:
            str: ì£¼ë³„ ë³€í™” ë¶„ì„ ì½”ë©˜íŠ¸
        """
        sector_analysis = analysis_result['sector_analysis']
        
        # ì£¼ë³„ ë³€í™”ê°€ ìˆëŠ” ì„¹í„° ì°¾ê¸°
        changing_sectors = []
        for sector, data in sector_analysis.items():
            if 'prediction' in data:
                pred = data['prediction']
                if pred['mention_trend'] != 'ìœ ì§€' or pred['sentiment_trend'] != 'ìœ ì§€':
                    changing_sectors.append({
                        'name': sector,
                        'mention_trend': pred['mention_trend'],
                        'sentiment_trend': pred['sentiment_trend']
                    })
        
        if not changing_sectors:
            return "ìµœê·¼ ì£¼ê°„ ë³€í™”ëŠ” í¬ì§€ ì•Šìœ¼ë©°, ëŒ€ë¶€ë¶„ì˜ ì„¹í„°ê°€ ì•ˆì •ì ì¸ ëª¨ìŠµì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤."
        
        # ë³€í™” ë¶„ì„
        improving_sectors = [s for s in changing_sectors if s['sentiment_trend'] == 'ê°œì„ ']
        worsening_sectors = [s for s in changing_sectors if s['sentiment_trend'] == 'ì•…í™”']
        
        comment = "ìµœê·¼ 1ì£¼ê°„ "
        if improving_sectors:
            comment += f"{', '.join([s['name'] for s in improving_sectors])} ì„¹í„°ì˜ ê°ì •ì´ ê°œì„ ë˜ì—ˆê³ , "
        if worsening_sectors:
            comment += f"{', '.join([s['name'] for s in worsening_sectors])} ì„¹í„°ì˜ ê°ì •ì´ ì•…í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
        
        # ë³€í™”ì˜ ì˜ë¯¸ í•´ì„
        if improving_sectors and not worsening_sectors:
            comment += "ì´ëŠ” ì‹œì¥ì´ ì „ë°˜ì ìœ¼ë¡œ ê°œì„ ë˜ê³  ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤."
        elif worsening_sectors and not improving_sectors:
            comment += "ì´ëŠ” ì‹œì¥ì´ ì „ë°˜ì ìœ¼ë¡œ ì•…í™”ë˜ê³  ìˆìŒì„ ì‹œì‚¬í•©ë‹ˆë‹¤."
        elif improving_sectors and worsening_sectors:
            comment += "ì´ëŠ” ì„¹í„° ê°„ ë¶„í™”ê°€ ì‹¬í™”ë˜ê³  ìˆìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤."
        else:
            comment += "ì´ëŠ” ì‹œì¥ì´ ì•ˆì •ì ì¸ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
        
        return comment
    
    def _generate_prediction_reason(self, analysis_result):
        """
        ì˜ˆì¸¡ ê·¼ê±° ìƒì„±
        
        Args:
            analysis_result (dict): ë¶„ì„ ê²°ê³¼
            
        Returns:
            str: ì˜ˆì¸¡ ê·¼ê±°
        """
        sector_analysis = analysis_result['sector_analysis']
        
        # ê¸ì •/ë¶€ì • ì˜ˆì¸¡ ì„¹í„° ë¶„ì„
        positive_sectors = []
        negative_sectors = []
        
        for sector, data in sector_analysis.items():
            if 'prediction' in data:
                pred = data['prediction']
                if pred['next_day_prediction'] == 'ê¸ì •':
                    positive_sectors.append(sector)
                elif pred['next_day_prediction'] == 'ë¶€ì •':
                    negative_sectors.append(sector)
        
        if not positive_sectors and not negative_sectors:
            return "ëª…í™•í•œ ì˜ˆì¸¡ ê·¼ê±°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
        
        reasons = []
        
        if positive_sectors:
            # ê¸ì • ì˜ˆì¸¡ ê·¼ê±°
            positive_reasons = []
            for sector in positive_sectors:
                data = sector_analysis[sector]
                if 'prediction' in data:
                    pred = data['prediction']
                    if pred['mention_trend'] == 'ì¦ê°€' and pred['sentiment_trend'] == 'ê°œì„ ':
                        positive_reasons.append(f"{sector}ì˜ ì–¸ê¸‰ ì¦ê°€ì™€ ê°ì • ê°œì„ ")
                    elif pred['mention_trend'] == 'ì¦ê°€':
                        positive_reasons.append(f"{sector}ì˜ ê´€ì‹¬ë„ ì¦ê°€")
                    elif pred['sentiment_trend'] == 'ê°œì„ ':
                        positive_reasons.append(f"{sector}ì˜ ê¸ì •ì  ë‰´ìŠ¤ ì¦ê°€")
            
            if positive_reasons:
                reasons.append(f"ê¸ì • ì˜ˆì¸¡: {', '.join(positive_reasons[:2])}")
        
        if negative_sectors:
            # ë¶€ì • ì˜ˆì¸¡ ê·¼ê±°
            negative_reasons = []
            for sector in negative_sectors:
                data = sector_analysis[sector]
                if 'prediction' in data:
                    pred = data['prediction']
                    if pred['mention_trend'] == 'ê°ì†Œ' and pred['sentiment_trend'] == 'ì•…í™”':
                        negative_reasons.append(f"{sector}ì˜ ì–¸ê¸‰ ê°ì†Œì™€ ê°ì • ì•…í™”")
                    elif pred['sentiment_trend'] == 'ì•…í™”':
                        negative_reasons.append(f"{sector}ì˜ ë¶€ì •ì  ë‰´ìŠ¤ ì¦ê°€")
            
            if negative_reasons:
                reasons.append(f"ë¶€ì • ì˜ˆì¸¡: {', '.join(negative_reasons[:2])}")
        
        return ' | '.join(reasons) if reasons else "íŠ¸ë Œë“œ ë³€í™” ê¸°ë°˜ ì˜ˆì¸¡"
    
    def _analyze_keyword_trend(self, keyword_evolution):
        """
        í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„
        
        Args:
            keyword_evolution (dict): í‚¤ì›Œë“œ ë³€í™” ë°ì´í„°
            
        Returns:
            str: í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ ì½”ë©˜íŠ¸
        """
        new_keywords = keyword_evolution.get('new_keywords', [])
        disappeared_keywords = keyword_evolution.get('disappeared_keywords', [])
        
        if not new_keywords and not disappeared_keywords:
            return "í‚¤ì›Œë“œ ë³€í™”ê°€ í¬ì§€ ì•Šì•„ ì•ˆì •ì ì¸ ì‹œì¥ ìƒí™©ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
        
        comment = ""
        
        if new_keywords:
            # ì‹ ê·œ í‚¤ì›Œë“œ ë¶„ì„
            tech_keywords = [kw for kw in new_keywords if kw in ['AI', 'ë°˜ë„ì²´', 'í…Œí¬', 'ì†Œí”„íŠ¸ì›¨ì–´']]
            finance_keywords = [kw for kw in new_keywords if kw in ['ê¸ˆë¦¬', 'Fed', 'ì—°ì¤€', 'ì€í–‰']]
            energy_keywords = [kw for kw in new_keywords if kw in ['ì„ìœ ', 'ê°€ìŠ¤', 'ì—ë„ˆì§€']]
            
            if tech_keywords:
                comment += f"ê¸°ìˆ  ê´€ë ¨ í‚¤ì›Œë“œ({', '.join(tech_keywords)})ê°€ ìƒˆë¡­ê²Œ ë¶€ìƒí•˜ê³  ìˆìœ¼ë©°, "
            if finance_keywords:
                comment += f"ê¸ˆìœµ ì •ì±… ê´€ë ¨ í‚¤ì›Œë“œ({', '.join(finance_keywords)})ê°€ ê´€ì‹¬ì„ ë°›ê³  ìˆê³ , "
            if energy_keywords:
                comment += f"ì—ë„ˆì§€ ê´€ë ¨ í‚¤ì›Œë“œ({', '.join(energy_keywords)})ê°€ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤. "
        
        if disappeared_keywords:
            comment += f"í•œí¸ {', '.join(disappeared_keywords[:2])} ë“±ì˜ í‚¤ì›Œë“œëŠ” ê´€ì‹¬ì´ ì¤„ì–´ë“¤ì—ˆìŠµë‹ˆë‹¤."
        
        return comment if comment else "í‚¤ì›Œë“œ ë³€í™”ê°€ ì‹œì¥ ê´€ì‹¬ì‚¬ ë³€í™”ë¥¼ ë°˜ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    
    def _analyze_global_trend(self, global_impact):
        """
        ê¸€ë¡œë²Œ íŠ¸ë Œë“œ ë¶„ì„
        
        Args:
            global_impact (dict): ê¸€ë¡œë²Œ ì˜í–¥ë„ ë°ì´í„°
            
        Returns:
            str: ê¸€ë¡œë²Œ íŠ¸ë Œë“œ ë¶„ì„ ì½”ë©˜íŠ¸
        """
        if not global_impact:
            return "ê¸€ë¡œë²Œ ì˜í–¥ë„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
        
        # ê°€ì¥ ì˜í–¥ë ¥ ìˆëŠ” ì§€ì—­ ì°¾ê¸°
        top_region = max(global_impact.items(), key=lambda x: x[1]['total_impact'])
        region_name, region_data = top_region
        
        # íŠ¸ë Œë“œ ë¶„ì„
        if region_data['trend'] == 'ì¦ê°€':
            trend_desc = "ê´€ì‹¬ì´ ì¦ê°€"
        elif region_data['trend'] == 'ê°ì†Œ':
            trend_desc = "ê´€ì‹¬ì´ ê°ì†Œ"
        else:
            trend_desc = "ì•ˆì •ì "
        
        # ì§€ì—­ë³„ íŠ¹ì„± ë¶„ì„
        region_characteristics = {
            'ë¯¸êµ­': 'ë¯¸êµ­ ê²½ì œ ì •ì±…ê³¼ ê¸ˆë¦¬ ë™í–¥',
            'ì¤‘êµ­': 'ì¤‘êµ­ ê²½ì œ ìƒí™©ê³¼ ë¬´ì—­ ê´€ê³„',
            'ìœ ëŸ½': 'ìœ ëŸ½ ê²½ì œì™€ ECB ì •ì±…',
            'ì¼ë³¸': 'ì¼ë³¸ ê²½ì œì™€ BOJ ì •ì±…',
            'í•œêµ­': 'í•œêµ­ ê²½ì œì™€ êµ­ë‚´ ì •ì±…'
        }
        
        characteristic = region_characteristics.get(region_name, 'í•´ë‹¹ ì§€ì—­ ê²½ì œ')
        
        return f"{region_name}ì´ ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ê³  ìˆìœ¼ë©°, {characteristic}ì— ëŒ€í•œ ê´€ì‹¬ì´ {trend_desc}í•˜ê³  ìˆìŠµë‹ˆë‹¤."
    
    def _perform_deep_market_analysis(self, historical_data):
        """
        ì‹¬ì¸µ ì‹œì¥ ë¶„ì„ ìˆ˜í–‰
        
        Args:
            historical_data (list): ê³¼ê±° ë‰´ìŠ¤ ë°ì´í„°
            
        Returns:
            dict: ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼
        """
        try:
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            all_texts = []
            dates = []
            for item in historical_data:
                text = f"{item.get('title', '')} {item.get('content', '')}"
                all_texts.append(text)
                dates.append(item.get('date', ''))
            
            if len(all_texts) < 5:
                return {"error": "ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}
            
            # TF-IDF ë²¡í„°í™”
            vectorizer = TfidfVectorizer(
                max_features=100,
                stop_words=None,
                ngram_range=(1, 2),
                min_df=2
            )
            
            tfidf_matrix = vectorizer.fit_transform(all_texts)
            feature_names = vectorizer.get_feature_names_out()
            
            # í† í”½ ëª¨ë¸ë§ (LDA)
            lda = LatentDirichletAllocation(
                n_components=min(5, len(all_texts)),
                random_state=42,
                max_iter=10
            )
            lda_output = lda.fit_transform(tfidf_matrix)
            
            # ì£¼ìš” í† í”½ ì¶”ì¶œ
            topics = []
            for topic_idx, topic in enumerate(lda.components_):
                top_words = [feature_names[i] for i in topic.argsort()[-5:]]
                topics.append({
                    'topic_id': topic_idx,
                    'keywords': top_words,
                    'weight': topic.max()
                })
            
            # ì‹œì¥ ë³€ë™ì„± ë¶„ì„
            volatility_analysis = self._analyze_market_volatility(historical_data)
            
            # ì„¹í„° ìƒê´€ê´€ê³„ ë¶„ì„
            correlation_analysis = self._analyze_sector_correlation(historical_data)
            
            # ë‰´ìŠ¤ ì„íŒ©íŠ¸ ìŠ¤ì½”ì–´ë§
            impact_scores = self._calculate_news_impact_scores(historical_data)
            
            return {
                'topics': topics,
                'volatility': volatility_analysis,
                'correlations': correlation_analysis,
                'impact_scores': impact_scores,
                'tfidf_features': feature_names[:20].tolist()
            }
            
        except Exception as e:
            return {"error": f"ì‹¬ì¸µ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
    
    def _analyze_market_volatility(self, historical_data):
        """
        ì‹œì¥ ë³€ë™ì„± ë¶„ì„
        
        Args:
            historical_data (list): ê³¼ê±° ë‰´ìŠ¤ ë°ì´í„°
            
        Returns:
            dict: ë³€ë™ì„± ë¶„ì„ ê²°ê³¼
        """
        # ì¼ë³„ ë‰´ìŠ¤ ë¹ˆë„ ë¶„ì„
        daily_counts = defaultdict(int)
        daily_sentiments = defaultdict(list)
        
        for item in historical_data:
            date = item.get('date', '')
            daily_counts[date] += 1
            
            # ê°ì • ë¶„ì„
            text = f"{item.get('title', '')} {item.get('content', '')}"
            sentiment = self._calculate_text_sentiment(text)
            daily_sentiments[date].append(sentiment)
        
        # ë³€ë™ì„± ê³„ì‚°
        if len(daily_counts) > 1:
            counts = list(daily_counts.values())
            volatility = np.std(counts) / np.mean(counts) if np.mean(counts) > 0 else 0
            
            # ê°ì • ë³€ë™ì„±
            sentiment_volatility = 0
            if daily_sentiments:
                avg_sentiments = [np.mean(sentiments) for sentiments in daily_sentiments.values() if sentiments]
                if len(avg_sentiments) > 1:
                    sentiment_volatility = np.std(avg_sentiments)
            
            return {
                'news_volatility': volatility,
                'sentiment_volatility': sentiment_volatility,
                'high_volatility_days': [date for date, count in daily_counts.items() if count > np.mean(counts) + np.std(counts)],
                'low_volatility_days': [date for date, count in daily_counts.items() if count < np.mean(counts) - np.std(counts)]
            }
        
        return {'news_volatility': 0, 'sentiment_volatility': 0}
    
    def _analyze_sector_correlation(self, historical_data):
        """
        ì„¹í„° ê°„ ìƒê´€ê´€ê³„ ë¶„ì„
        
        Args:
            historical_data (list): ê³¼ê±° ë‰´ìŠ¤ ë°ì´í„°
            
        Returns:
            dict: ìƒê´€ê´€ê³„ ë¶„ì„ ê²°ê³¼
        """
        sector_keywords = {
            'ê¸°ìˆ ': ['AI', 'ë°˜ë„ì²´', 'ì†Œí”„íŠ¸ì›¨ì–´', 'í…Œí¬', 'ë””ì§€í„¸'],
            'ê¸ˆìœµ': ['ê¸ˆë¦¬', 'Fed', 'ì—°ì¤€', 'ì€í–‰', 'íˆ¬ì'],
            'ì—ë„ˆì§€': ['ì„ìœ ', 'ê°€ìŠ¤', 'ì—ë„ˆì§€', 'ì›ìì¬'],
            'ì œì¡°ì—…': ['ì œì¡°', 'ê³µì¥', 'ìƒì‚°', 'ì‚°ì—…'],
            'ì†Œë¹„ì¬': ['ì†Œë¹„', 'ì†Œë§¤', 'ìœ í†µ', 'ë§ˆì¼€íŒ…']
        }
        
        # ì¼ë³„ ì„¹í„°ë³„ ì–¸ê¸‰ íšŸìˆ˜
        daily_sector_mentions = defaultdict(lambda: defaultdict(int))
        
        for item in historical_data:
            date = item.get('date', '')
            text = f"{item.get('title', '')} {item.get('content', '')}"
            
            for sector, keywords in sector_keywords.items():
                for keyword in keywords:
                    if keyword.lower() in text.lower():
                        daily_sector_mentions[date][sector] += 1
                        break
        
        # ìƒê´€ê´€ê³„ ê³„ì‚°
        if len(daily_sector_mentions) > 1:
            dates = sorted(daily_sector_mentions.keys())
            sectors = list(sector_keywords.keys())
            
            # ì„¹í„°ë³„ ì¼ë³„ ì–¸ê¸‰ íšŸìˆ˜ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
            mention_matrix = []
            for date in dates:
                row = [daily_sector_mentions[date].get(sector, 0) for sector in sectors]
                mention_matrix.append(row)
            
            if len(mention_matrix) > 1:
                df = pd.DataFrame(mention_matrix, columns=sectors)
                correlation_matrix = df.corr()
                
                # ë†’ì€ ìƒê´€ê´€ê³„ ì°¾ê¸°
                high_correlations = []
                for i in range(len(sectors)):
                    for j in range(i+1, len(sectors)):
                        corr = correlation_matrix.iloc[i, j]
                        if abs(corr) > 0.5:  # ìƒê´€ê³„ìˆ˜ 0.5 ì´ìƒ
                            high_correlations.append({
                                'sector1': sectors[i],
                                'sector2': sectors[j],
                                'correlation': corr
                            })
                
                return {
                    'correlation_matrix': correlation_matrix.to_dict(),
                    'high_correlations': high_correlations
                }
        
        return {'correlation_matrix': {}, 'high_correlations': []}
    
    def _calculate_news_impact_scores(self, historical_data):
        """
        ë‰´ìŠ¤ ì„íŒ©íŠ¸ ìŠ¤ì½”ì–´ ê³„ì‚°
        
        Args:
            historical_data (list): ê³¼ê±° ë‰´ìŠ¤ ë°ì´í„°
            
        Returns:
            list: ì„íŒ©íŠ¸ ìŠ¤ì½”ì–´ê°€ ë†’ì€ ë‰´ìŠ¤ ëª©ë¡
        """
        impact_scores = []
        
        for item in historical_data:
            title = item.get('title', '')
            content = item.get('content', '')
            date = item.get('date', '')
            
            # ì„íŒ©íŠ¸ ìŠ¤ì½”ì–´ ê³„ì‚° ìš”ì†Œë“¤
            score = 0
            
            # 1. ì œëª© ê¸¸ì´ (ì ë‹¹í•œ ê¸¸ì´ê°€ ì„íŒ©íŠ¸ ë†’ìŒ)
            title_length = len(title)
            if 20 <= title_length <= 60:
                score += 2
            elif title_length > 60:
                score += 1
            
            # 2. ê°ì • ê°•ë„
            sentiment = self._calculate_text_sentiment(f"{title} {content}")
            score += abs(sentiment) * 3
            
            # 3. í‚¤ì›Œë“œ ì¤‘ìš”ë„
            important_keywords = ['ê¸´ê¸‰', 'ì†ë³´', 'íŠ¹ë³„', 'ì¤‘ìš”', 'ëŒ€í­', 'ê¸‰ë“±', 'í­ë½', 'ìœ„ê¸°', 'í˜¸ì¬', 'ì•…ì¬']
            for keyword in important_keywords:
                if keyword in title or keyword in content:
                    score += 2
            
            # 4. ìˆ«ì í¬í•¨ (êµ¬ì²´ì  ìˆ˜ì¹˜)
            if re.search(r'\d+', title) or re.search(r'\d+', content):
                score += 1
            
            # 5. ê¸€ë¡œë²Œ í‚¤ì›Œë“œ
            global_keywords = ['ë¯¸êµ­', 'ì¤‘êµ­', 'ìœ ëŸ½', 'Fed', 'ECB', 'BOJ']
            for keyword in global_keywords:
                if keyword in title or keyword in content:
                    score += 1
            
            impact_scores.append({
                'date': date,
                'title': title,
                'impact_score': score,
                'sentiment': sentiment
            })
        
        # ì„íŒ©íŠ¸ ìŠ¤ì½”ì–´ ìˆœìœ¼ë¡œ ì •ë ¬
        impact_scores.sort(key=lambda x: x['impact_score'], reverse=True)
        return impact_scores[:10]  # ìƒìœ„ 10ê°œë§Œ ë°˜í™˜
    
    def _calculate_text_sentiment(self, text):
        """
        í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ (TextBlob ì‚¬ìš©)
        
        Args:
            text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            float: ê°ì • ì ìˆ˜ (-1 ~ 1)
        """
        try:
            # í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì—¬ ê°ì • ë¶„ì„
            # (TextBlobì€ ì˜ì–´ì— ìµœì í™”ë˜ì–´ ìˆìŒ)
            blob = TextBlob(text)
            return blob.sentiment.polarity
        except:
            # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„
            return self._keyword_based_sentiment(text)
    
    def _keyword_based_sentiment(self, text):
        """
        í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì • ë¶„ì„ (í•œêµ­ì–´)
        
        Args:
            text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            float: ê°ì • ì ìˆ˜ (-1 ~ 1)
        """
        positive_words = ['ìƒìŠ¹', 'í˜¸ì¡°', 'ì„±ì¥', 'ê¸°ëŒ€', 'ê¸ì •', 'íšŒë³µ', 'ê°œì„ ', 'í˜¸ì¬', 'ëŒíŒŒ', 'ê¸‰ë“±']
        negative_words = ['í•˜ë½', 'ì•½ì„¸', 'ë¶€ì •', 'ìœ„í—˜', 'ìš°ë ¤', 'ì¶©ê²©', 'ì•…ì¬', 'í­ë½', 'ê¸‰ë½']
        
        text_lower = text.lower()
        positive_count = sum(1 for word in positive_words if word in text_lower)
        negative_count = sum(1 for word in negative_words if word in text_lower)
        
        total = positive_count + negative_count
        if total == 0:
            return 0
        
        return (positive_count - negative_count) / total
    
    def _generate_insightful_analysis(self, analysis_result, deep_analysis):
        """
        ì¸ì‚¬ì´íŠ¸ ìˆëŠ” ë¶„ì„ ì½”ë©˜íŠ¸ ìƒì„±
        
        Args:
            analysis_result (dict): ê¸°ë³¸ ë¶„ì„ ê²°ê³¼
            deep_analysis (dict): ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼
            
        Returns:
            str: ì¸ì‚¬ì´íŠ¸ ìˆëŠ” ë¶„ì„ ì½”ë©˜íŠ¸
        """
        insights = []
        
        # 1. ì‹œì¥ ë³€ë™ì„± ì¸ì‚¬ì´íŠ¸
        if 'volatility' in deep_analysis and not isinstance(deep_analysis['volatility'], str):
            volatility = deep_analysis['volatility']
            if volatility.get('news_volatility', 0) > 0.5:
                insights.append("ğŸ“Š ì‹œì¥ ë³€ë™ì„±ì´ ë†’ì•„ ë¶ˆí™•ì‹¤ì„±ì´ ì¦ê°€í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            elif volatility.get('news_volatility', 0) < 0.2:
                insights.append("ğŸ“Š ì‹œì¥ì´ ì•ˆì •ì ì¸ ëª¨ìŠµì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # 2. ì„¹í„° ìƒê´€ê´€ê³„ ì¸ì‚¬ì´íŠ¸
        if 'correlations' in deep_analysis and not isinstance(deep_analysis['correlations'], str):
            correlations = deep_analysis['correlations']
            high_corrs = correlations.get('high_correlations', [])
            if high_corrs:
                top_corr = max(high_corrs, key=lambda x: abs(x['correlation']))
                insights.append(f"ğŸ”— {top_corr['sector1']}ì™€ {top_corr['sector2']} ì„¹í„°ê°€ ê°•í•œ ìƒê´€ê´€ê³„({top_corr['correlation']:.2f})ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # 3. ì£¼ìš” í† í”½ ì¸ì‚¬ì´íŠ¸
        if 'topics' in deep_analysis and not isinstance(deep_analysis['topics'], str):
            topics = deep_analysis['topics']
            if topics:
                main_topic = max(topics, key=lambda x: x['weight'])
                insights.append(f"ğŸ¯ ì£¼ìš” ê´€ì‹¬ì‚¬: {', '.join(main_topic['keywords'][:3])}")
        
        # 4. ì„íŒ©íŠ¸ ë†’ì€ ë‰´ìŠ¤ ì¸ì‚¬ì´íŠ¸
        if 'impact_scores' in deep_analysis and not isinstance(deep_analysis['impact_scores'], str):
            impact_scores = deep_analysis['impact_scores']
            if impact_scores:
                top_impact = impact_scores[0]
                if top_impact['impact_score'] > 5:
                    insights.append(f"ğŸ’¥ ìµœê³  ì„íŒ©íŠ¸ ë‰´ìŠ¤: {top_impact['title'][:30]}... (ì„íŒ©íŠ¸ ì ìˆ˜: {top_impact['impact_score']})")
        
        # 5. ì‹œì¥ ì‚¬ì´í´ ì¸ì‚¬ì´íŠ¸
        sector_analysis = analysis_result.get('sector_analysis', {})
        if sector_analysis:
            positive_sectors = [s for s in sector_analysis.items() if s[1]['sentiment'] == 'ê¸ì •']
            negative_sectors = [s for s in sector_analysis.items() if s[1]['sentiment'] == 'ë¶€ì •']
            
            if len(positive_sectors) >= 3 and len(negative_sectors) <= 1:
                insights.append("ğŸš€ ì‹œì¥ì´ ì „ë°˜ì ìœ¼ë¡œ ê°•ì„¸ ëª¨ë“œì— ì§„ì…í•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.")
            elif len(negative_sectors) >= 3 and len(positive_sectors) <= 1:
                insights.append("âš ï¸ ì‹œì¥ì´ ì „ë°˜ì ìœ¼ë¡œ ì•½ì„¸ ëª¨ë“œì— ì§„ì…í•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.")
            elif len(positive_sectors) == len(negative_sectors):
                insights.append("âš–ï¸ ì‹œì¥ì´ í˜¼ì¡°ì„¸ë¥¼ ë³´ì´ë©° ë°©í–¥ì„±ì„ ì°¾ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # ì¸ì‚¬ì´íŠ¸ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ë¶„ì„ ì œê³µ
        if not insights:
            sector_analysis = analysis_result.get('sector_analysis', {})
            if sector_analysis:
                total_mentions = sum(data['mentions'] for data in sector_analysis.values())
                if total_mentions > 0:
                    insights.append(f"ğŸ“Š ì´ {total_mentions}íšŒì˜ ì„¹í„° ì–¸ê¸‰ì„ í†µí•´ ì‹œì¥ ë™í–¥ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.")
                    insights.append("ğŸ“ˆ í˜„ì¬ ì‹œì¥ì€ ì•ˆì •ì ì¸ ëª¨ìŠµì„ ë³´ì´ê³  ìˆìœ¼ë©°, íŠ¹ë³„í•œ ë³€ë™ì„±ì€ ê´€ì°°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    insights.append("ğŸ“Š ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì‹¬ì¸µ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.")
            else:
                insights.append("ğŸ“Š ì‹œì¥ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ì‹¬ì¸µ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return '\n\n'.join(insights)
    
    def _generate_investment_strategy(self, analysis_result):
        """
        íˆ¬ì ì „ëµ ê°€ì´ë“œ ìƒì„±
        
        Args:
            analysis_result (dict): ë¶„ì„ ê²°ê³¼
            
        Returns:
            str: íˆ¬ì ì „ëµ ê°€ì´ë“œ
        """
        sector_analysis = analysis_result.get('sector_analysis', {})
        if not sector_analysis:
            return "ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
        
        strategies = []
        
        # 1. ì‹œì¥ ë¶„ìœ„ê¸° ë¶„ì„
        positive_count = len([s for s in sector_analysis.items() if s[1]['sentiment'] == 'ê¸ì •'])
        negative_count = len([s for s in sector_analysis.items() if s[1]['sentiment'] == 'ë¶€ì •'])
        total_sectors = len(sector_analysis)
        
        if total_sectors > 0:
            positive_ratio = positive_count / total_sectors
            
            if positive_ratio >= 0.6:
                strategies.append("ğŸ“ˆ ê³µê²©ì  ì„±ì¥ ì „ëµ")
                strategies.append("   â€¢ ê¸ì • ì„¹í„° ë¹„ì¤‘ 70% í™•ëŒ€")
                strategies.append("   â€¢ ë ˆë²„ë¦¬ì§€ ETF ê³ ë ¤")
            elif positive_ratio <= 0.3:
                strategies.append("ğŸ“‰ ë³´ìˆ˜ì  ë°©ì–´ ì „ëµ")
                strategies.append("   â€¢ í˜„ê¸ˆ ë¹„ì¤‘ 60% ìœ ì§€")
                strategies.append("   â€¢ ì±„ê¶Œí˜• ETF ë¹„ì¤‘ í™•ëŒ€")
            else:
                strategies.append("âš–ï¸ ê· í˜•ì  ë¶„ì‚° ì „ëµ")
                strategies.append("   â€¢ ì„¹í„°ë³„ ë¶„ì‚° íˆ¬ì")
                strategies.append("   â€¢ ì›” ì •ê¸° ë¦¬ë°¸ëŸ°ì‹±")
        
        # 2. êµ¬ì²´ì ì¸ ì•¡ì…˜ ì•„ì´í…œ
        buy_opportunities = []
        for sector, data in sector_analysis.items():
            if 'prediction' in data:
                pred = data['prediction']
                if pred['next_day_prediction'] == 'ê¸ì •' and pred['prediction_confidence'] >= 0.7:
                    buy_opportunities.append(sector)
        
        if buy_opportunities:
            strategies.append(f"ğŸ’¼ ì¦‰ì‹œ ë§¤ìˆ˜: {', '.join(buy_opportunities)}")
        
        # 3. ë¦¬ìŠ¤í¬ ê´€ë¦¬
        risk_sectors = []
        for sector, data in sector_analysis.items():
            if 'prediction' in data:
                pred = data['prediction']
                if pred['next_day_prediction'] == 'ë¶€ì •' and pred['prediction_confidence'] >= 0.7:
                    risk_sectors.append(sector)
        
        if risk_sectors:
            strategies.append(f"ğŸ›¡ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬: {', '.join(risk_sectors)} ë¹„ì¤‘ ì¶•ì†Œ")
        
        # 4. í¬íŠ¸í´ë¦¬ì˜¤ ì¡°ì–¸
        if len(buy_opportunities) >= 2:
            strategies.append("ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤: ì„±ì¥ì£¼ 60%, ê°€ì¹˜ì£¼ 30%, í˜„ê¸ˆ 10%")
        elif len(buy_opportunities) == 1:
            strategies.append("ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤: ì„ íƒì  ì„±ì¥ì£¼ 40%, ì•ˆì •ì£¼ 40%, í˜„ê¸ˆ 20%")
        else:
            strategies.append("ğŸ“Š í¬íŠ¸í´ë¦¬ì˜¤: ì•ˆì •ì£¼ 50%, í˜„ê¸ˆ 50%")
        
        return '\n'.join(strategies)
    
    def _generate_risk_management(self, analysis_result, deep_analysis):
        """
        ë¦¬ìŠ¤í¬ ê´€ë¦¬ í¬ì¸íŠ¸ ìƒì„±
        
        Args:
            analysis_result (dict): ë¶„ì„ ê²°ê³¼
            deep_analysis (dict): ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼
            
        Returns:
            str: ë¦¬ìŠ¤í¬ ê´€ë¦¬ í¬ì¸íŠ¸
        """
        risk_points = []
        
        # 1. ì‹œì¥ ë³€ë™ì„± ë¦¬ìŠ¤í¬
        if 'volatility' in deep_analysis and not isinstance(deep_analysis['volatility'], str):
            volatility = deep_analysis['volatility']
            if volatility.get('news_volatility', 0) > 0.5:
                risk_points.append("ğŸ“Š **ì‹œì¥ ë³€ë™ì„± ì¦ê°€** â†’ ìŠ¤íƒ‘ë¡œìŠ¤ ì„¤ì • ê°•í™” í•„ìš”")
                risk_points.append("   â†’ í¬ì§€ì…˜ í¬ê¸° ì¶•ì†Œ, ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê°•í™”")
            elif volatility.get('news_volatility', 0) < 0.2:
                risk_points.append("ğŸ“Š **ì‹œì¥ ì•ˆì •ì„±** â†’ ê¸°ì¡´ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ìœ ì§€")
        
        # 2. ì„¹í„° ë¶„í™” ë¦¬ìŠ¤í¬
        sector_analysis = analysis_result.get('sector_analysis', {})
        positive_sectors = [s for s in sector_analysis.items() if s[1]['sentiment'] == 'ê¸ì •']
        negative_sectors = [s for s in sector_analysis.items() if s[1]['sentiment'] == 'ë¶€ì •']
        
        if positive_sectors and negative_sectors:
            risk_points.append("ğŸ”€ **ì„¹í„° ë¶„í™” ì‹¬í™”** â†’ í¬íŠ¸í´ë¦¬ì˜¤ ë‹¤ê°í™” ì ê²€ í•„ìš”")
            risk_points.append("   â†’ ê³¼ë„í•œ íŠ¹ì • ì„¹í„° ì§‘ì¤‘ë„ í™•ì¸")
        
        # 3. ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬
        global_impact = analysis_result.get('global_impact', {})
        if global_impact:
            top_region = max(global_impact.items(), key=lambda x: x[1]['total_impact'])
            if top_region[0] in ['ë¯¸êµ­', 'ì¤‘êµ­', 'ìœ ëŸ½']:
                risk_points.append(f"ğŸŒ **ê¸€ë¡œë²Œ ë¦¬ìŠ¤í¬**: {top_region[0]} ì˜í–¥ë„ ì¦ê°€")
                risk_points.append("   â†’ í™˜ìœ¨ ë¦¬ìŠ¤í¬, ê¸€ë¡œë²Œ ì´ë²¤íŠ¸ ëª¨ë‹ˆí„°ë§ ê°•í™”")
        
        # 4. ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¦¬ìŠ¤í¬
        low_confidence_predictions = []
        for sector, data in sector_analysis.items():
            if 'prediction' in data:
                pred = data['prediction']
                if pred['prediction_confidence'] < 0.6:
                    low_confidence_predictions.append(sector)
        
        if low_confidence_predictions:
            risk_points.append(f"â“ **ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„±**: {', '.join(low_confidence_predictions)} ì„¹í„°")
            risk_points.append("   â†’ ë³´ìˆ˜ì  ì ‘ê·¼, ì¶”ê°€ ëª¨ë‹ˆí„°ë§ í•„ìš”")
        
        # 5. ì‹œì¥ ì‚¬ì´í´ ë¦¬ìŠ¤í¬
        if len(positive_sectors) >= 4 and len(negative_sectors) <= 1:
            risk_points.append("ğŸš€ **ê°•ì„¸ ëª¨ë“œ** â†’ ê³¼ì—´ ìœ„í—˜ ì£¼ì˜")
            risk_points.append("   â†’ ì´ìµ ì‹¤í˜„, ë¦¬ìŠ¤í¬ ê´€ë¦¬ ê°•í™”")
        elif len(negative_sectors) >= 4 and len(positive_sectors) <= 1:
            risk_points.append("âš ï¸ **ì•½ì„¸ ëª¨ë“œ** â†’ ì¶”ê°€ í•˜ë½ ìœ„í—˜")
            risk_points.append("   â†’ ë°©ì–´ì  í¬ì§€ì…˜, í˜„ê¸ˆ ë¹„ì¤‘ í™•ëŒ€")
        
        # 6. ì‹¤ì‹œê°„ ë¦¬ìŠ¤í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸
        risk_points.append("\nğŸ“‹ **ë¦¬ìŠ¤í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸**")
        risk_points.append("â–¡ í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ ì ê²€ (30ë¶„)")
        risk_points.append("â–¡ ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ìì‚° ë¹„ì¤‘ ì¡°ì • (1ì‹œê°„)")
        risk_points.append("â–¡ ìŠ¤íƒ‘ë¡œìŠ¤ ì„¤ì • í™•ì¸ (ì¦‰ì‹œ)")
        risk_points.append("â–¡ ê¸€ë¡œë²Œ ì´ë²¤íŠ¸ ëª¨ë‹ˆí„°ë§ (ì§€ì†)")
        
        return '\n'.join(risk_points)
    
    def _generate_simple_summary(self, analysis_result):
        """
        ê°„ë‹¨í•œ ìš”ì•½ ìƒì„± (ì›¹í›…ìš©)
        
        Args:
            analysis_result (dict): ë¶„ì„ ê²°ê³¼
            
        Returns:
            str: ê°„ë‹¨í•œ ìš”ì•½
        """
        sector_analysis = analysis_result.get('sector_analysis', {})
        total_articles = analysis_result.get('total_articles', 0)
        
        if not sector_analysis:
            return f"ğŸ“Š {total_articles}ê±´ ë¶„ì„ ì™„ë£Œ\nâš ï¸ ë¶„ì„ ë°ì´í„° ë¶€ì¡±"
        
        # ì„¹í„°ë³„ í˜„í™© (ìƒìœ„ 3ê°œ)
        top_sectors = sorted(sector_analysis.items(), key=lambda x: x[1]['mentions'], reverse=True)[:3]
        
        # íˆ¬ì ê¸°íšŒ ì„¹í„° (ê¸ì • ì˜ˆì¸¡)
        buy_opportunities = []
        for sector, data in sector_analysis.items():
            if 'prediction' in data:
                pred = data['prediction']
                if pred['next_day_prediction'] == 'ê¸ì •' and pred['prediction_confidence'] >= 0.7:
                    buy_opportunities.append(sector)
        
        # ë¦¬ìŠ¤í¬ ì„¹í„° (ë¶€ì • ì˜ˆì¸¡)
        risk_sectors = []
        for sector, data in sector_analysis.items():
            if 'prediction' in data:
                pred = data['prediction']
                if pred['next_day_prediction'] == 'ë¶€ì •' and pred['prediction_confidence'] >= 0.7:
                    risk_sectors.append(sector)
        
        # ì‹œì¥ ë¶„ìœ„ê¸° ë¶„ì„
        positive_count = len([s for s in sector_analysis.items() if s[1]['sentiment'] == 'ê¸ì •'])
        negative_count = len([s for s in sector_analysis.items() if s[1]['sentiment'] == 'ë¶€ì •'])
        total_sectors = len(sector_analysis)
        
        if total_sectors > 0:
            positive_ratio = positive_count / total_sectors
            if positive_ratio >= 0.6:
                market_mood = "ìƒìŠ¹ì„¸"
            elif positive_ratio <= 0.3:
                market_mood = "í•˜ë½ì„¸"
            else:
                market_mood = "í˜¼ì¡°ì„¸"
        else:
            market_mood = "ë¶ˆë¶„ëª…"
        
        # íˆ¬ì ì „ëµ ì œì•ˆ
        if positive_ratio >= 0.6:
            strategy = "ê³µê²©ì : ê¸ì • ì„¹í„° ë¹„ì¤‘ í™•ëŒ€"
        elif positive_ratio <= 0.3:
            strategy = "ë³´ìˆ˜ì : í˜„ê¸ˆ ë¹„ì¤‘ 50% ìœ ì§€"
        else:
            strategy = "ê· í˜•ì : ì„¹í„°ë³„ ë¶„ì‚° íˆ¬ì"
        
        summary_parts = []
        
        # ê¸°ë³¸ ì •ë³´
        summary_parts.append(f"ğŸ“Š {total_articles}ê±´ ë¶„ì„ ì™„ë£Œ")
        
        # ì£¼ìš” ì„¹í„° í˜„í™©
        if top_sectors:
            sector_info = []
            for sector, data in top_sectors:
                sentiment_emoji = "ğŸ“ˆ" if data['sentiment'] == 'ê¸ì •' else "ğŸ“‰" if data['sentiment'] == 'ë¶€ì •' else "â¡ï¸"
                sector_info.append(f"{sector}({data['mentions']}íšŒ {sentiment_emoji})")
            summary_parts.append(f"ğŸ­ ì£¼ìš” ì„¹í„°: {', '.join(sector_info)}")
        
        # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
        if buy_opportunities:
            summary_parts.append(f"ğŸ“ˆ ë§¤ìˆ˜ ê¸°íšŒ: {', '.join(buy_opportunities)}")
        
        if risk_sectors:
            summary_parts.append(f"âš ï¸ ì£¼ì˜ ì„¹í„°: {', '.join(risk_sectors)}")
        
        # ì‹œì¥ ë¶„ìœ„ê¸°
        summary_parts.append(f"ğŸ¯ ì‹œì¥ ë¶„ìœ„ê¸°: {market_mood}")
        
        # íˆ¬ì ì „ëµ
        summary_parts.append(f"ğŸ’¼ íˆ¬ì ì „ëµ: {strategy}")
        
        return '\n'.join(summary_parts)
    
    def _generate_market_insight(self, analysis_result):
        """
        í•µì‹¬ ì‹œì¥ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        
        Args:
            analysis_result (dict): ë¶„ì„ ê²°ê³¼
            
        Returns:
            str: í•µì‹¬ ì¸ì‚¬ì´íŠ¸
        """
        sector_analysis = analysis_result.get('sector_analysis', {})
        if not sector_analysis:
            return "ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."
        
        insights = []
        
        # 1. ì‹œì¥ ë¶„ìœ„ê¸° ë¶„ì„
        positive_count = len([s for s in sector_analysis.items() if s[1]['sentiment'] == 'ê¸ì •'])
        negative_count = len([s for s in sector_analysis.items() if s[1]['sentiment'] == 'ë¶€ì •'])
        total_sectors = len(sector_analysis)
        
        if total_sectors > 0:
            positive_ratio = positive_count / total_sectors
            
            if positive_ratio >= 0.6:
                insights.append("ğŸ“ˆ ì‹œì¥ì´ ê°•í•œ ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
            elif positive_ratio <= 0.3:
                insights.append("ğŸ“‰ ì‹œì¥ì´ ê°•í•œ í•˜ë½ì„¸ë¥¼ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤.")
            else:
                insights.append("âš–ï¸ ì‹œì¥ì´ í˜¼ì¡°ì„¸ë¥¼ ë³´ì´ë©° ë°©í–¥ì„±ì„ ì°¾ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
        
        # 2. íˆ¬ì ê¸°íšŒ ì„¹í„°
        buy_opportunities = []
        for sector, data in sector_analysis.items():
            if 'prediction' in data:
                pred = data['prediction']
                if pred['next_day_prediction'] == 'ê¸ì •' and pred['prediction_confidence'] >= 0.7:
                    buy_opportunities.append(sector)
        
        if buy_opportunities:
            insights.append(f"ğŸ’¡ ë§¤ìˆ˜ ê¸°íšŒ: {', '.join(buy_opportunities)}")
        
        # 3. ë¦¬ìŠ¤í¬ ì„¹í„°
        risk_sectors = []
        for sector, data in sector_analysis.items():
            if 'prediction' in data:
                pred = data['prediction']
                if pred['next_day_prediction'] == 'ë¶€ì •' and pred['prediction_confidence'] >= 0.7:
                    risk_sectors.append(sector)
        
        if risk_sectors:
            insights.append(f"âš ï¸ ì£¼ì˜ ì„¹í„°: {', '.join(risk_sectors)}")
        
        # 4. ì„¹í„° ê°„ ë¶„í™”
        if len(buy_opportunities) > 0 and len(risk_sectors) > 0:
            insights.append("ğŸ”€ ì„¹í„° ê°„ ë¶„í™”ê°€ ì‹¬í™”ë˜ì–´ ì„ íƒì  íˆ¬ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # 5. ì˜ˆì¸¡ ì‹ ë¢°ë„
        high_confidence_count = 0
        for sector, data in sector_analysis.items():
            if 'prediction' in data and data['prediction']['prediction_confidence'] >= 0.8:
                high_confidence_count += 1
        
        if high_confidence_count >= 2:
            insights.append("ğŸ¯ ë†’ì€ ì‹ ë¢°ë„ì˜ ì˜ˆì¸¡ì´ ë‹¤ìˆ˜ ìˆì–´ íˆ¬ì ê¸°íšŒê°€ ëª…í™•í•©ë‹ˆë‹¤.")
        elif high_confidence_count == 0:
            insights.append("ğŸ¤” ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë‚®ì•„ ê´€ë§ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        return '\n'.join(insights)
    
    def _analyze_global_impact(self, historical_data):
        """
        ê¸€ë¡œë²Œ ì´ë²¤íŠ¸ ì˜í–¥ë„ ë¶„ì„
        
        Args:
            historical_data (list): ê³¼ê±° ë°ì´í„°
            
        Returns:
            dict: ê¸€ë¡œë²Œ ì˜í–¥ë„ ë¶„ì„ ê²°ê³¼
        """
        global_regions = {
            'ë¯¸êµ­': ['ë¯¸êµ­', 'ì›Œì‹±í„´', 'ë‰´ìš•', 'íŠ¸ëŸ¼í”„', 'ë°”ì´ë“ ', 'ë‹¬ëŸ¬'],
            'ì¤‘êµ­': ['ì¤‘êµ­', 'ë² ì´ì§•', 'ì‹œì§„í•‘', 'ìœ„ì•ˆ', 'ì¤‘êµ­ê²½ì œ'],
            'ìœ ëŸ½': ['ìœ ëŸ½', 'EU', 'ë…ì¼', 'í”„ë‘ìŠ¤', 'ìœ ë¡œ', 'ECB'],
            'ì¼ë³¸': ['ì¼ë³¸', 'ë„ì¿„', 'ì•„ë² ', 'ì—”', 'ì¼ë³¸ì€í–‰'],
            'í•œêµ­': ['í•œêµ­', 'ì„œìš¸', 'ì›í™”', 'í•œêµ­ì€í–‰', 'í•œêµ­ê²½ì œ']
        }
        
        global_impact = {}
        for region, keywords in global_regions.items():
            impact_score = 0
            recent_mentions = 0
            
            for data in historical_data:
                content = data.get('content', '') + ' ' + data.get('title', '')
                keyword_count = sum(content.count(keyword) for keyword in keywords)
                
                if keyword_count > 0:
                    impact_score += keyword_count
                    if data['days_ago'] <= 7:
                        recent_mentions += keyword_count
            
            global_impact[region] = {
                'total_impact': impact_score,
                'recent_mentions': recent_mentions,
                'trend': 'ì¦ê°€' if recent_mentions > impact_score / 4 else 'ê°ì†Œ' if recent_mentions < impact_score / 4 else 'ìœ ì§€'
            }
        
        return global_impact
    
    def _extract_keywords(self, text):
        """
        í…ìŠ¤íŠ¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
        
        Args:
            text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            list: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ë¹ˆë„ìˆœ)
        """
        # ì£¼ìš” ê²½ì œ/ê¸ˆìœµ í‚¤ì›Œë“œ
        keywords = [
            'ë‹¬ëŸ¬', 'ì—”', 'ìœ ë¡œ', 'ìœ„ì•ˆ', 'ì›í™”', 'í™˜ìœ¨', 'DXY',
            'ì½”ìŠ¤í”¼', 'ë‚˜ìŠ¤ë‹¥', 'ë‹¤ìš°', 'S&P', 'ì£¼ì‹', 'ì±„ê¶Œ', 'ê¸ˆë¦¬',
            'Fed', 'ì—°ì¤€', 'FOMC', 'íŒŒì›”', 'ì¸í”Œë ˆì´ì…˜', 'GDP',
            'ë¬´ì—­', 'ê´€ì„¸', 'í˜‘ìƒ', 'í•©ì˜', 'íŠ¸ëŸ¼í”„', 'ë°”ì´ë“ ',
            'ì¤‘êµ­', 'ì¼ë³¸', 'ìœ ëŸ½', 'EU', 'ì›ìœ ', 'WTI', 'ë¸Œë ŒíŠ¸',
            'ê¸ˆ', 'ì€', 'êµ¬ë¦¬', 'ì² ê°•', 'ë°˜ë„ì²´', 'AI', 'í…Œí¬'
        ]
        
        keyword_freq = {}
        for keyword in keywords:
            freq = text.count(keyword)
            if freq > 0:
                keyword_freq[keyword] = freq
        
        # ë¹ˆë„ìˆœ ì •ë ¬
        return sorted(keyword_freq.items(), key=lambda x: x[1], reverse=True)
    
    def _send_type_analysis(self, news_type, display_name, emoji, analysis_result):
        """
        ë‰´ìŠ¤ íƒ€ì…ë³„ ë¶„ì„ ê²°ê³¼ë¥¼ ë³„ë„ ë§í’ì„ ìœ¼ë¡œ ì „ì†¡ (ì •ê¸°ë°œí–‰ë¬¼ íŠ¹ì„±ì— ë§ì¶¤)
        
        Args:
            news_type (str): ë‰´ìŠ¤ íƒ€ì…
            display_name (str): í‘œì‹œëª…
            emoji (str): ì´ëª¨ì§€
            analysis_result (dict): ë¶„ì„ ê²°ê³¼
        """
        if not analysis_result:
            return
        
        message = f"{emoji} {display_name} AI ë¶„ì„\n"
        message += "=" * 50 + "\n\n"
        
        # 1. ê¸°ë³¸ ì •ë³´
        current_news = analysis_result['current_news']
        current_date = current_news.get('date', '')
        today_date = datetime.now().strftime('%Y%m%d')
        
        message += f"ğŸ“Š ë¶„ì„ ë²”ìœ„: ìµœê·¼ 30ì¼ ({analysis_result['total_articles']}ê±´)\n"
        
        if current_date == today_date:
            message += f"ğŸ“° ìµœì‹  ë‰´ìŠ¤: {current_news.get('title', 'N/A')}\n"
        else:
            days_diff = (datetime.strptime(today_date, '%Y%m%d') - datetime.strptime(current_date, '%Y%m%d')).days
            message += f"ğŸ“° ìµœì‹  ë‰´ìŠ¤: {current_news.get('title', 'N/A')} ({days_diff}ì¼ ì „)\n"
        
        message += "\n"
        
        # 2. ì„¹í„°ë³„ ì„±ê³¼ ë¶„ì„
        message += f"ğŸ­ ì„¹í„°ë³„ ì„±ê³¼ ë¶„ì„\n"
        message += "â”€" * 30 + "\n"
        sector_analysis = analysis_result['sector_analysis']
        top_sectors = sorted(sector_analysis.items(), key=lambda x: x[1]['mentions'], reverse=True)[:4]  # ìƒìœ„ 4ê°œ
        
        for i, (sector, data) in enumerate(top_sectors, 1):
            if data['mentions'] > 0:
                # í˜„ì¬ ìƒíƒœ
                sentiment_emoji = "ğŸ“ˆ" if data['sentiment'] == "ê¸ì •" else "ğŸ“‰" if data['sentiment'] == "ë¶€ì •" else "â¡ï¸"
                message += f"{i}. {sector}: {sentiment_emoji} {data['sentiment']} ({data['mentions']}íšŒ)\n"
                
                # ì˜ˆì¸¡ ì •ë³´ (ê°„ë‹¨í•˜ê²Œ)
                if 'prediction' in data:
                    pred = data['prediction']
                    if pred['next_day_prediction'] != "ì¤‘ë¦½":
                        pred_emoji = "ğŸ”®" if pred['next_day_prediction'] == "ê¸ì •" else "âš ï¸"
                        confidence = pred['prediction_confidence']
                        if confidence >= 0.7:
                            message += f"   â””â”€ {pred_emoji} ë‚´ì¼ {pred['next_day_prediction']} ì˜ˆìƒ\n"
        
        message += "\n"
        
        # 3. í•µì‹¬ ì‹œì¥ ì¸ì‚¬ì´íŠ¸
        message += f"ğŸ§  í•µì‹¬ ì‹œì¥ ì¸ì‚¬ì´íŠ¸\n"
        message += "â”€" * 30 + "\n"
        market_insight = self._generate_market_insight(analysis_result)
        message += f"{market_insight}\n\n"
        
        # 4. ì›”ê°„ íŠ¸ë Œë“œ ë¶„ì„
        message += f"ğŸ“ˆ ì›”ê°„ íŠ¸ë Œë“œ ë¶„ì„\n"
        message += "â”€" * 30 + "\n"
        month_trend = self._analyze_monthly_trend(analysis_result)
        message += f"{month_trend}\n\n"
        
        # 5. ì£¼ë³„ ë³€í™” ë¶„ì„
        message += f"ğŸ“Š ì£¼ë³„ ë³€í™” ë¶„ì„\n"
        message += "â”€" * 30 + "\n"
        weekly_analysis = self._analyze_weekly_changes(analysis_result)
        message += f"{weekly_analysis}\n\n"
        
        # 6. AI ì˜ˆì¸¡ ìš”ì•½
        message += f"ğŸ”® ë‚´ì¼ ì‹œì¥ ì „ë§\n"
        message += "â”€" * 30 + "\n"
        positive_predictions = [s[0] for s in top_sectors if s[1].get('prediction', {}).get('next_day_prediction') == 'ê¸ì •']
        negative_predictions = [s[0] for s in top_sectors if s[1].get('prediction', {}).get('next_day_prediction') == 'ë¶€ì •']
        
        if positive_predictions:
            message += f"ğŸ“ˆ ê¸ì • ì˜ˆìƒ: {', '.join(positive_predictions)}\n"
        if negative_predictions:
            message += f"ğŸ“‰ ë¶€ì • ì˜ˆìƒ: {', '.join(negative_predictions)}\n"
        
        # ì˜ˆì¸¡ ê·¼ê±° ì¶”ê°€
        prediction_reason = self._generate_prediction_reason(analysis_result)
        if prediction_reason:
            message += f"ğŸ’¡ ê·¼ê±°: {prediction_reason}\n"
        
        message += "\n"
        
        # 7. íˆ¬ì ì „ëµ ê°€ì´ë“œ
        message += f"ğŸ’¼ íˆ¬ì ì „ëµ ê°€ì´ë“œ\n"
        message += "â”€" * 30 + "\n"
        investment_strategy = self._generate_investment_strategy(analysis_result)
        message += f"{investment_strategy}\n"
        
        message += "\n"
        
        # 8. ê¸€ë¡œë²Œ ì˜í–¥ë„ ë¶„ì„
        message += f"ğŸŒ ê¸€ë¡œë²Œ ì˜í–¥ë„ ë¶„ì„\n"
        message += "â”€" * 30 + "\n"
        global_impact = analysis_result['global_impact']
        top_regions = sorted(global_impact.items(), key=lambda x: x[1]['total_impact'], reverse=True)[:4]  # ìƒìœ„ 4ê°œ
        
        for i, (region, data) in enumerate(top_regions, 1):
            if data['total_impact'] > 0:
                trend_emoji = "ğŸ“ˆ" if data['trend'] == "ì¦ê°€" else "ğŸ“‰" if data['trend'] == "ê°ì†Œ" else "â¡ï¸"
                message += f"{i}. {region}: {trend_emoji} {data['trend']} ({data['total_impact']}íšŒ)\n"
        
        # ê¸€ë¡œë²Œ ë¶„ì„ ì½”ë©˜íŠ¸
        global_comment = self._analyze_global_trend(global_impact)
        if global_comment:
            message += f"ğŸ’¡ ë¶„ì„: {global_comment}\n"
        
        message += "\n"
        
        # 9. ìƒì„¸ ë¦¬í¬íŠ¸ ë§í¬
        message += f"ğŸ“‹ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸\n"
        message += "â”€" * 30 + "\n"
        
        # HTML ë¦¬í¬íŠ¸ ìƒì„±
        try:
            from reports.html_report_generator import HTMLReportGenerator
            report_generator = HTMLReportGenerator()
            report_result = report_generator.generate_report(analysis_result, news_type, display_name)
            message += f"ğŸ“„ {report_result['display_name']} ìƒì„¸ ë¦¬í¬íŠ¸:\n"
            message += f"ğŸ”— {report_result['web_url']}\n\n"
        except Exception as e:
            message += f"âš ï¸ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}\n\n"
        
        # ê°„ë‹¨í•œ ìš”ì•½ ì •ë³´
        message += f"ğŸ’¡ í•µì‹¬ ìš”ì•½\n"
        message += "â”€" * 30 + "\n"
        summary = self._generate_simple_summary(analysis_result)
        message += f"{summary}\n"
        
        # ë³„ë„ ë§í’ì„ ìœ¼ë¡œ ì „ì†¡
        payload = {
            "botName": f"POSCO {display_name} ğŸ“Š",
            "botIconImage": self.bot_profile_image_url,
            "text": f"{display_name} ê³ ê¸‰ ë¶„ì„",
            "attachments": [{
                "color": "#6f42c1",
                "text": message
            }]
        }
        
        try:
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            if response.status_code == 200:
                print(f"âœ… {display_name} ê³ ê¸‰ ë¶„ì„ ì „ì†¡ ì„±ê³µ")
            else:
                print(f"âŒ {display_name} ê³ ê¸‰ ë¶„ì„ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
        except Exception as e:
            print(f"âŒ {display_name} ê³ ê¸‰ ë¶„ì„ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    def _send_summary_notification(self, current_data, analyzed_types):
        """
        ì „ì²´ ìš”ì•½ ì•Œë¦¼ ì „ì†¡ (ê°œì„ ëœ ë²„ì „)
        
        Args:
            current_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            analyzed_types (list): ë¶„ì„ëœ ë‰´ìŠ¤ íƒ€ì… ë¦¬ìŠ¤íŠ¸
        """
        message = "ğŸ“Š ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ ì™„ë£Œ\n\n"
        
        # ë¶„ì„ëœ íƒ€ì…ë“¤
        if analyzed_types:
            message += f"ğŸ” ê³ ê¸‰ ë¶„ì„ ì™„ë£Œëœ ë‰´ìŠ¤ íƒ€ì…:\n"
            for news_type in analyzed_types:
                message += f"â€¢ {news_type}\n"
            message += "\n"
        
        # ë°ì´í„°ê°€ ì—†ëŠ” íƒ€ì…ë“¤
        no_data_types = []
        for news_type, news_data in current_data.items():
            if not news_data or not news_data.get('title'):
                news_config = NEWS_TYPES.get(news_type, {})
                display_name = news_config.get('display_name', news_type.upper())
                no_data_types.append(display_name)
        
        if no_data_types:
            message += f"ğŸ“ ë°ì´í„° ì—†ëŠ” ë‰´ìŠ¤ íƒ€ì…:\n"
            for news_type in no_data_types:
                message += f"â€¢ {news_type}\n"
            message += "\n"
        
        message += f"ğŸ’¡ ì•ˆë‚´ì‚¬í•­\n"
        message += f"â€¢ ê° íƒ€ì…ë³„ë¡œ ë³„ë„ ë§í’ì„ ì„ í™•ì¸í•˜ì„¸ìš”\n"
        message += f"â€¢ ë°ì´í„°ê°€ ì—†ëŠ” íƒ€ì…ì€ ì´ë²¤íŠ¸ ê¸°ë°˜ ë°œí–‰ì…ë‹ˆë‹¤\n"
        message += f"â€¢ ìƒˆë¡œìš´ ë‰´ìŠ¤ ë°œí–‰ ì‹œ ìë™ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤"
        
        payload = {
            "botName": "POSCO ê³ ê¸‰ ë¶„ì„ ğŸ“Š",
            "botIconImage": self.bot_profile_image_url,
            "text": "ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ ì™„ë£Œ",
            "attachments": [{
                "color": "#28a745",
                "text": message
            }]
        }
        
        try:
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            if response.status_code == 200:
                print(f"âœ… ì „ì²´ ìš”ì•½ ì•Œë¦¼ ì „ì†¡ ì„±ê³µ")
            else:
                print(f"âŒ ì „ì²´ ìš”ì•½ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
        except Exception as e:
            print(f"âŒ ì „ì²´ ìš”ì•½ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    def _send_no_data_message(self, news_type, display_name, emoji):
        """
        ë°ì´í„°ê°€ ì—†ëŠ” ë‰´ìŠ¤ íƒ€ì…ì— ëŒ€í•œ ë©”ì‹œì§€ ì „ì†¡
        
        Args:
            news_type (str): ë‰´ìŠ¤ íƒ€ì…
            display_name (str): í‘œì‹œëª…
            emoji (str): ì´ëª¨ì§€
        """
        message = f"{emoji} {display_name} ë¶„ì„\n\n"
        message += f"ğŸ“Š í˜„ì¬ ìƒíƒœ\n"
        message += f"â€¢ ë°œí–‰ëœ ë‰´ìŠ¤: ì—†ìŒ\n"
        message += f"â€¢ ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
        message += f"ğŸ’¡ ì°¸ê³ ì‚¬í•­\n"
        message += f"â€¢ ì´ ë‰´ìŠ¤ íƒ€ì…ì€ íŠ¹ì • ì¡°ê±´ì—ì„œë§Œ ë°œí–‰ë©ë‹ˆë‹¤\n"
        message += f"â€¢ ì •ê¸° ë°œí–‰ì´ ì•„ë‹Œ ì´ë²¤íŠ¸ ê¸°ë°˜ ë°œí–‰ì…ë‹ˆë‹¤\n"
        message += f"â€¢ ìƒˆë¡œìš´ ë‰´ìŠ¤ê°€ ë°œí–‰ë˜ë©´ ìë™ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤\n"
        
        payload = {
            "botName": f"POSCO {display_name} ğŸ“Š",
            "botIconImage": self.bot_profile_image_url,
            "text": f"{display_name} ë¶„ì„",
            "attachments": [{
                "color": "#6c757d",
                "text": message
            }]
        }
        
        try:
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            if response.status_code == 200:
                print(f"âœ… {display_name} (ë°ì´í„° ì—†ìŒ) ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ")
            else:
                print(f"âŒ {display_name} (ë°ì´í„° ì—†ìŒ) ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
        except Exception as e:
            print(f"âŒ {display_name} (ë°ì´í„° ì—†ìŒ) ë©”ì‹œì§€ ì „ì†¡ ì˜¤ë¥˜: {e}")
    
    def _send_simple_analysis(self, news_type, display_name, emoji, current_news):
        """
        ê³¼ê±° ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° í˜„ì¬ ë°ì´í„°ë§Œìœ¼ë¡œ ê°„ë‹¨ ë¶„ì„
        
        Args:
            news_type (str): ë‰´ìŠ¤ íƒ€ì…
            display_name (str): í‘œì‹œëª…
            emoji (str): ì´ëª¨ì§€
            current_news (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
        """
        message = f"{emoji} {display_name} ê°„ë‹¨ ë¶„ì„\n\n"
        
        # í˜„ì¬ ë‰´ìŠ¤ ì •ë³´
        title = current_news.get('title', '')
        content = current_news.get('content', '')
        date = current_news.get('date', '')
        time = current_news.get('time', '')
        
        message += f"ğŸ“Š í˜„ì¬ ë‰´ìŠ¤ ì •ë³´\n"
        message += f"â€¢ ì œëª©: {title}\n"
        message += f"â€¢ ë°œí–‰ì¼: {self._format_datetime(date, time)}\n"
        message += f"â€¢ ë³¸ë¬¸ ê¸¸ì´: {len(content)}ì\n\n"
        
        # í‚¤ì›Œë“œ ë¶„ì„
        if content:
            keywords = self._extract_keywords(title + ' ' + content)
            if keywords:
                message += f"ğŸ” ì£¼ìš” í‚¤ì›Œë“œ\n"
                for keyword, count in keywords[:5]:
                    message += f"â€¢ {keyword}: {count}íšŒ\n"
                message += "\n"
        
        message += f"ğŸ’¡ ì°¸ê³ ì‚¬í•­\n"
        message += f"â€¢ ê³¼ê±° ë°ì´í„°ê°€ ì—†ì–´ ê°„ë‹¨ ë¶„ì„ë§Œ ì œê³µí•©ë‹ˆë‹¤\n"
        message += f"â€¢ 30ì¼ê°„ì˜ ë°ì´í„°ê°€ ì¶•ì ë˜ë©´ ê³ ê¸‰ ë¶„ì„ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤\n"
        
        payload = {
            "botName": f"POSCO {display_name} ğŸ“Š",
            "botIconImage": self.bot_profile_image_url,
            "text": f"{display_name} ê°„ë‹¨ ë¶„ì„",
            "attachments": [{
                "color": "#ffc107",
                "text": message
            }]
        }
        
        try:
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'},
                timeout=10
            )
            if response.status_code == 200:
                print(f"âœ… {display_name} ê°„ë‹¨ ë¶„ì„ ì „ì†¡ ì„±ê³µ")
            else:
                print(f"âŒ {display_name} ê°„ë‹¨ ë¶„ì„ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}")
        except Exception as e:
            print(f"âŒ {display_name} ê°„ë‹¨ ë¶„ì„ ì „ì†¡ ì˜¤ë¥˜: {e}")


# ============================================================================
# ë©”ì¸ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤ (from core/monitor.py)
# ============================================================================

class PoscoNewsMonitor:
    """
    POSCO ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤ (ìµœì í™”ë¨)
    
    ëª¨ë“  í•µì‹¬ ê¸°ëŠ¥ì„ í†µí•©í•˜ì—¬ ë‹¨ìˆœí•˜ê³  íš¨ìœ¨ì ì¸ êµ¬ì¡°ë¡œ ê°œì„ í–ˆìŠµë‹ˆë‹¤.
    """
    
    def __init__(self, dooray_webhook_url):
        """
        ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            dooray_webhook_url (str): Dooray ì›¹í›… URL
        """
        # ì„¤ì • ë¡œë“œ
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.dirname(__file__)))
        from config import API_CONFIG, MONITORING_CONFIG, BOT_PROFILE_IMAGE_URL
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.api_client = PoscoNewsAPIClient(API_CONFIG)
        self.notifier = DoorayNotifier(dooray_webhook_url, BOT_PROFILE_IMAGE_URL, self.api_client)
        self.data_processor = NewsDataProcessor()
        
        # ì„¤ì •ê°’
        self.cache_file = MONITORING_CONFIG["cache_file"]
        self.max_retry_days = MONITORING_CONFIG["max_retry_days"]
        self.last_hash = None
    
    def check_once(self, simple_status=False):
        """
        ì¼íšŒì„± ë‰´ìŠ¤ ìƒíƒœ ì²´í¬
        
        Args:
            simple_status (bool): Trueë©´ ê°„ê²°í•œ ìƒíƒœ ì•Œë¦¼ ì „ì†¡
            
        Returns:
            bool: ë³€ê²½ì‚¬í•­ ë°œê²¬ ì—¬ë¶€
        """
        from utils import log_with_timestamp, get_data_hash, load_cache, save_cache
        
        log_with_timestamp(f"ë‰´ìŠ¤ ë°ì´í„° ì²´í¬ ì¤‘...", "INFO")
        
        current_data = self.api_client.get_news_data()
        if not current_data:
            self.notifier.send_notification("API í˜¸ì¶œ ì‹¤íŒ¨", is_error=True)
            return False
        
        current_hash = get_data_hash(current_data)
        cached_data, cached_hash = load_cache(self.cache_file)
        
        if cached_hash != current_hash:
            log_with_timestamp("ë°ì´í„° ë³€ê²½ ê°ì§€!", "SUCCESS")
            
            change_result = self.data_processor.detect_changes(cached_data, current_data)
            
            if change_result["changes"]:
                for news_type in change_result["changes"]:
                    old_item = cached_data.get(news_type) if cached_data else None
                    new_item = current_data[news_type]
                    self.notifier.send_change_notification(news_type, old_item, new_item)
            
            save_cache(self.cache_file, current_data, current_hash)
            self.last_hash = current_hash
            return True
        else:
            log_with_timestamp("ë³€ê²½ì‚¬í•­ ì—†ìŒ", "INFO")
            
            status_info = self.data_processor.get_status_info(current_data)
            if simple_status:
                self._send_simple_status_notification(current_data, status_info)
            else:
                self.notifier.send_status_notification(current_data, status_info)
            return False
    
    def check_silent(self):
        """
        ì¡°ìš©í•œ ëª¨ë“œ ì²´í¬ - ë³€ê²½ì‚¬í•­ ìˆì„ ë•Œë§Œ ì•Œë¦¼ ì „ì†¡
        
        Returns:
            bool: ë³€ê²½ì‚¬í•­ ë°œê²¬ ì—¬ë¶€
        """
        from utils import log_with_timestamp, get_data_hash, load_cache, save_cache
        
        log_with_timestamp("ë‰´ìŠ¤ ë°ì´í„° ì²´í¬ ì¤‘... (ì¡°ìš©í•œ ëª¨ë“œ)", "INFO")
        
        current_data = self.api_client.get_news_data()
        if not current_data:
            return False
        
        current_hash = get_data_hash(current_data)
        cached_data, cached_hash = load_cache(self.cache_file)
        
        if cached_hash != current_hash:
            log_with_timestamp("ë°ì´í„° ë³€ê²½ ê°ì§€! (ì¡°ìš©í•œ ëª¨ë“œ)", "SUCCESS")
            
            change_result = self.data_processor.detect_changes(cached_data, current_data)
            
            if change_result["changes"]:
                for news_type in change_result["changes"]:
                    old_item = cached_data.get(news_type) if cached_data else None
                    new_item = current_data[news_type]
                    self.notifier.send_change_notification(news_type, old_item, new_item)
            
            save_cache(self.cache_file, current_data, current_hash)
            self.last_hash = current_hash
            return True
        
        return False
    
    def check_extended(self):
        """
        í™•ì¥ ì²´í¬ - ì˜ì—…ì¼ ë¹„êµ ë¶„ì„
        
        Returns:
            bool: ì„±ê³µ ì—¬ë¶€
        """
        from utils import log_with_timestamp
        
        log_with_timestamp("ì˜ì—…ì¼ ë¹„êµ ë¶„ì„ ì¤‘...", "INFO")
        
        current_data = self.api_client.get_news_data()
        if not current_data:
            self.notifier.send_notification("API í˜¸ì¶œ ì‹¤íŒ¨", is_error=True)
            return False
        
        # ì§ì „ ì˜ì—…ì¼ ë°ì´í„° ì¡°íšŒ
        previous_data = self.data_processor.get_previous_day_data(
            self.api_client, current_data, self.max_retry_days
        )
        
        if previous_data:
            self._send_comparison_notification(current_data, previous_data)
        else:
            log_with_timestamp("ì§ì „ ì˜ì—…ì¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ", "WARNING")
        
        return True
    
    def send_daily_summary(self):
        """
        ì¼ì¼ ìš”ì•½ ë¦¬í¬íŠ¸ ì „ì†¡ (ê¸°ë³¸ ë²„ì „)
        
        ì˜¤ëŠ˜ ë°œí–‰ëœ ë‰´ìŠ¤ë“¤ì„ ìš”ì•½í•˜ì—¬ ì „ì†¡í•©ë‹ˆë‹¤.
        """
        from utils import log_with_timestamp
        
        log_with_timestamp("ì¼ì¼ ìš”ì•½ ë¦¬í¬íŠ¸ ì „ì†¡ ì‹œì‘", "INFO")
        
        try:
            # í˜„ì¬ ë°ì´í„° ì¡°íšŒ
            current_data = self.api_client.get_news_data()
            if not current_data:
                log_with_timestamp("ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨", "ERROR")
                self.notifier.send_notification("ì¼ì¼ ìš”ì•½: ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨", is_error=True)
                return False
            
            # ì§ì „ ì˜ì—…ì¼ ë°ì´í„° ì¡°íšŒ
            previous_data = self.data_processor.get_previous_day_data(
                self.api_client, current_data
            )
            
            # ìƒì„¸í•œ ì¼ì¼ ìš”ì•½ ì „ì†¡
            success = self.notifier.send_detailed_daily_summary(current_data, previous_data)
            
            if success:
                log_with_timestamp("ìƒì„¸ ì¼ì¼ ìš”ì•½ ì „ì†¡ ì™„ë£Œ", "SUCCESS")
            else:
                log_with_timestamp("ìƒì„¸ ì¼ì¼ ìš”ì•½ ì „ì†¡ ì‹¤íŒ¨", "ERROR")
            
            return success
            
        except Exception as e:
            log_with_timestamp(f"ì¼ì¼ ìš”ì•½ ì˜¤ë¥˜: {e}", "ERROR")
            self.notifier.send_notification(f"ì¼ì¼ ìš”ì•½ ì˜¤ë¥˜: {e}", is_error=True)
            return False
    
    def execute_detailed_daily_summary(self):
        """
        ìƒì„¸í•œ ì¼ì¼ ìš”ì•½ ë¦¬í¬íŠ¸ ì „ì†¡ (ì œëª© + ë³¸ë¬¸ ë¹„êµ)
        
        ê° ë‰´ìŠ¤ íƒ€ì…ë³„ë¡œ ì œëª©ê³¼ ë³¸ë¬¸ ë‚´ìš©ì„ í¬í•¨í•œ ìƒì„¸í•œ ìš”ì•½ì„ ìƒì„±í•˜ê³ ,
        ì§ì „ ì˜ì—…ì¼ê³¼ì˜ ë¹„êµ ë¶„ì„ì„ í¬í•¨í•˜ì—¬ ì „ì†¡í•©ë‹ˆë‹¤.
        """
        from utils import log_with_timestamp
        
        log_with_timestamp("ìƒì„¸ ì¼ì¼ ìš”ì•½ ë¦¬í¬íŠ¸ ì „ì†¡ ì‹œì‘", "INFO")
        
        try:
            # í˜„ì¬ ë°ì´í„° ì¡°íšŒ
            current_data = self.api_client.get_news_data()
            if not current_data:
                log_with_timestamp("ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨", "ERROR")
                self.notifier.send_notification("ìƒì„¸ ì¼ì¼ ìš”ì•½: ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨", is_error=True)
                return False
            
            # ì§ì „ ì˜ì—…ì¼ ë°ì´í„° ì¡°íšŒ
            previous_data = self.data_processor.get_previous_day_data(
                self.api_client, current_data
            )
            
            # ìƒì„¸í•œ ì¼ì¼ ìš”ì•½ ì „ì†¡
            success = self.notifier.send_detailed_daily_summary(current_data, previous_data)
            
            if success:
                log_with_timestamp("ìƒì„¸ ì¼ì¼ ìš”ì•½ ì „ì†¡ ì™„ë£Œ", "SUCCESS")
            else:
                log_with_timestamp("ìƒì„¸ ì¼ì¼ ìš”ì•½ ì „ì†¡ ì‹¤íŒ¨", "ERROR")
            
            return success
            
        except Exception as e:
            log_with_timestamp(f"ìƒì„¸ ì¼ì¼ ìš”ì•½ ì˜¤ë¥˜: {e}", "ERROR")
            self.notifier.send_notification(f"ìƒì„¸ ì¼ì¼ ìš”ì•½ ì˜¤ë¥˜: {e}", is_error=True)
            return False
    
    def execute_advanced_analysis(self, days_back=30):
        """
        ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ ì‹¤í–‰ (30ì¼ ì¶”ì´ + ì£¼ë‹¨ìœ„ ë¶„ì„ + í–¥í›„ ì˜ˆìƒ)
        
        ìµœê·¼ 30ì¼ê°„ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¶”ì´, ì£¼ë‹¨ìœ„ íŒ¨í„´, í–¥í›„ ì˜ˆìƒì„ í¬í•¨í•œ
        ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ê° ë‰´ìŠ¤ íƒ€ì…ë³„ë¡œ ë³„ë„ ë§í’ì„ ìœ¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
        
        Args:
            days_back (int): ë¶„ì„í•  ê³¼ê±° ì¼ìˆ˜ (ê¸°ë³¸ê°’: 30ì¼)
        """
        from utils import log_with_timestamp
        
        log_with_timestamp("ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ ì‹¤í–‰ ì‹œì‘", "INFO")
        
        try:
            # í˜„ì¬ ë°ì´í„° ì¡°íšŒ
            current_data = self.api_client.get_news_data()
            if not current_data:
                log_with_timestamp("ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨", "ERROR")
                self.notifier.send_notification("ê³ ê¸‰ ë¶„ì„: ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨", is_error=True)
                return False
            
            # ê³ ê¸‰ ë¶„ì„ ì‹¤í–‰
            success = self.notifier.send_advanced_analysis(current_data, self.api_client, days_back)
            
            if success:
                log_with_timestamp("ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ ì „ì†¡ ì™„ë£Œ", "SUCCESS")
            else:
                log_with_timestamp("ê³ ê¸‰ ë¶„ì„ ë¦¬í¬íŠ¸ ì „ì†¡ ì‹¤íŒ¨", "ERROR")
            
            return success
            
        except Exception as e:
            log_with_timestamp(f"ê³ ê¸‰ ë¶„ì„ ì˜¤ë¥˜: {e}", "ERROR")
            self.notifier.send_notification(f"ê³ ê¸‰ ë¶„ì„ ì˜¤ë¥˜: {e}", is_error=True)
            return False
    
    def start_monitoring(self, interval_minutes=60):
        """
        ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        
        Args:
            interval_minutes (int): ì²´í¬ ê°„ê²© (ë¶„)
        """
        from utils import log_with_timestamp
        
        log_with_timestamp(f"ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ê°„ê²©: {interval_minutes}ë¶„)", "INFO")
        
        try:
            while True:
                self.check_silent()
                time.sleep(interval_minutes * 60)
        except KeyboardInterrupt:
            log_with_timestamp("ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨ë¨", "INFO")
        except Exception as e:
            log_with_timestamp(f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}", "ERROR")
            self.notifier.send_notification(f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜ ë°œìƒ: {e}", is_error=True)
    
    def start_smart_monitoring(self):
        """
        ìŠ¤ë§ˆíŠ¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        
        ì‹œê°„ëŒ€ë³„ ì ì‘í˜• ê°„ê²©ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤.
        """
        from utils import log_with_timestamp
        
        log_with_timestamp("ìŠ¤ë§ˆíŠ¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘", "INFO")
        
        try:
            while True:
                current_hour = datetime.now().hour
                interval = self._get_smart_interval(current_hour)
                
                log_with_timestamp(f"ìŠ¤ë§ˆíŠ¸ ê°„ê²©: {interval}ë¶„ (í˜„ì¬ ì‹œê°„: {current_hour}ì‹œ)", "INFO")
                
                self.check_silent()
                time.sleep(interval * 60)
                
        except KeyboardInterrupt:
            log_with_timestamp("ìŠ¤ë§ˆíŠ¸ ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨ë¨", "INFO")
        except Exception as e:
            log_with_timestamp(f"ìŠ¤ë§ˆíŠ¸ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {e}", "ERROR")
            self.notifier.send_notification(f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜ ë°œìƒ: {e}", is_error=True)
    
    def _send_simple_status_notification(self, current_data, status_info):
        """
        ê°„ê²°í•œ ìƒíƒœ ì•Œë¦¼ ì „ì†¡
        
        Args:
            current_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            status_info (str): ìƒíƒœ ì •ë³´ ë¬¸ìì—´
        """
        self.notifier.send_simple_status_notification(current_data, status_info)
    
    def _send_comparison_notification(self, current_data, previous_data):
        """
        ì˜ì—…ì¼ ë¹„êµ ì•Œë¦¼ ì „ì†¡
        
        Args:
            current_data (dict): í˜„ì¬ ë‰´ìŠ¤ ë°ì´í„°
            previous_data (dict): ì§ì „ ì˜ì—…ì¼ ë‰´ìŠ¤ ë°ì´í„°
        """
        self.notifier.send_comparison_notification(current_data, previous_data)
    
    def _get_smart_interval(self, current_hour):
        """
        ì‹œê°„ëŒ€ë³„ ìŠ¤ë§ˆíŠ¸ ê°„ê²© ê³„ì‚°
        
        Args:
            current_hour (int): í˜„ì¬ ì‹œê°„ (0-23)
            
        Returns:
            int: ëª¨ë‹ˆí„°ë§ ê°„ê²© (ë¶„)
        """
        # ì—…ë¬´ ì‹œê°„ (9-18ì‹œ): 30ë¶„ ê°„ê²©
        if 9 <= current_hour <= 18:
            return 30
        # ì ì‹¬ ì‹œê°„ (12-13ì‹œ): 15ë¶„ ê°„ê²© (ë” ìì£¼ ì²´í¬)
        elif 12 <= current_hour <= 13:
            return 15
        # ì €ë… ì‹œê°„ (18-22ì‹œ): 60ë¶„ ê°„ê²©
        elif 18 <= current_hour <= 22:
            return 60
        # ì•¼ê°„ ì‹œê°„ (22-9ì‹œ): 120ë¶„ ê°„ê²© (ì¡°ìš©í•œ ëª¨ë“œ)
        else:
            return 120


# ============================================================================
# ë‚´ë³´ë‚¼ í´ë˜ìŠ¤ë“¤
# ============================================================================

__all__ = [
    'PoscoNewsAPIClient',
    'NewsDataProcessor', 
    'DoorayNotifier',
    'PoscoNewsMonitor'
]