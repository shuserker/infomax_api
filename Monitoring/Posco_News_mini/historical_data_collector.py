#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
POSCO ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ê¸°

7ì›” 25ì¼ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ëª¨ë“  ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬
ìºì‹œì— ì €ì¥í•˜ê³  ì•Œë¦¼ì—ì„œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- ë‚ ì§œë³„ API ë°ì´í„° ìˆ˜ì§‘
- ìºì‹œ íŒŒì¼ ì—…ë°ì´íŠ¸
- ì˜ì—…ì¼ ê¸°ì¤€ ë°ì´í„° ì •ë¦¬
- ì§ì „ ë°ì´í„° ë§¤í•‘

ì‘ì„±ì: AI Assistant
ìµœì¢… ìˆ˜ì •: 2025-08-05
"""

import os
import sys
import json
import requests
from datetime import datetime, timedelta
from requests.auth import HTTPBasicAuth

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

try:
    from core import PoscoNewsAPIClient
    from config import API_CONFIG
except ImportError as e:
    print(f"[WARNING] ì¼ë¶€ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    API_CONFIG = {
        "url": "https://dev-global-api.einfomax.co.kr/apis/posco/news",
        "user": "infomax",
        "password": "infomax!",
        "timeout": 10
    }

class HistoricalDataCollector:
    """
    ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ê¸° í´ë˜ìŠ¤
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.api_config = API_CONFIG
        self.cache_file = "../../posco_news_historical_cache.json"
        self.collected_data = {}
        
        print("ğŸ“Š POSCO ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™”")
    
    def get_api_data_for_date(self, date_str):
        """íŠ¹ì • ë‚ ì§œì˜ API ë°ì´í„° ì¡°íšŒ"""
        try:
            print(f"ğŸ“… {date_str} ë°ì´í„° ì¡°íšŒ ì¤‘...")
            
            params = {'date': date_str}
            
            response = requests.get(
                self.api_config['url'],
                auth=HTTPBasicAuth(self.api_config['user'], self.api_config['password']),
                params=params,
                timeout=self.api_config['timeout']
            )
            
            if response.status_code == 200:
                data = response.json()
                
                # ë°ì´í„° ìœ íš¨ì„± í™•ì¸
                valid_count = 0
                for news_type, news_data in data.items():
                    if news_data.get('title'):
                        valid_count += 1
                
                print(f"  âœ… ì„±ê³µ: {valid_count}/3 ë‰´ìŠ¤ ë°ì´í„° íšë“")
                return data
            else:
                print(f"  âŒ API ì˜¤ë¥˜: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"  âŒ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
    
    def collect_historical_data(self, start_date_str, end_date_str):
        """ê¸°ê°„ë³„ ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘"""
        try:
            start_date = datetime.strptime(start_date_str, '%Y%m%d')
            end_date = datetime.strptime(end_date_str, '%Y%m%d')
            
            print(f"ğŸ” ë°ì´í„° ìˆ˜ì§‘ ê¸°ê°„: {start_date_str} ~ {end_date_str}")
            print()
            
            current_date = start_date
            total_days = (end_date - start_date).days + 1
            collected_days = 0
            
            while current_date <= end_date:
                date_str = current_date.strftime('%Y%m%d')
                
                # APIì—ì„œ ë°ì´í„° ì¡°íšŒ
                data = self.get_api_data_for_date(date_str)
                
                if data:
                    self.collected_data[date_str] = {
                        'date': date_str,
                        'data': data,
                        'collected_at': datetime.now().isoformat()
                    }
                    collected_days += 1
                
                current_date += timedelta(days=1)
            
            print()
            print(f"ğŸ“Š ìˆ˜ì§‘ ì™„ë£Œ: {collected_days}/{total_days}ì¼")
            return collected_days > 0
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return False
    
    def save_to_cache(self):
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ìºì‹œ íŒŒì¼ì— ì €ì¥"""
        try:
            cache_data = {
                'historical_data': self.collected_data,
                'last_updated': datetime.now().isoformat(),
                'total_dates': len(self.collected_data)
            }
            
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ìºì‹œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {self.cache_file}")
            print(f"ğŸ“Š ì´ {len(self.collected_data)}ì¼ ë°ì´í„° ì €ì¥")
            return True
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def find_previous_business_day_data(self, target_date_str, news_type):
        """íŠ¹ì • ë‚ ì§œ ì´ì „ì˜ ì˜ì—…ì¼ ë°ì´í„° ì°¾ê¸°"""
        try:
            target_date = datetime.strptime(target_date_str, '%Y%m%d')
            
            # ìµœëŒ€ 10ì¼ ì „ê¹Œì§€ ê²€ìƒ‰
            for i in range(1, 11):
                check_date = target_date - timedelta(days=i)
                check_date_str = check_date.strftime('%Y%m%d')
                
                if check_date_str in self.collected_data:
                    data = self.collected_data[check_date_str]['data']
                    
                    # ë‰´ìŠ¤ íƒ€ì… ë§¤í•‘
                    api_key_mapping = {
                        'newyork': 'newyork-market-watch',
                        'kospi': 'kospi-close', 
                        'exchange': 'exchange-rate'
                    }
                    
                    api_key = api_key_mapping.get(news_type)
                    if api_key and api_key in data and data[api_key].get('title'):
                        return {
                            'date': check_date_str,
                            'data': data[api_key]
                        }
            
            return None
            
        except Exception as e:
            print(f"âŒ ì§ì „ ë°ì´í„° ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None
    
    def generate_business_day_mapping(self):
        """ì˜ì—…ì¼ ê¸°ì¤€ ì§ì „ ë°ì´í„° ë§¤í•‘ ìƒì„±"""
        try:
            print("ğŸ” ì˜ì—…ì¼ ê¸°ì¤€ ì§ì „ ë°ì´í„° ë§¤í•‘ ìƒì„± ì¤‘...")
            
            mapping = {}
            
            for date_str in sorted(self.collected_data.keys()):
                mapping[date_str] = {}
                
                for news_type in ['newyork', 'kospi', 'exchange']:
                    previous_data = self.find_previous_business_day_data(date_str, news_type)
                    
                    if previous_data:
                        mapping[date_str][news_type] = {
                            'previous_date': previous_data['date'],
                            'previous_title': previous_data['data'].get('title', ''),
                            'previous_time': f"{previous_data['date'][:4]}-{previous_data['date'][4:6]}-{previous_data['date'][6:8]} {previous_data['data'].get('time', '')}"
                        }
            
            # ë§¤í•‘ ë°ì´í„° ì €ì¥
            mapping_file = "../../posco_business_day_mapping.json"
            with open(mapping_file, 'w', encoding='utf-8') as f:
                json.dump(mapping, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ ì˜ì—…ì¼ ë§¤í•‘ ì €ì¥ ì™„ë£Œ: {mapping_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ë§¤í•‘ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def run_collection(self):
        """ì „ì²´ ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸ“Š POSCO ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print("=" * 60)
        
        # 7ì›” 25ì¼ë¶€í„° ì˜¤ëŠ˜ê¹Œì§€ ìˆ˜ì§‘
        start_date = "20250725"
        end_date = datetime.now().strftime('%Y%m%d')
        
        # 1. ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘
        if self.collect_historical_data(start_date, end_date):
            print("âœ… ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
        else:
            print("âŒ ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return False
        
        # 2. ìºì‹œ íŒŒì¼ ì €ì¥
        if self.save_to_cache():
            print("âœ… ìºì‹œ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        else:
            print("âŒ ìºì‹œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")
            return False
        
        # 3. ì˜ì—…ì¼ ë§¤í•‘ ìƒì„±
        if self.generate_business_day_mapping():
            print("âœ… ì˜ì—…ì¼ ë§¤í•‘ ìƒì„± ì™„ë£Œ")
        else:
            print("âŒ ì˜ì—…ì¼ ë§¤í•‘ ìƒì„± ì‹¤íŒ¨")
            return False
        
        print()
        print("ğŸ‰ ëª¨ë“  ê³¼ê±° ë°ì´í„° ìˆ˜ì§‘ ë° ì²˜ë¦¬ ì™„ë£Œ!")
        print()
        print("ğŸ“‹ ìƒì„±ëœ íŒŒì¼ë“¤:")
        print(f"  â€¢ {self.cache_file} - ê³¼ê±° ë°ì´í„° ìºì‹œ")
        print(f"  â€¢ ../../posco_business_day_mapping.json - ì˜ì—…ì¼ ë§¤í•‘")
        
        return True

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    collector = HistoricalDataCollector()
    
    try:
        success = collector.run_collection()
        return 0 if success else 1
    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•œ ì¤‘ë‹¨")
        return 1
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())