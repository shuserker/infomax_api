#!/usr/bin/env python3
"""
ê³¼ê±° ë‚ ì§œ í†µí•© ë¦¬í¬íŠ¸ ìƒì„±ê¸°
2025-07-25ë¶€í„° 2025-07-30ê¹Œì§€ í†µí•© ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import json
from datetime import datetime, timedelta
from reports.integrated_report_generator import IntegratedReportGenerator
from reports.metadata_manager import ReportMetadataManager

class HistoricalReportGenerator:
    def __init__(self):
        self.integrated_generator = IntegratedReportGenerator()
        self.metadata_manager = ReportMetadataManager()
        
    def generate_sample_news_data(self, date_str, report_type):
        """ìƒ˜í”Œ ë‰´ìŠ¤ ë°ì´í„° ìƒì„± (ë”•ì…”ë„ˆë¦¬ í˜•íƒœ)"""
        base_date = datetime.strptime(date_str, '%Y-%m-%d')
        
        # ë‚ ì§œë³„ ë‹¤ì–‘í•œ ë‰´ìŠ¤ ë°ì´í„° (ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜)
        news_templates = {
            'exchange-rate': {
                'title': f'{date_str} ì›/ë‹¬ëŸ¬ í™˜ìœ¨ ë™í–¥',
                'content': f'{base_date.strftime("%mì›” %dì¼")} ì„œìš¸ ì™¸í™˜ì‹œì¥ì—ì„œ ì›/ë‹¬ëŸ¬ í™˜ìœ¨ì´ ì „ì¼ ëŒ€ë¹„ ì†Œí­ ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤.',
                'sentiment': 'ì•ˆì •',
                'keywords': ['í™˜ìœ¨', 'ë‹¬ëŸ¬', 'ì™¸í™˜ì‹œì¥'],
                'analysis': {
                    'market_impact': 'ë³´í†µ',
                    'key_points': ['í™˜ìœ¨ ì•ˆì •ì„¸', 'ìˆ˜ì¶œ ê¸°ì—… ì˜í–¥']
                },
                'published_time': base_date.strftime('%Y-%m-%d %H:%M:%S'),
                'source': 'ì—°í•©ë‰´ìŠ¤',
                'url': f'https://example.com/news/{date_str}-exchange'
            },
            'kospi-close': {
                'title': f'{date_str} KOSPI ë§ˆê° í˜„í™©',
                'content': f'{base_date.strftime("%mì›” %dì¼")} ì½”ìŠ¤í”¼ ì§€ìˆ˜ê°€ ì™¸êµ­ì¸ ë§¤ìˆ˜ì„¸ì— í˜ì…ì–´ ìƒìŠ¹ ë§ˆê°í–ˆìŠµë‹ˆë‹¤.',
                'sentiment': 'ìƒìŠ¹',
                'keywords': ['KOSPI', 'ì¦ì‹œ', 'ì™¸êµ­ì¸'],
                'analysis': {
                    'market_impact': 'ë†’ìŒ',
                    'key_points': ['ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜', 'ê¸°ê´€ ë§¤ë„']
                },
                'published_time': base_date.strftime('%Y-%m-%d %H:%M:%S'),
                'source': 'í•œêµ­ê²½ì œ',
                'url': f'https://example.com/news/{date_str}-kospi'
            },
            'newyork-market-watch': {
                'title': f'{date_str} ë‰´ìš• ì¦ì‹œ ë™í–¥',
                'content': f'{base_date.strftime("%mì›” %dì¼")} ë‰´ìš• ì¦ì‹œê°€ ê¸°ìˆ ì£¼ ì¤‘ì‹¬ìœ¼ë¡œ ìƒìŠ¹ì„¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.',
                'sentiment': 'ìƒìŠ¹',
                'keywords': ['ë‰´ìš•', 'ë‚˜ìŠ¤ë‹¥', 'ê¸°ìˆ ì£¼'],
                'analysis': {
                    'market_impact': 'ë†’ìŒ',
                    'key_points': ['ê¸°ìˆ ì£¼ ê°•ì„¸', 'Fed ì •ì±… ê¸°ëŒ€']
                },
                'published_time': base_date.strftime('%Y-%m-%d %H:%M:%S'),
                'source': 'MarketWatch',
                'url': f'https://example.com/news/{date_str}-nyse'
            }
        }
        
        return news_templates.get(report_type, {})
    
    def generate_integrated_news_data(self, date_str):
        """í†µí•© ë‰´ìŠ¤ ë°ì´í„° ìƒì„±"""
        all_news = []
        
        # ê° íƒ€ì…ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
        for news_type in ['exchange-rate', 'kospi-close', 'newyork-market-watch']:
            news_data = self.generate_sample_news_data(date_str, news_type)
            all_news.extend(news_data)
        
        return all_news
    
    def generate_historical_reports(self, start_date='2025-07-25', end_date='2025-07-30'):
        """ê³¼ê±° ë‚ ì§œ í†µí•© ë¦¬í¬íŠ¸ ìƒì„±"""
        print(f"ğŸ“… {start_date}ë¶€í„° {end_date}ê¹Œì§€ í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì‹œì‘...")
        
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.strptime(end_date, '%Y-%m-%d')
        
        current_date = start
        generated_reports = []
        
        while current_date <= end:
            date_str = current_date.strftime('%Y-%m-%d')
            print(f"\nğŸ“Š {date_str} í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
            
            # í†µí•© ë‰´ìŠ¤ ë°ì´í„° ìƒì„±
            integrated_news = self.generate_integrated_news_data(date_str)
            
            if integrated_news:
                # í†µí•© ë¦¬í¬íŠ¸ ìƒì„±
                news_data_dict = {
                    'exchange-rate': self.generate_sample_news_data(date_str, 'exchange-rate'),
                    'kospi-close': self.generate_sample_news_data(date_str, 'kospi-close'),
                    'newyork-market-watch': self.generate_sample_news_data(date_str, 'newyork-market-watch')
                }
                
                report_info = self.integrated_generator.generate_integrated_report(news_data_dict)
                
                if report_info and not report_info.get('error'):
                    # ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
                    self.metadata_manager.add_report(
                        report_info['filename'],
                        report_info.get('local_path')
                    )
                    
                    generated_reports.append({
                        'date': date_str,
                        'filename': report_info['filename'],
                        'status': 'success'
                    })
                    
                    print(f"âœ… {date_str} ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {report_info['filename']}")
                else:
                    print(f"âŒ {date_str} ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨")
                    generated_reports.append({
                        'date': date_str,
                        'status': 'failed'
                    })
            
            current_date += timedelta(days=1)
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“‹ ìƒì„± ê²°ê³¼ ìš”ì•½:")
        success_count = len([r for r in generated_reports if r['status'] == 'success'])
        total_count = len(generated_reports)
        
        print(f"âœ… ì„±ê³µ: {success_count}/{total_count}")
        print(f"ğŸ“ ìƒì„±ëœ ë¦¬í¬íŠ¸:")
        
        for report in generated_reports:
            if report['status'] == 'success':
                print(f"  - {report['date']}: {report['filename']}")
        
        return generated_reports
    
    def cleanup_old_individual_reports(self):
        """ê¸°ì¡´ ê°œë³„ ë¦¬í¬íŠ¸ ì •ë¦¬"""
        print("ğŸ§¹ ê¸°ì¡´ ê°œë³„ ë¦¬í¬íŠ¸ ì •ë¦¬ ì¤‘...")
        
        # reports_index.json ì½ê¸° (ìƒìœ„ ë””ë ‰í† ë¦¬)
        index_path = "../docs/reports_index.json"
        if not os.path.exists(index_path):
            print("âŒ reports_index.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        with open(index_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        original_count = len(data['reports'])
        
        # 2025-07-25 ì´í›„ì˜ ê°œë³„ ë¦¬í¬íŠ¸ ì œê±°
        filtered_reports = []
        removed_files = []
        
        for report in data['reports']:
            # í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ëŠ” ìœ ì§€
            if report['id'].startswith('test_'):
                filtered_reports.append(report)
                continue
            
            # 2025-07-25 ì´í›„ì˜ ê°œë³„ exchange-rate ë¦¬í¬íŠ¸ ì œê±°
            if (report['type'] == 'exchange-rate' and 
                report['date'] >= '2025-07-25' and
                'posco_analysis_exchange-rate' in report['id']):
                removed_files.append(report['filename'])
                continue
            
            # ë‚˜ë¨¸ì§€ëŠ” ìœ ì§€
            filtered_reports.append(report)
        
        # ì—…ë°ì´íŠ¸ëœ ë°ì´í„° ì €ì¥
        data['reports'] = filtered_reports
        data['totalReports'] = len(filtered_reports)
        data['lastUpdate'] = datetime.now().isoformat() + 'Z'
        
        with open(index_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        removed_count = original_count - len(filtered_reports)
        print(f"âœ… {removed_count}ê°œ ê°œë³„ ë¦¬í¬íŠ¸ ë©”íƒ€ë°ì´í„° ì œê±° ì™„ë£Œ")
        print(f"ğŸ“Š ë‚¨ì€ ë¦¬í¬íŠ¸: {len(filtered_reports)}ê°œ")
        
        # ì‹¤ì œ íŒŒì¼ë„ ì œê±°
        reports_dir = "../docs/reports"
        if os.path.exists(reports_dir):
            actual_removed = 0
            for filename in removed_files:
                file_path = os.path.join(reports_dir, filename)
                if os.path.exists(file_path):
                    os.remove(file_path)
                    actual_removed += 1
            
            print(f"ğŸ—‘ï¸ {actual_removed}ê°œ ê°œë³„ ë¦¬í¬íŠ¸ íŒŒì¼ ì œê±° ì™„ë£Œ")

def main():
    generator = HistoricalReportGenerator()
    
    # 1. ê¸°ì¡´ ê°œë³„ ë¦¬í¬íŠ¸ ì •ë¦¬
    generator.cleanup_old_individual_reports()
    
    # 2. ìƒˆë¡œìš´ í†µí•© ë¦¬í¬íŠ¸ ìƒì„±
    generator.generate_historical_reports('2025-07-25', '2025-07-30')
    
    print("\nğŸ‰ ê³¼ê±° í†µí•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    main()