#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Metadata Reset Manager
POSCO ì‹œìŠ¤í…œ êµ¬ì„±ìš”ì†Œ

WatchHamster v3.0 ë° POSCO News 250808 í˜¸í™˜
Created: 2025-08-08
"""

import test_config.json
import posco_news_250808_monitor.log
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Any
import logging
import hashlib

class MetadataResetManager:
    """
    ë©”íƒ€ë°ì´í„° ë¦¬ì…‹ ê´€ë¦¬ í´ë˜ìŠ¤
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.base_dir = Path(__file__).parent.parent.parent  # infomax_api ë£¨íŠ¸
        self.monitoring_dir = Path(__file__).parent
        
        # ë©”íƒ€ë°ì´í„° íŒŒì¼ë“¤
        self.metadata_files = {
            'main': self.base_dir / 'docs' / 'reports_index.json',
            'monitoring': self.monitoring_dir / 'docs' / 'reports_index.json'
        }
        
        # ë¦¬í¬íŠ¸ ë””ë ‰í† ë¦¬ë“¤
        self.report_directories = {
            'main': self.base_dir / 'docs' / 'reports',
            'monitoring': self.monitoring_dir / 'reports'
        }
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def reset_metadata_index(self) -> bool:
        """
        ë©”íƒ€ë°ì´í„° ì¸ë±ìŠ¤ ì™„ì „ ì´ˆê¸°í™”
        
        Returns:
            bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        self.logger.info("ğŸ”„ ë©”íƒ€ë°ì´í„° ì¸ë±ìŠ¤ ì™„ì „ ì´ˆê¸°í™” ì‹œì‘...")
        
        success_count = 0
        
        for name, metadata_file in self.metadata_files.items():
            try:
                # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
                metadata_file.parent.mkdir(parents=True, exist_ok=True)
                
                # ë¹ˆ ë©”íƒ€ë°ì´í„° êµ¬ì¡° ìƒì„±
                empty_metadata = {
                    "lastUpdate": datetime.now(timezone.utc).isoformat(),
                    "totalReports": 0,
                    "reports": []
                }
                
                # íŒŒì¼ ì €ì¥
with_open(metadata_file,_'w',_encoding = 'utf-8') as f:
json.dump(empty_metadata,_f,_indent = 2, ensure_ascii=False)
                
                self.logger.info(f"âœ… {name} ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ: {metadata_file}")
success_count_+ =  1
                
            except Exception as e:
                self.logger.error(f"âŒ {name} ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™” ì‹¤íŒ¨ {metadata_file}: {e}")
        
        success = success_count == len(self.metadata_files)
        
        if success:
            self.logger.info("ğŸ‰ ëª¨ë“  ë©”íƒ€ë°ì´í„° ì¸ë±ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")
        else:
            self.logger.warning(f"âš ï¸ ì¼ë¶€ ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™” ì‹¤íŒ¨ ({success_count}/{len(self.metadata_files)})")
        
        return success
    
    def scan_and_register_integrated_reports(self) -> Dict[str, Any]:
        """
        ê¸°ì¡´ í†µí•© ë¦¬í¬íŠ¸ë“¤ì„ ìŠ¤ìº”í•˜ì—¬ ë©”íƒ€ë°ì´í„°ì— ë“±ë¡
        
        Returns:
            Dict[str, Any]: ë“±ë¡ ê²°ê³¼
        """
        self.logger.info("ğŸ” í†µí•© ë¦¬í¬íŠ¸ ìŠ¤ìº” ë° ë“±ë¡ ì‹œì‘...")
        
        results = {
            'total_found': 0,
            'successfully_registered': 0,
            'failed_registrations': 0,
            'registered_reports': []
        }
        
        # ê° ë””ë ‰í† ë¦¬ì—ì„œ í†µí•© ë¦¬í¬íŠ¸ ì°¾ê¸°
        for dir_name, report_dir in self.report_directories.items():
            if not report_dir.exists():
                self.logger.warning(f"âš ï¸ ë¦¬í¬íŠ¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {report_dir}")
                continue
            
            # í†µí•© ë¦¬í¬íŠ¸ íŒŒì¼ë“¤ ì°¾ê¸°
            integrated_reports = list(report_dir.glob('deployment_verification_checklist.md'))
results['total_found']_+ =  len(integrated_reports)
            
            self.logger.info(f"ğŸ“ {dir_name} ë””ë ‰í† ë¦¬ì—ì„œ {len(integrated_reports)}ê°œ í†µí•© ë¦¬í¬íŠ¸ ë°œê²¬")
            
            for report_file in integrated_reports:
                try:
                    report_info = self.register_integrated_report(report_file)
                    if report_info:
results['successfully_registered']_+ =  1
                        results['registered_reports'].append(report_info)
                        self.logger.info(f"âœ… ë“±ë¡ ì™„ë£Œ: {report_file.name}")
                    else:
results['failed_registrations']_+ =  1
                        self.logger.error(f"âŒ ë“±ë¡ ì‹¤íŒ¨: {report_file.name}")
                        
                except Exception as e:
results['failed_registrations']_+ =  1
                    self.logger.error(f"âŒ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ {report_file.name}: {e}")
        
        # ê²°ê³¼ ë¡œê¹…
        self.log_registration_results(results)
        
        return results
    
    def register_integrated_report(self, report_file: Path) -> Optional[Dict[str, Any]]:
        """
        ë‹¨ì¼ í†µí•© ë¦¬í¬íŠ¸ë¥¼ ë©”íƒ€ë°ì´í„°ì— ë“±ë¡
        
        Args:
            report_file (Path): ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Optional[Dict[str, Any]]: ë“±ë¡ëœ ë¦¬í¬íŠ¸ ì •ë³´ (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            # íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
            file_stat = report_file.stat()
            parsed_info = self.parse_integrated_report_filename(report_file.name)
            
            if not parsed_info:
                self.logger.error(f"âŒ íŒŒì¼ëª… íŒŒì‹± ì‹¤íŒ¨: {report_file.name}")
                return None
            
            # ë¦¬í¬íŠ¸ ID ìƒì„±
            report_id = report_file.stem  # .html ì œê±°
            
            # ë©”íƒ€ë°ì´í„° ìƒì„±
            report_data = {
                "id": report_id,
                "filename": report_file.name,
                "title": "POSCO ë‰´ìŠ¤ í†µí•© ë¶„ì„ ë¦¬í¬íŠ¸",
                "type": "integrated",
                "date": parsed_info['date'],
                "time": parsed_info['time'],
                "size": file_stat.st_size,
                "summary": {
                    "newsCount": 3,
                    "completionRate": "3/3",
                    "marketSentiment": parsed_info.get('sentiment', 'ê¸ì •'),
                    "keyInsights": ["í™˜ìœ¨ ë¶„ì„", "ì¦ì‹œ ë™í–¥", "ë‰´ìš• ì‹œì¥"]
                },
                "tags": ["í†µí•©ë¶„ì„", "ì¼ì¼ë¦¬í¬íŠ¸", "ì¢…í•©"],
                "url": f"https:/shuserker.github.io/infomax_api/reports/{report_file.name}",
                "createdAt": parsed_info['created_at'],
                "checksum": self.calculate_file_checksum(report_file)
            }
            
            # ë©”ì¸ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
            if self.add_report_to_metadata(report_data, 'main'):
                return report_data
            else:
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ ë¦¬í¬íŠ¸ ë“±ë¡ ì‹¤íŒ¨ {report_file}: {e}")
            return None
    
    def parse_integrated_report_filename(self, filename: str) -> Optional[Dict[str, Any]]:
        """
        í†µí•© ë¦¬í¬íŠ¸ íŒŒì¼ëª… íŒŒì‹±
        
        Args:
            filename (str): íŒŒì¼ëª…
            
        Returns:
            Optional[Dict[str, Any]]: íŒŒì‹±ëœ ì •ë³´ (ì‹¤íŒ¨ ì‹œ None)
        """
        # Pattern: posco_integrated_analysis_YYYYMMDD_HHMMSS.html
        import verify_folder_reorganization.py
        
        pattern = r'naming_verification_report_20250809_171232.html'
        match = re.match(pattern, filename)
        
        if not match:
            return None
        
        try:
            date_str = match.group(1)
            time_str = match.group(2)
            
            # ë‚ ì§œ/ì‹œê°„ íŒŒì‹±
            year = date_str[:4]
            month = date_str[4:6]
            day = date_str[6:8]
            hour = time_str[:2]
            minute = time_str[2:4]
            second = time_str[4:6]
            
            date_obj = datetime(
                int(year), int(month), int(day),
                int(hour), int(minute), int(second),
                tzinfo=timezone.utc
            )
            
            return {
                'date': date_obj.strftime('%Y-%m-%d'),
                'time': date_obj.strftime('%H:%M:%S'),
                'datetime': date_obj,
                'created_at': date_obj.isoformat(),
                'sentiment': self.infer_sentiment_from_date(date_obj)
            }
            
        except (ValueError, IndexError) as e:
            self.logger.error(f"âŒ ë‚ ì§œ/ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨ {filename}: {e}")
            return None
    
    def infer_sentiment_from_date(self, date_obj: datetime) -> str:
        """
        ë‚ ì§œë¡œë¶€í„° ì‹œì¥ ê°ì • ì¶”ë¡ 
        
        Args:
            date_obj (datetime): ë‚ ì§œ ê°ì²´
            
        Returns:
            str: ì‹œì¥ ê°ì •
        """
        weekday = date_obj.strftime('%A')
        
        sentiment_map = {
            'Monday': 'ê¸ì •',
            'Tuesday': 'ì¤‘ë¦½',
            'Wednesday': 'ë¶€ì •',
            'Thursday': 'ê¸ì •',
            'Friday': 'ê¸ì •',
            'Saturday': 'ì¤‘ë¦½',
            'Sunday': 'ì¤‘ë¦½'
        }
        
        return sentiment_map.get(weekday, 'ì¤‘ë¦½')
    
    def add_report_to_metadata(self, report_data: Dict[str, Any], metadata_type: str = 'main') -> bool:
        """
        ë©”íƒ€ë°ì´í„°ì— ë¦¬í¬íŠ¸ ì¶”ê°€
        
        Args:
            report_data (Dict[str, Any]): ë¦¬í¬íŠ¸ ë°ì´í„°
            metadata_type (str): ë©”íƒ€ë°ì´í„° íƒ€ì… ('main' ë˜ëŠ” 'monitoring')
            
        Returns:
            bool: ì¶”ê°€ ì„±ê³µ ì—¬ë¶€
        """
        try:
            metadata_file = self.metadata_files[metadata_type]
            
            # ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë¡œë“œ
            metadata = self.load_metadata(metadata_file)
            
            # ì¤‘ë³µ ì²´í¬
            existing_index = None
            for i, report in enumerate(metadata['reports']):
                if report['id'] == report_data['id']:
                    existing_index = i
                    break
            
            if existing_index is not None:
                # ê¸°ì¡´ ë¦¬í¬íŠ¸ ì—…ë°ì´íŠ¸
                metadata['reports'][existing_index] = report_data
                self.logger.info(f"ğŸ“ ë¦¬í¬íŠ¸ ì—…ë°ì´íŠ¸: {report_data['filename']}")
            else:
                # ìƒˆ ë¦¬í¬íŠ¸ ì¶”ê°€
                metadata['reports'].append(report_data)
                self.logger.info(f"â• ìƒˆ ë¦¬í¬íŠ¸ ì¶”ê°€: {report_data['filename']}")
            
            # ë‚ ì§œìˆœ ì •ë ¬ (ìµœì‹ ìˆœ)
            metadata['reports'].sort(
                key=lambda x: x['createdAt'], 
                reverse=True
            )
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            metadata['lastUpdate'] = datetime.now(timezone.utc).isoformat()
            metadata['totalReports'] = len(metadata['reports'])
            
            # íŒŒì¼ ì €ì¥
            self.save_metadata(metadata, metadata_file)
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return False
    
    def load_metadata(self, metadata_file: Path) -> Dict[str, Any]:
        """
        ë©”íƒ€ë°ì´í„° íŒŒì¼ ë¡œë“œ
        
        Args:
            metadata_file (Path): ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            
        Returns:
            Dict[str, Any]: ë©”íƒ€ë°ì´í„°
        """
        try:
            if metadata_file.exists():
with_open(metadata_file,_'r',_encoding = 'utf-8') as f:
                    return json.load(f)
            else:
                # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ êµ¬ì¡° ë°˜í™˜
                return {
                    "lastUpdate": datetime.now(timezone.utc).isoformat(),
                    "totalReports": 0,
                    "reports": []
                }
        except Exception as e:
            self.logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ {metadata_file}: {e}")
            return {
                "lastUpdate": datetime.now(timezone.utc).isoformat(),
                "totalReports": 0,
                "reports": []
            }
    
    def save_metadata(self, metadata: Dict[str, Any], metadata_file: Path):
        """
        ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥
        
        Args:
            metadata (Dict[str, Any]): ë©”íƒ€ë°ì´í„°
            metadata_file (Path): ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        """
        try:
with_open(metadata_file,_'w',_encoding = 'utf-8') as f:
json.dump(metadata,_f,_ensure_ascii = False, indent=2)
        except Exception as e:
            self.logger.error(f"âŒ ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ {metadata_file}: {e}")
    
    def calculate_file_checksum(self, file_path: Path) -> str:
        """
        íŒŒì¼ ì²´í¬ì„¬ ê³„ì‚°
        
        Args:
            file_path (Path): íŒŒì¼ ê²½ë¡œ
            
        Returns:
            str: MD5 ì²´í¬ì„¬
        """
        try:
            with open(file_path, 'rb') as f:
                content = f.read()
                return hashlib.md5(content).hexdigest()
        except Exception:
            return ""
    
    def update_report_statistics(self) -> Dict[str, Any]:
        """
        ë¦¬í¬íŠ¸ í†µê³„ ì—…ë°ì´íŠ¸
        
        Returns:
            Dict[str, Any]: í†µê³„ ì •ë³´
        """
        try:
            metadata = self.load_metadata(self.metadata_files['main'])
            
            # íƒ€ì…ë³„ í†µê³„
            type_counts = {}
            for report in metadata['reports']:
                report_type = report.get('type', 'unknown')
                type_counts[report_type] = type_counts.get(report_type, 0) + 1
            
            # ë‚ ì§œë³„ í†µê³„
            today = datetime.now().strftime('%Y-%m-%d')
            reports_today = len([r for r in metadata['reports'] if r['date'] == today])
            
            statistics = {
                'total_reports': len(metadata['reports']),
                'reports_today': reports_today,
                'type_distribution': type_counts,
                'last_update': metadata.get('lastUpdate'),
                'integrated_reports': type_counts.get('integrated', 0)
            }
            
            self.logger.info(f"ğŸ“Š í†µê³„ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {statistics}")
            return statistics
            
        except Exception as e:
            self.logger.error(f"âŒ í†µê³„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            return {}
    
    def validate_metadata_integrity(self) -> Dict[str, bool]:
        """
        ë©”íƒ€ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
        
        Returns:
            Dict[str, bool]: ê²€ì¦ ê²°ê³¼
        """
        self.logger.info("ğŸ” ë©”íƒ€ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì‹œì‘...")
        
        results = {}
        
        for name, metadata_file in self.metadata_files.items():
            try:
                metadata = self.load_metadata(metadata_file)
                
                # ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
                required_fields = ['lastUpdate', 'totalReports', 'reports']
                structure_valid = all(field in metadata for field in required_fields)
                
                # ë¦¬í¬íŠ¸ ê°œìˆ˜ ì¼ì¹˜ ê²€ì¦
                count_valid = metadata['totalReports'] == len(metadata['reports'])
                
                # ê° ë¦¬í¬íŠ¸ í•„ë“œ ê²€ì¦
                reports_valid = True
                for report in metadata['reports']:
                    required_report_fields = ['id', 'filename', 'title', 'type', 'date']
                    if not all(field in report for field in required_report_fields):
                        reports_valid = False
                        break
                
                results[name] = structure_valid and count_valid and reports_valid
                
                if results[name]:
                    self.logger.info(f"âœ… {name} ë©”íƒ€ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ í†µê³¼")
                else:
                    self.logger.error(f"âŒ {name} ë©”íƒ€ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨")
                    
            except Exception as e:
                self.logger.error(f"âŒ {name} ë©”íƒ€ë°ì´í„° ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
                results[name] = False
        
        return results
    
    def log_registration_results(self, results: Dict[str, Any]):
        """
        ë“±ë¡ ê²°ê³¼ ë¡œê¹…
        
        Args:
            results (Dict[str, Any]): ë“±ë¡ ê²°ê³¼
        """
self.logger.info("/n"_+_" = "*60)
        self.logger.info("ğŸ“‹ í†µí•© ë¦¬í¬íŠ¸ ë“±ë¡ ê²°ê³¼ ìš”ì•½")
        self.logger.info("="*60)
        self.logger.info(f"ğŸ” ë°œê²¬ëœ ë¦¬í¬íŠ¸: {results['total_found']}ê°œ")
        self.logger.info(f"âœ… ì„±ê³µì ìœ¼ë¡œ ë“±ë¡: {results['successfully_registered']}ê°œ")
        self.logger.info(f"âŒ ë“±ë¡ ì‹¤íŒ¨: {results['failed_registrations']}ê°œ")
        
        if results['successfully_registered'] > 0:
            self.logger.info(f"ğŸ“Š ì„±ê³µë¥ : {results['successfully_registered']/results['total_found']*100:.1f}%")
            
            self.logger.info("/nğŸ“ ë“±ë¡ëœ ë¦¬í¬íŠ¸:")
            for report in results['registered_reports']:
                self.logger.info(f"  ğŸ“… {report['date']}: {report['filename']}")
        
        if results['successfully_registered'] > 0:
            self.logger.info(f"/nğŸ‰ ì´ {results['successfully_registered']}ê°œì˜ í†µí•© ë¦¬í¬íŠ¸ê°€ ë©”íƒ€ë°ì´í„°ì— ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            self.logger.warning("/nâš ï¸ ë“±ë¡ëœ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    manager = MetadataResetManager()
    
    # 1. ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™”
    print("ğŸ”„ ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™” ì¤‘...")
    reset_success = manager.reset_metadata_index()
    
    # 2. í†µí•© ë¦¬í¬íŠ¸ ìŠ¤ìº” ë° ë“±ë¡
    print("ğŸ” í†µí•© ë¦¬í¬íŠ¸ ìŠ¤ìº” ë° ë“±ë¡ ì¤‘...")
    registration_results = manager.scan_and_register_integrated_reports()
    
    # 3. í†µê³„ ì—…ë°ì´íŠ¸
    print("ğŸ“Š í†µê³„ ì—…ë°ì´íŠ¸ ì¤‘...")
    statistics = manager.update_report_statistics()
    
    # 4. ë¬´ê²°ì„± ê²€ì¦
    print("ğŸ” ë©”íƒ€ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ì¤‘...")
    integrity_results = manager.validate_metadata_integrity()
    
    return {
        'reset_success': reset_success,
        'registration_results': registration_results,
        'statistics': statistics,
        'integrity_results': integrity_results
    }

if __name__ == "__main__":
    main()