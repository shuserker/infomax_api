#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Performance Monitor
POSCO ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

WatchHamster v3.0 ë° POSCO News 250808 í˜¸í™˜
Created: 2025-08-08
"""

import psutil
import .comprehensive_repair_backup/realtime_news_monitor.py.backup_20250809_181657
import test_config.json
import posco_news_250808_monitor.log
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import threading
import statistics
from collections import deque, defaultdict

class PerformanceLevel(Enum):
    """ì„±ëŠ¥ ìˆ˜ì¤€ ì—´ê±°í˜•"""
    EXCELLENT = "excellent"
    GOOD = "good"
    WARNING = "warning"
    CRITICAL = "critical"

class MetricType(Enum):
    """ë©”íŠ¸ë¦­ íƒ€ì… ì—´ê±°í˜•"""
    CPU_USAGE = "cpu_usage"
    MEMORY_USAGE = "memory_usage"
    RESPONSE_TIME = "response_time"
    PROCESS_COUNT = "process_count"
    SYSTEM_LOAD = "system_load"

@dataclass
class PerformanceMetric:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: datetime
    metric_type: MetricType
    value: float
process_name:_Optional[str] =  None
operation_name:_Optional[str] =  None
additional_data:_Optional[Dict[str,_Any]] =  None

@dataclass
class SystemPerformanceSnapshot:
    """ì‹œìŠ¤í…œ ì„±ëŠ¥ ìŠ¤ëƒ…ìƒ·"""
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    memory_available_mb: float
    disk_usage_percent: float
    process_count: int
    active_processes: List[str]
system_load_avg:_Optional[Tuple[float,_float,_float]] =  None
network_io:_Optional[Dict[str,_int]] =  None

@dataclass
class ProcessPerformanceData:
    """í”„ë¡œì„¸ìŠ¤ë³„ ì„±ëŠ¥ ë°ì´í„°"""
    process_name: str
    pid: int
    cpu_percent: float
    memory_percent: float
    memory_mb: float
    status: str
    create_time: datetime
    num_threads: int
io_counters:_Optional[Dict[str,_int]] =  None

@dataclass
class PerformanceComparison:
    """v1/v2 ì„±ëŠ¥ ë¹„êµ ê²°ê³¼"""
    comparison_time: datetime
    v1_metrics: Dict[str, float]
    v2_metrics: Dict[str, float]
    improvement_percentage: Dict[str, float]
    recommendations: List[str]

class PerformanceMonitor:
    """
    POSCO WatchHamster v3.0.0 ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
    
    ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•˜ê³ ,
    ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë¶„ì„ ë° ê¶Œì¥ì‚¬í•­ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, script_dir: str, monitoring_interval: int = 60):
        """
        PerformanceMonitor ì´ˆê¸°í™”
        
        Args:
            script_dir (str): ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            monitoring_interval (int): ëª¨ë‹ˆí„°ë§ ê°„ê²© (ì´ˆ)
        """
        self.script_dir = script_dir
        self.monitoring_interval = monitoring_interval
        self.logger = logging.getLogger(__name__)
        
        # ì„±ëŠ¥ ë°ì´í„° ì €ì¥ì†Œ
self.metrics_history:_deque =  deque(maxlen=1440)  # 24ì‹œê°„ ë¶„ëŸ‰ (1ë¶„ ê°„ê²©)
self.process_metrics:_Dict[str,_deque] =  defaultdict(lambda: deque(maxlen=60))  # 1ì‹œê°„ ë¶„ëŸ‰
self.response_times:_Dict[str,_deque] =  defaultdict(lambda: deque(maxlen=100))  # ìµœê·¼ 100íšŒ
        
        # ì„±ëŠ¥ ì„ê³„ê°’ ì„¤ì •
        self.thresholds = {
            'cpu_warning': 70.0,
            'cpu_critical': 85.0,
            'memory_warning': 75.0,
            'memory_critical': 90.0,
            'response_time_warning': 5.0,  # 5ì´ˆ
            'response_time_critical': 10.0,  # 10ì´ˆ
            'process_count_warning': 20,
            'process_count_critical': 30
        }
        
        # ëª¨ë‹ˆí„°ë§ ìƒíƒœ
        self.is_monitoring = False
        self.monitoring_thread = None
        self.start_time = datetime.now()
        
        # ì„±ëŠ¥ í†µê³„
        self.total_measurements = 0
        self.alert_count = 0
        self.last_optimization_check = datetime.now()
        
        # v1/v2 ë¹„êµ ë°ì´í„°
        self.v1_baseline = None
        self.v2_performance_data = {}
        
        self.logger.info("ğŸ“Š PerformanceMonitor ì´ˆê¸°í™” ì™„ë£Œ")
    
    def start_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if self.is_monitoring:
            self.logger.warning("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤")
            return
        
        self.is_monitoring = True
        self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitoring_thread.start()
        
        self.logger.info(f"ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ê°„ê²©: {self.monitoring_interval}ì´ˆ)")
    
    def stop_monitoring(self):
        """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.is_monitoring = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        
        self.logger.info("ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    def _monitoring_loop(self):
        """ëª¨ë‹ˆí„°ë§ ë©”ì¸ ë£¨í”„"""
        while self.is_monitoring:
            try:
                # ì‹œìŠ¤í…œ ì„±ëŠ¥ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘
                snapshot = self._collect_system_snapshot()
                self.metrics_history.append(snapshot)
                
                # í”„ë¡œì„¸ìŠ¤ë³„ ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
                self._collect_process_metrics()
                
                # ì„±ëŠ¥ ë¶„ì„ ë° ì•Œë¦¼ ì²´í¬
                self._analyze_performance()
                
self.total_measurements_+ =  1
                
                # ë‹¤ìŒ ì¸¡ì •ê¹Œì§€ ëŒ€ê¸°
                time.sleep(self.monitoring_interval)
                
            except Exception as e:
                self.logger.error(f"ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                time.sleep(self.monitoring_interval)
    
    def _collect_system_snapshot(self) -> SystemPerformanceSnapshot:
        """ì‹œìŠ¤í…œ ì„±ëŠ¥ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘"""
        try:
            # CPU ì‚¬ìš©ë¥ 
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # ë©”ëª¨ë¦¬ ì •ë³´
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_available_mb = memory.available / (1024 * 1024)
            
            # ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
            disk = psutil.disk_usage('/')
            disk_usage_percent = disk.percent
            
            # í”„ë¡œì„¸ìŠ¤ ìˆ˜
            process_count = len(psutil.pids())
            
            # í™œì„± í”„ë¡œì„¸ìŠ¤ ëª©ë¡ (ì›Œì¹˜í–„ìŠ¤í„° ê´€ë ¨)
            active_processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    if proc.info['cmdline'] and any('posco' in cmd.lower() or 'watchhamster' in cmd.lower() 
                                                   for cmd in proc.info['cmdline']):
                        active_processes.append(proc.info['name'])
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            # ì‹œìŠ¤í…œ ë¡œë“œ (Linux/macOSë§Œ)
            system_load_avg = None
            try:
                if hasattr(os, 'getloadavg'):
                    system_load_avg = os.getloadavg()
            except (OSError, AttributeError):
                pass
            
            # ë„¤íŠ¸ì›Œí¬ I/O
            network_io = None
            try:
                net_io = psutil.net_io_counters()
                if net_io:
                    network_io = {
                        'bytes_sent': net_io.bytes_sent,
                        'bytes_recv': net_io.bytes_recv,
                        'packets_sent': net_io.packets_sent,
                        'packets_recv': net_io.packets_recv
                    }
            except Exception:
                pass
            
            return SystemPerformanceSnapshot(
                timestamp=datetime.now(),
                cpu_percent=cpu_percent,
                memory_percent=memory_percent,
                memory_available_mb=memory_available_mb,
                disk_usage_percent=disk_usage_percent,
                process_count=process_count,
                active_processes=active_processes,
                system_load_avg=system_load_avg,
                network_io=network_io
            )
            
        except Exception as e:
            self.logger.error(f"ì‹œìŠ¤í…œ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ë¹ˆ ìŠ¤ëƒ…ìƒ· ë°˜í™˜
            return SystemPerformanceSnapshot(
                timestamp=datetime.now(),
                cpu_percent=0.0,
                memory_percent=0.0,
                memory_available_mb=0.0,
                disk_usage_percent=0.0,
                process_count=0,
                active_processes=[]
            )
    
    def _collect_process_metrics(self):
        """í”„ë¡œì„¸ìŠ¤ë³„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            current_time = datetime.now()
            
            # ì›Œì¹˜í–„ìŠ¤í„° ê´€ë ¨ í”„ë¡œì„¸ìŠ¤ ì°¾ê¸°
            watchhamster_processes = []
            
            for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'cpu_percent', 
                                           'memory_percent', 'memory_info', 'status', 
                                           'create_time', 'num_threads']):
                try:
                    if not proc.info['cmdline']:
                        continue
                    
                    # ì›Œì¹˜í–„ìŠ¤í„° ê´€ë ¨ í”„ë¡œì„¸ìŠ¤ ì‹ë³„
                    cmdline_str = ' '.join(proc.info['cmdline']).lower()
                    if any(keyword in cmdline_str for keyword in 
                          ['posco', 'watchhamster', 'monitor_watchhamster', 
                           'POSCO News 250808_monitor', 
                           'integrated_report_scheduler']):
                        
                        # I/O ì¹´ìš´í„° ìˆ˜ì§‘ (ê°€ëŠ¥í•œ ê²½ìš°)
                        io_counters = None
                        try:
                            io_info = proc.io_counters()
                            if io_info:
                                io_counters = {
                                    'read_count': io_info.read_count,
                                    'write_count': io_info.write_count,
                                    'read_bytes': io_info.read_bytes,
                                    'write_bytes': io_info.write_bytes
                                }
                        except (psutil.AccessDenied, AttributeError):
                            pass
                        
                        process_data = ProcessPerformanceData(
                            process_name=proc.info['name'],
                            pid=proc.info['pid'],
                            cpu_percent=proc.info['cpu_percent'] or 0.0,
                            memory_percent=proc.info['memory_percent'] or 0.0,
                            memory_mb=(proc.info['memory_info'].rss / (1024 * 1024)) if proc.info['memory_info'] else 0.0,
                            status=proc.info['status'],
                            create_time=datetime.fromtimestamp(proc.info['create_time']),
                            num_threads=proc.info['num_threads'] or 0,
                            io_counters=io_counters
                        )
                        
                        watchhamster_processes.append(process_data)
                        
                        # í”„ë¡œì„¸ìŠ¤ë³„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                        process_key = f"{proc.info['name']}_{proc.info['pid']}"
                        self.process_metrics[process_key].append(process_data)
                        
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    continue
            
            # ìˆ˜ì§‘ëœ í”„ë¡œì„¸ìŠ¤ ìˆ˜ ë¡œê·¸
            if watchhamster_processes:
                self.logger.debug(f"í”„ë¡œì„¸ìŠ¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì™„ë£Œ: {len(watchhamster_processes)}ê°œ í”„ë¡œì„¸ìŠ¤")
            
        except Exception as e:
            self.logger.error(f"í”„ë¡œì„¸ìŠ¤ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    def _analyze_performance(self):
        """ì„±ëŠ¥ ë¶„ì„ ë° ì•Œë¦¼ ì²´í¬"""
        try:
            if not self.metrics_history:
                return
            
            latest_snapshot = self.metrics_history[-1]
            
            # CPU ì‚¬ìš©ë¥  ì²´í¬
            if latest_snapshot.cpu_percent > self.thresholds['cpu_critical']:
                self._trigger_performance_alert(
                    MetricType.CPU_USAGE, 
                    latest_snapshot.cpu_percent, 
                    PerformanceLevel.CRITICAL
                )
            elif latest_snapshot.cpu_percent > self.thresholds['cpu_warning']:
                self._trigger_performance_alert(
                    MetricType.CPU_USAGE, 
                    latest_snapshot.cpu_percent, 
                    PerformanceLevel.WARNING
                )
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì²´í¬
            if latest_snapshot.memory_percent > self.thresholds['memory_critical']:
                self._trigger_performance_alert(
                    MetricType.MEMORY_USAGE, 
                    latest_snapshot.memory_percent, 
                    PerformanceLevel.CRITICAL
                )
            elif latest_snapshot.memory_percent > self.thresholds['memory_warning']:
                self._trigger_performance_alert(
                    MetricType.MEMORY_USAGE, 
                    latest_snapshot.memory_percent, 
                    PerformanceLevel.WARNING
                )
            
            # í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì²´í¬
            if latest_snapshot.process_count > self.thresholds['process_count_critical']:
                self._trigger_performance_alert(
                    MetricType.PROCESS_COUNT, 
                    latest_snapshot.process_count, 
                    PerformanceLevel.CRITICAL
                )
            elif latest_snapshot.process_count > self.thresholds['process_count_warning']:
                self._trigger_performance_alert(
                    MetricType.PROCESS_COUNT, 
                    latest_snapshot.process_count, 
                    PerformanceLevel.WARNING
                )
            
            # ìµœì í™” ê¶Œì¥ì‚¬í•­ ì²´í¬ (1ì‹œê°„ë§ˆë‹¤)
            if datetime.now() - self.last_optimization_check > timedelta(hours=1):
                self._check_optimization_opportunities()
                self.last_optimization_check = datetime.now()
            
        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def _trigger_performance_alert(self, metric_type: MetricType, value: float, level: PerformanceLevel):
        """ì„±ëŠ¥ ì•Œë¦¼ íŠ¸ë¦¬ê±°"""
        try:
self.alert_count_+ =  1
            
            alert_message = self._generate_alert_message(metric_type, value, level)
            
            # ë¡œê·¸ ê¸°ë¡
            if level == PerformanceLevel.CRITICAL:
                self.logger.critical(alert_message)
            elif level == PerformanceLevel.WARNING:
                self.logger.warning(alert_message)
            else:
                self.logger.info(alert_message)
            
            # ì•Œë¦¼ íˆìŠ¤í† ë¦¬ì— ê¸°ë¡
            alert_record = {
                'timestamp': datetime.now().isoformat(),
                'metric_type': metric_type.value,
                'value': value,
                'level': level.value,
                'message': alert_message
            }
            
            # ì•Œë¦¼ íˆìŠ¤í† ë¦¬ íŒŒì¼ì— ì €ì¥
            self._save_alert_to_history(alert_record)
            
        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ ì•Œë¦¼ íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {e}")
    
    def _generate_alert_message(self, metric_type: MetricType, value: float, level: PerformanceLevel) -> str:
        """ì•Œë¦¼ ë©”ì‹œì§€ ìƒì„±"""
        level_emoji = {
            PerformanceLevel.WARNING: "âš ï¸",
            PerformanceLevel.CRITICAL: "ğŸš¨"
        }
        
        metric_names = {
            MetricType.CPU_USAGE: "CPU ì‚¬ìš©ë¥ ",
            MetricType.MEMORY_USAGE: "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ",
            MetricType.PROCESS_COUNT: "í”„ë¡œì„¸ìŠ¤ ìˆ˜"
        }
        
        emoji = level_emoji.get(level, "â„¹ï¸")
        metric_name = metric_names.get(metric_type, str(metric_type.value))
        
        if metric_type in [MetricType.CPU_USAGE, MetricType.MEMORY_USAGE]:
            return f"{emoji} {metric_name} {level.value.upper()}: {value:.1f}%"
        else:
            return f"{emoji} {metric_name} {level.value.upper()}: {value}"
    
    def _save_alert_to_history(self, alert_record: Dict[str, Any]):
        """ì•Œë¦¼ íˆìŠ¤í† ë¦¬ ì €ì¥"""
        try:
            history_file = os.path.join(self.script_dir, 'performance_alerts.json')
            
            # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ ë¡œë“œ
            alerts_history = []
            if os.path.exists(history_file):
                try:
with_open(history_file,_'r',_encoding = 'utf-8') as f:
                        alerts_history = json.load(f)
                except Exception:
                    alerts_history = []
            
            # ìƒˆ ì•Œë¦¼ ì¶”ê°€
            alerts_history.append(alert_record)
            
            # ìµœê·¼ 1000ê°œë§Œ ìœ ì§€
            if len(alerts_history) > 1000:
                alerts_history = alerts_history[-1000:]
            
            # íŒŒì¼ì— ì €ì¥
with_open(history_file,_'w',_encoding = 'utf-8') as f:
json.dump(alerts_history,_f,_ensure_ascii = False, indent=2)
            
        except Exception as e:
            self.logger.error(f"ì•Œë¦¼ íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _check_optimization_opportunities(self):
        """ìµœì í™” ê¸°íšŒ ì²´í¬"""
        try:
            recommendations = []
            
            if len(self.metrics_history) < 10:
                return recommendations
            
            # ìµœê·¼ 10ë¶„ê°„ í‰ê·  ê³„ì‚°
            recent_snapshots = list(self.metrics_history)[-10:]
            avg_cpu = statistics.mean([s.cpu_percent for s in recent_snapshots])
            avg_memory = statistics.mean([s.memory_percent for s in recent_snapshots])
            
            # CPU ìµœì í™” ê¶Œì¥ì‚¬í•­
            if avg_cpu > 60:
                recommendations.append("CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•˜ê±°ë‚˜ ëª¨ë‹ˆí„°ë§ ê°„ê²©ì„ ëŠ˜ë ¤ë³´ì„¸ìš”.")
            
            # ë©”ëª¨ë¦¬ ìµœì í™” ê¶Œì¥ì‚¬í•­
            if avg_memory > 70:
                recommendations.append("ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ë¡œê·¸ íŒŒì¼ ì •ë¦¬ë‚˜ ìºì‹œ í¬ê¸° ì¡°ì •ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")
            
            # í”„ë¡œì„¸ìŠ¤ ìˆ˜ ìµœì í™”
            avg_process_count = statistics.mean([s.process_count for s in recent_snapshots])
            if avg_process_count > 15:
                recommendations.append("ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ê°€ ë§ìŠµë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ ëª¨ë‹ˆí„°ë§ í”„ë¡œì„¸ìŠ¤ë¥¼ ë¹„í™œì„±í™”í•´ë³´ì„¸ìš”.")
            
            # ê¶Œì¥ì‚¬í•­ì´ ìˆìœ¼ë©´ ë¡œê·¸ì— ê¸°ë¡
            if recommendations:
                self.logger.info("ğŸ”§ ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­:")
                for i, rec in enumerate(recommendations, 1):
                    self.logger.info(f"  {i}. {rec}")
            
            return recommendations
            
        except Exception as e:
            self.logger.error(f"ìµœì í™” ê¸°íšŒ ì²´í¬ ì‹¤íŒ¨: {e}")
            return []
    
    def measure_operation_time(self, operation_name: str):
        """
        ì‘ì—… ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €
        
        Usage:
            with performance_monitor.measure_operation_time("process_start"):
                # ì‹œê°„ì„ ì¸¡ì •í•  ì‘ì—…
                pass
        """
        return OperationTimer(self, operation_name)
    
    def record_response_time(self, operation_name: str, response_time: float):
        """
        ì‘ë‹µ ì‹œê°„ ê¸°ë¡
        
        Args:
            operation_name (str): ì‘ì—… ì´ë¦„
            response_time (float): ì‘ë‹µ ì‹œê°„ (ì´ˆ)
        """
        try:
            self.response_times[operation_name].append(response_time)
            
            # ì‘ë‹µ ì‹œê°„ ì„ê³„ê°’ ì²´í¬
            if response_time > self.thresholds['response_time_critical']:
                self._trigger_performance_alert(
                    MetricType.RESPONSE_TIME, 
                    response_time, 
                    PerformanceLevel.CRITICAL
                )
            elif response_time > self.thresholds['response_time_warning']:
                self._trigger_performance_alert(
                    MetricType.RESPONSE_TIME, 
                    response_time, 
                    PerformanceLevel.WARNING
                )
            
self.logger.debug(f"ì‘ë‹µ_ì‹œê°„_ê¸°ë¡:_{operation_name} =  {response_time:.2f}ì´ˆ")
            
        except Exception as e:
            self.logger.error(f"ì‘ë‹µ ì‹œê°„ ê¸°ë¡ ì‹¤íŒ¨: {e}")
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ìš”ì•½ ì •ë³´ ì¡°íšŒ"""
        try:
            if not self.metrics_history:
                return {'error': 'ì„±ëŠ¥ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
            
            # ìµœê·¼ ë°ì´í„° ê¸°ë°˜ ìš”ì•½
            recent_snapshots = list(self.metrics_history)[-10:] if len(self.metrics_history) >= 10 else list(self.metrics_history)
            latest_snapshot = self.metrics_history[-1]
            
            # í‰ê·  ê³„ì‚°
            avg_cpu = statistics.mean([s.cpu_percent for s in recent_snapshots])
            avg_memory = statistics.mean([s.memory_percent for s in recent_snapshots])
            avg_process_count = statistics.mean([s.process_count for s in recent_snapshots])
            
            # ì‘ë‹µ ì‹œê°„ í†µê³„
            response_time_stats = {}
            for operation, times in self.response_times.items():
                if times:
                    response_time_stats[operation] = {
                        'avg': statistics.mean(times),
                        'min': min(times),
                        'max': max(times),
                        'count': len(times)
                    }
            
            # ê°€ë™ ì‹œê°„ ê³„ì‚°
            uptime = datetime.now() - self.start_time
            
            summary = {
                'timestamp': datetime.now().isoformat(),
                'uptime_seconds': uptime.total_seconds(),
                'uptime_formatted': str(uptime).split('.')[0],  # ì†Œìˆ˜ì  ì œê±°
                'monitoring_status': 'active' if self.is_monitoring else 'inactive',
                'total_measurements': self.total_measurements,
                'alert_count': self.alert_count,
                
                # í˜„ì¬ ìƒíƒœ
                'current': {
                    'cpu_percent': latest_snapshot.cpu_percent,
                    'memory_percent': latest_snapshot.memory_percent,
                    'memory_available_mb': latest_snapshot.memory_available_mb,
                    'disk_usage_percent': latest_snapshot.disk_usage_percent,
                    'process_count': latest_snapshot.process_count,
                    'active_processes': latest_snapshot.active_processes
                },
                
                # í‰ê·  (ìµœê·¼ 10ë¶„)
                'averages': {
                    'cpu_percent': round(avg_cpu, 2),
                    'memory_percent': round(avg_memory, 2),
                    'process_count': round(avg_process_count, 1)
                },
                
                # ì‘ë‹µ ì‹œê°„ í†µê³„
                'response_times': response_time_stats,
                
                # ì„±ëŠ¥ ìˆ˜ì¤€ í‰ê°€
                'performance_level': self._evaluate_performance_level(avg_cpu, avg_memory),
                
                # ì‹œìŠ¤í…œ ë¡œë“œ (ê°€ëŠ¥í•œ ê²½ìš°)
                'system_load': latest_snapshot.system_load_avg,
                
                # ë„¤íŠ¸ì›Œí¬ I/O (ê°€ëŠ¥í•œ ê²½ìš°)
                'network_io': latest_snapshot.network_io
            }
            
            return summary
            
        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {'error': f'ì„±ëŠ¥ ìš”ì•½ ì¡°íšŒ ì‹¤íŒ¨: {e}'}
    
    def _evaluate_performance_level(self, avg_cpu: float, avg_memory: float) -> str:
        """ì„±ëŠ¥ ìˆ˜ì¤€ í‰ê°€"""
        if avg_cpu > 80 or avg_memory > 85:
            return PerformanceLevel.CRITICAL.value
        elif avg_cpu > 60 or avg_memory > 70:
            return PerformanceLevel.WARNING.value
        elif avg_cpu > 40 or avg_memory > 50:
            return PerformanceLevel.GOOD.value
        else:
            return PerformanceLevel.EXCELLENT.value
    
    def compare_with_baseline(self, baseline_data: Dict[str, Any]) -> PerformanceComparison:
        """
        ê¸°ì¤€ì„ ê³¼ ì„±ëŠ¥ ë¹„êµ
        
        Args:
            baseline_data (Dict): v1 ì‹œìŠ¤í…œì˜ ê¸°ì¤€ì„  ë°ì´í„°
            
        Returns:
            PerformanceComparison: ë¹„êµ ê²°ê³¼
        """
        try:
            current_summary = self.get_performance_summary()
            
            if 'error' in current_summary:
                raise ValueError(current_summary['error'])
            
            # v2 ë©”íŠ¸ë¦­ ì¶”ì¶œ
            v2_metrics = {
                'cpu_percent': current_summary['averages']['cpu_percent'],
                'memory_percent': current_summary['averages']['memory_percent'],
                'process_count': current_summary['averages']['process_count'],
                'response_time_avg': 0.0  # ê¸°ë³¸ê°’
            }
            
            # í‰ê·  ì‘ë‹µ ì‹œê°„ ê³„ì‚°
            if current_summary['response_times']:
                response_times = [stats['avg'] for stats in current_summary['response_times'].values()]
                v2_metrics['response_time_avg'] = statistics.mean(response_times)
            
            # v1 ë©”íŠ¸ë¦­ (ê¸°ì¤€ì„ )
            v1_metrics = baseline_data
            
            # ê°œì„ ìœ¨ ê³„ì‚°
            improvement_percentage = {}
            recommendations = []
            
            for metric, v2_value in v2_metrics.items():
                if metric in v1_metrics:
                    v1_value = v1_metrics[metric]
                    if v1_value > 0:
                        # ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ ë©”íŠ¸ë¦­ë“¤ (CPU, ë©”ëª¨ë¦¬, ì‘ë‹µì‹œê°„)
                        if metric in ['cpu_percent', 'memory_percent', 'response_time_avg']:
                            improvement = ((v1_value - v2_value) / v1_value) * 100
                        else:  # ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ë©”íŠ¸ë¦­ë“¤
                            improvement = ((v2_value - v1_value) / v1_value) * 100
                        
                        improvement_percentage[metric] = round(improvement, 2)
                        
                        # ê¶Œì¥ì‚¬í•­ ìƒì„±
                        if improvement < -10:  # 10% ì´ìƒ ì•…í™”
                            recommendations.append(f"{metric} ì„±ëŠ¥ì´ {abs(improvement):.1f}% ì•…í™”ë˜ì—ˆìŠµë‹ˆë‹¤. ìµœì í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                        elif improvement > 10:  # 10% ì´ìƒ ê°œì„ 
                            recommendations.append(f"{metric} ì„±ëŠ¥ì´ {improvement:.1f}% ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ì „ë°˜ì ì¸ ê¶Œì¥ì‚¬í•­
            if not recommendations:
                recommendations.append("ì „ë°˜ì ì¸ ì„±ëŠ¥ì´ ì•ˆì •ì ì…ë‹ˆë‹¤.")
            
            return PerformanceComparison(
                comparison_time=datetime.now(),
                v1_metrics=v1_metrics,
                v2_metrics=v2_metrics,
                improvement_percentage=improvement_percentage,
                recommendations=recommendations
            )
            
        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ ë¹„êµ ì‹¤íŒ¨: {e}")
            return PerformanceComparison(
                comparison_time=datetime.now(),
                v1_metrics={},
                v2_metrics={},
                improvement_percentage={},
                recommendations=[f"ì„±ëŠ¥ ë¹„êµ ì‹¤íŒ¨: {e}"]
            )
    
    def set_v1_baseline(self, baseline_data: Dict[str, Any]):
        """v1 ì‹œìŠ¤í…œ ê¸°ì¤€ì„  ì„¤ì •"""
        self.v1_baseline = baseline_data
        self.logger.info("v1 ì‹œìŠ¤í…œ ê¸°ì¤€ì„  ì„¤ì • ì™„ë£Œ")
    
    def get_v1_v2_comparison(self) -> Optional[PerformanceComparison]:
        """v1ê³¼ v2 ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¹„êµ"""
        if not self.v1_baseline:
            self.logger.warning("v1 ê¸°ì¤€ì„ ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return None
        
        return self.compare_with_baseline(self.v1_baseline)
    
    def export_performance_data(self, filepath: str = None) -> str:
        """ì„±ëŠ¥ ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
        try:
            if not filepath:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filepath = os.path.join(self.script_dir, f'performance_alerts.json')
            
            # ë‚´ë³´ë‚¼ ë°ì´í„° ì¤€ë¹„
            export_data = {
                'export_timestamp': datetime.now().isoformat(),
                'monitoring_period': {
                    'start': self.start_time.isoformat(),
                    'end': datetime.now().isoformat(),
                    'duration_seconds': (datetime.now() - self.start_time).total_seconds()
                },
                'summary': self.get_performance_summary(),
                'metrics_history': [asdict(snapshot) for snapshot in list(self.metrics_history)],
                'alert_count': self.alert_count,
                'total_measurements': self.total_measurements,
                'thresholds': self.thresholds
            }
            
            # JSON ì§ë ¬í™”ë¥¼ ìœ„í•œ datetime ë³€í™˜
            def json_serializer(obj):
                if isinstance(obj, datetime):
                    return obj.isoformat()
                raise TypeError(f"Object of type {type(obj)} is not JSON serializable")
            
            # íŒŒì¼ì— ì €ì¥
with_open(filepath,_'w',_encoding = 'utf-8') as f:
json.dump(export_data,_f,_ensure_ascii = False, indent=2, default=json_serializer)
            
            self.logger.info(f"ì„±ëŠ¥ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
            return ""
    
    def get_notification_stats(self) -> Dict[str, Any]:
        """ì•Œë¦¼ í†µê³„ ì¡°íšŒ (NotificationManager í˜¸í™˜ì„±)"""
        return {
            'total_notifications': self.alert_count,
            'failed_notifications': 0,  # ì„±ëŠ¥ ëª¨ë‹ˆí„°ëŠ” ì‹¤íŒ¨ ì¶”ì  ì•ˆí•¨
            'last_notification': datetime.now() if self.alert_count > 0 else None
        }


class OperationTimer:
    """ì‘ì—… ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    
    def __init__(self, performance_monitor: PerformanceMonitor, operation_name: str):
        self.performance_monitor = performance_monitor
        self.operation_name = operation_name
        self.start_time = None
    
    def __enter__(self):
        self.start_time = time.time()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.start_time:
            response_time = time.time() - self.start_time
            self.performance_monitor.record_response_time(self.operation_name, response_time)


class PerformanceComparator:
    """
    v1ê³¼ v2 ì‹œìŠ¤í…œ ê°„ ì„±ëŠ¥ ë¹„êµ ë„êµ¬
    
    ë‘ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ë¹„êµí•˜ê³  ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, script_dir: str):
        self.script_dir = script_dir
        self.logger = logging.getLogger(__name__)
        
        # ë¹„êµ ê²°ê³¼ ì €ì¥ì†Œ
        self.comparison_history = []
        
        self.logger.info("ğŸ“Š PerformanceComparator ì´ˆê¸°í™” ì™„ë£Œ")
    
    def collect_v1_baseline(self) -> Dict[str, Any]:
        """
        v1 ì‹œìŠ¤í…œì˜ ê¸°ì¤€ì„  ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
        
        Returns:
            Dict: v1 ì‹œìŠ¤í…œ ì„±ëŠ¥ ê¸°ì¤€ì„ 
        """
        try:
            self.logger.info("ğŸ“Š v1 ì‹œìŠ¤í…œ ê¸°ì¤€ì„  ìˆ˜ì§‘ ì‹œì‘...")
            
            # v1 ì‹œìŠ¤í…œ í”„ë¡œì„¸ìŠ¤ ì‹ë³„ ë° ì„±ëŠ¥ ì¸¡ì •
            v1_processes = []
            total_cpu = 0.0
            total_memory = 0.0
            
            # ê¸°ì¡´ ì›Œì¹˜í–„ìŠ¤í„° í”„ë¡œì„¸ìŠ¤ ì°¾ê¸°
            for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'cpu_percent', 'memory_percent']):
                try:
                    if not proc.info['cmdline']:
                        continue
                    
                    cmdline_str = ' '.join(proc.info['cmdline']).lower()
                    
                    # v1 ì‹œìŠ¤í…œ í”„ë¡œì„¸ìŠ¤ ì‹ë³„ (v2 ì œì™¸)
                    if ('monitor_watchhamster' in cmdline_str or 
                        'posco_main_notifier' in cmdline_str or
                        'realtime_news_monitor' in cmdline_str) and 'v2' not in cmdline_str:
                        
                        cpu_percent = proc.info['cpu_percent'] or 0.0
                        memory_percent = proc.info['memory_percent'] or 0.0
                        
                        v1_processes.append({
                            'name': proc.info['name'],
                            'pid': proc.info['pid'],
                            'cpu_percent': cpu_percent,
                            'memory_percent': memory_percent
                        })
                        
total_cpu_+ =  cpu_percent
total_memory_+ =  memory_percent
                        
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue
            
            # ì‹œìŠ¤í…œ ì „ì²´ ì„±ëŠ¥ ì¸¡ì •
            system_cpu = psutil.cpu_percent(interval=1)
            system_memory = psutil.virtual_memory().percent
            
            baseline = {
                'timestamp': datetime.now().isoformat(),
                'system_type': 'v1',
                'cpu_percent': total_cpu,
                'memory_percent': total_memory,
                'system_cpu_percent': system_cpu,
                'system_memory_percent': system_memory,
                'process_count': len(v1_processes),
                'processes': v1_processes,
                'response_time_avg': 3.0  # v1 ì‹œìŠ¤í…œ ì˜ˆìƒ ì‘ë‹µì‹œê°„
            }
            
            self.logger.info(f"v1 ê¸°ì¤€ì„  ìˆ˜ì§‘ ì™„ë£Œ: CPU {total_cpu:.1f}%, ë©”ëª¨ë¦¬ {total_memory:.1f}%, í”„ë¡œì„¸ìŠ¤ {len(v1_processes)}ê°œ")
            
            return baseline
            
        except Exception as e:
            self.logger.error(f"v1 ê¸°ì¤€ì„  ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def generate_comparison_report(self, v1_data: Dict[str, Any], v2_data: Dict[str, Any]) -> str:
        """
        v1/v2 ì„±ëŠ¥ ë¹„êµ ë³´ê³ ì„œ ìƒì„±
        
        Args:
            v1_data (Dict): v1 ì‹œìŠ¤í…œ ë°ì´í„°
            v2_data (Dict): v2 ì‹œìŠ¤í…œ ë°ì´í„°
            
        Returns:
            str: ë¹„êµ ë³´ê³ ì„œ í…ìŠ¤íŠ¸
        """
        try:
            report_lines = []
            report_lines.append("=" * 60)
            report_lines.append("ğŸ” POSCO WatchHamster v3.0.0 ì„±ëŠ¥ ë¹„êµ ë³´ê³ ì„œ")
            report_lines.append("=" * 60)
            report_lines.append(f"ğŸ“… ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            report_lines.append("")
            
            # ì‹œìŠ¤í…œ ì •ë³´
            report_lines.append("ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´")
            report_lines.append("-" * 30)
            report_lines.append(f"v1 ì‹œìŠ¤í…œ - í”„ë¡œì„¸ìŠ¤ ìˆ˜: {v1_data.get('process_count', 0)}ê°œ")
            report_lines.append(f"v2 ì‹œìŠ¤í…œ - í”„ë¡œì„¸ìŠ¤ ìˆ˜: {v2_data.get('process_count', 0)}ê°œ")
            report_lines.append("")
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¹„êµ
            report_lines.append("âš¡ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¹„êµ")
            report_lines.append("-" * 30)
            
            metrics = [
                ('CPU ì‚¬ìš©ë¥ ', 'cpu_percent', '%'),
                ('ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ', 'memory_percent', '%'),
                ('í‰ê·  ì‘ë‹µì‹œê°„', 'response_time_avg', 'ì´ˆ')
            ]
            
            for metric_name, metric_key, unit in metrics:
                v1_value = v1_data.get(metric_key, 0)
                v2_value = v2_data.get(metric_key, 0)
                
                if v1_value > 0:
                    improvement = ((v1_value - v2_value) / v1_value) * 100
                    improvement_text = f"({improvement:+.1f}%)"
                    
                    if improvement > 5:
                        status = "âœ… ê°œì„ "
                    elif improvement < -5:
                        status = "âš ï¸ ì•…í™”"
                    else:
                        status = "â– ìœ ì‚¬"
                else:
                    improvement_text = ""
                    status = "â– ë¹„êµë¶ˆê°€"
                
                report_lines.append(f"{metric_name:12}: v1 {v1_value:.1f}{unit} â†’ v2 {v2_value:.1f}{unit} {improvement_text} {status}")
            
            report_lines.append("")
            
            # ê¶Œì¥ì‚¬í•­
            report_lines.append("ğŸ’¡ ê¶Œì¥ì‚¬í•­")
            report_lines.append("-" * 30)
            
            recommendations = []
            
            # CPU ì‚¬ìš©ë¥  ë¶„ì„
            cpu_improvement = ((v1_data.get('cpu_percent', 0) - v2_data.get('cpu_percent', 0)) / max(v1_data.get('cpu_percent', 1), 1)) * 100
            if cpu_improvement > 10:
                recommendations.append("âœ… v2 ì‹œìŠ¤í…œì˜ CPU íš¨ìœ¨ì„±ì´ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.")
            elif cpu_improvement < -10:
                recommendations.append("âš ï¸ v2 ì‹œìŠ¤í…œì˜ CPU ì‚¬ìš©ë¥ ì´ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ìµœì í™”ë¥¼ ê²€í† í•´ë³´ì„¸ìš”.")
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ë¶„ì„
            memory_improvement = ((v1_data.get('memory_percent', 0) - v2_data.get('memory_percent', 0)) / max(v1_data.get('memory_percent', 1), 1)) * 100
            if memory_improvement > 10:
                recommendations.append("âœ… v2 ì‹œìŠ¤í…œì˜ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì´ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤.")
            elif memory_improvement < -10:
                recommendations.append("âš ï¸ v2 ì‹œìŠ¤í…œì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.")
            
            # ì‘ë‹µì‹œê°„ ë¶„ì„
            response_improvement = ((v1_data.get('response_time_avg', 0) - v2_data.get('response_time_avg', 0)) / max(v1_data.get('response_time_avg', 1), 1)) * 100
            if response_improvement > 20:
                recommendations.append("âœ… v2 ì‹œìŠ¤í…œì˜ ì‘ë‹µì†ë„ê°€ í¬ê²Œ í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.")
            elif response_improvement < -20:
                recommendations.append("âš ï¸ v2 ì‹œìŠ¤í…œì˜ ì‘ë‹µì†ë„ê°€ ì €í•˜ë˜ì—ˆìŠµë‹ˆë‹¤. ì„±ëŠ¥ íŠœë‹ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
            if not recommendations:
                recommendations.append("ğŸ“Š ì „ë°˜ì ì¸ ì„±ëŠ¥ì´ ì•ˆì •ì ìœ¼ë¡œ ìœ ì§€ë˜ê³  ìˆìŠµë‹ˆë‹¤.")
            
            for rec in recommendations:
                report_lines.append(f"â€¢ {rec}")
            
            report_lines.append("")
            report_lines.append("=" * 60)
            
            return "/n".join(report_lines)
            
        except Exception as e:
            self.logger.error(f"ë¹„êµ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ë¹„êµ ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}"
    
    def save_comparison_report(self, report_text: str, filename: str = None) -> str:
        """ë¹„êµ ë³´ê³ ì„œ íŒŒì¼ ì €ì¥"""
        try:
            if not filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"test_performance_monitoring.py"
            
            filepath = os.path.join(self.script_dir, filename)
            
with_open(filepath,_'w',_encoding = 'utf-8') as f:
                f.write(report_text)
            
            self.logger.info(f"ë¹„êµ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {filepath}")
            return filepath
            
        except Exception as e:
            self.logger.error(f"ë¹„êµ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return ""