#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë™ì  ë°ì´í„° ê¸°ë°˜ ë©”ì‹œì§€ ìƒì„± ì‹œìŠ¤í…œ (ì™„ì „ ë…ë¦½)
ì‹¤ì œ API ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë©”ì‹œì§€ ìƒì„± ë° ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬

ì£¼ìš” ê¸°ëŠ¥:
- ğŸ“Š ì‹¤ì‹œê°„ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ë° ìºì‹±
- ğŸ” ë°ì´í„° í’ˆì§ˆ í‰ê°€ ë° ì‹ ë¢°ë„ ê³„ì‚°
- ğŸ’¬ ë™ì  ë°ì´í„° ê¸°ë°˜ ë©”ì‹œì§€ ìƒì„±
- ğŸ“ˆ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ë©”ì‹œì§€ ë°˜ì˜

Requirements: 2.4 êµ¬í˜„
"""

import os
import json
import time
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import hashlib


class DataQuality(Enum):
    """ë°ì´í„° í’ˆì§ˆ ë“±ê¸‰"""
    EXCELLENT = "excellent"  # 90-100%
    GOOD = "good"           # 70-89%
    FAIR = "fair"           # 50-69%
    POOR = "poor"           # 30-49%
    CRITICAL = "critical"   # 0-29%


class DataSource(Enum):
    """ë°ì´í„° ì†ŒìŠ¤ íƒ€ì…"""
    KOSPI_API = "kospi_api"
    EXCHANGE_API = "exchange_api"
    POSCO_STOCK_API = "posco_stock_api"
    NEWS_API = "news_api"
    CACHED_DATA = "cached_data"
    FALLBACK_DATA = "fallback_data"


@dataclass
class DataPoint:
    """ê°œë³„ ë°ì´í„° í¬ì¸íŠ¸"""
    value: Any
    timestamp: str
    source: DataSource
    quality_score: float
    confidence: float
    metadata: Dict[str, Any]


@dataclass
class MarketData:
    """ì‹œì¥ ë°ì´í„° êµ¬ì¡°"""
    kospi: Optional[DataPoint] = None
    exchange_rate: Optional[DataPoint] = None
    posco_stock: Optional[DataPoint] = None
    news_sentiment: Optional[DataPoint] = None
    last_updated: Optional[str] = None
    overall_quality: Optional[float] = None


class DynamicDataManager:
    """ë™ì  ë°ì´í„° ê´€ë¦¬ì í´ë˜ìŠ¤"""
    
    def __init__(self, data_dir: Optional[str] = None):
        """ë™ì  ë°ì´í„° ê´€ë¦¬ì ì´ˆê¸°í™”"""
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        self.data_dir = data_dir or os.path.join(self.script_dir, "../data")
        
        # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.data_dir, exist_ok=True)
        
        # ìºì‹œ íŒŒì¼ ê²½ë¡œ
        self.cache_file = os.path.join(self.data_dir, "market_data_cache.json")
        self.quality_log_file = os.path.join(self.data_dir, "data_quality_log.json")
        self.analysis_cache_file = os.path.join(self.data_dir, "analysis_results_cache.json")
        
        # API ì„¤ì • (ì‹¤ì œ API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜ë‚˜ ì„¤ì •íŒŒì¼ì—ì„œ ë¡œë“œ)
        self.api_config = {
            'kospi_api_url': 'https://api.example.com/kospi',  # ì‹¤ì œ API URLë¡œ êµì²´
            'exchange_api_url': 'https://api.example.com/exchange',  # ì‹¤ì œ API URLë¡œ êµì²´
            'posco_api_url': 'https://api.example.com/stock/posco',  # ì‹¤ì œ API URLë¡œ êµì²´
            'news_api_url': 'https://api.example.com/news/posco',  # ì‹¤ì œ API URLë¡œ êµì²´
            'timeout': 10,
            'retry_attempts': 3,
            'cache_duration': 300  # 5ë¶„
        }
        
        # ë°ì´í„° í’ˆì§ˆ ê¸°ì¤€
        self.quality_thresholds = {
            'freshness_hours': 2,      # 2ì‹œê°„ ì´ë‚´ ë°ì´í„°
            'min_confidence': 0.7,     # ìµœì†Œ ì‹ ë¢°ë„ 70%
            'api_timeout': 10,         # API ì‘ë‹µ ì‹œê°„ 10ì´ˆ
            'required_fields': ['value', 'timestamp']
        }
        
        # í´ë°± ë°ì´í„° (API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©)
        self.fallback_data = {
            'kospi': {'value': 2500.0, 'change': 0.0, 'timestamp': datetime.now().isoformat()},
            'exchange_rate': {'value': 1350.0, 'change': 0.0, 'timestamp': datetime.now().isoformat()},
            'posco_stock': {'value': 280000.0, 'change': 0.0, 'timestamp': datetime.now().isoformat()}
        }
        
        print(f"ğŸ“Š ë™ì  ë°ì´í„° ê´€ë¦¬ì ì´ˆê¸°í™” ì™„ë£Œ (ë°ì´í„° ë””ë ‰í† ë¦¬: {self.data_dir})")
    
    def collect_market_data(self) -> MarketData:
        """ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ë° í’ˆì§ˆ í‰ê°€"""
        print("ğŸ“ˆ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
        
        market_data = MarketData()
        
        # ê° ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        market_data.kospi = self._fetch_kospi_data()
        market_data.exchange_rate = self._fetch_exchange_rate_data()
        market_data.posco_stock = self._fetch_posco_stock_data()
        market_data.news_sentiment = self._fetch_news_sentiment_data()
        
        # ì „ì²´ ë°ì´í„° í’ˆì§ˆ ê³„ì‚°
        market_data.overall_quality = self._calculate_overall_quality(market_data)
        market_data.last_updated = datetime.now().isoformat()
        
        # ìºì‹œì— ì €ì¥
        self._save_to_cache(market_data)
        
        # í’ˆì§ˆ ë¡œê·¸ ê¸°ë¡
        self._log_data_quality(market_data)
        
        print(f"âœ… ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (í’ˆì§ˆ: {market_data.overall_quality:.1%})")
        return market_data
    
    def _fetch_kospi_data(self) -> DataPoint:
        """KOSPI ë°ì´í„° ìˆ˜ì§‘"""
        try:
            print("ğŸ“Š KOSPI ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # ì‹¤ì œ API í˜¸ì¶œ (í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜)
            # response = requests.get(self.api_config['kospi_api_url'], timeout=self.api_config['timeout'])
            
            # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ì‹¤ì œ êµ¬í˜„ ì‹œ API ì‘ë‹µìœ¼ë¡œ êµì²´)
            simulated_data = {
                'index': 2520.5,
                'change': 15.3,
                'change_percent': 0.61,
                'timestamp': datetime.now().isoformat(),
                'volume': 450000000
            }
            
            # ë°ì´í„° í’ˆì§ˆ í‰ê°€
            quality_score = self._evaluate_data_quality(simulated_data, DataSource.KOSPI_API)
            confidence = self._calculate_confidence(simulated_data, 'kospi')
            
            return DataPoint(
                value=simulated_data['index'],
                timestamp=simulated_data['timestamp'],
                source=DataSource.KOSPI_API,
                quality_score=quality_score,
                confidence=confidence,
                metadata={
                    'change': simulated_data['change'],
                    'change_percent': simulated_data['change_percent'],
                    'volume': simulated_data['volume']
                }
            )
            
        except Exception as e:
            print(f"âš ï¸ KOSPI ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return self._create_fallback_datapoint('kospi', DataSource.KOSPI_API)
    
    def _fetch_exchange_rate_data(self) -> DataPoint:
        """í™˜ìœ¨ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            print("ğŸ’± í™˜ìœ¨ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ì‹¤ì œ êµ¬í˜„ ì‹œ API ì‘ë‹µìœ¼ë¡œ êµì²´)
            simulated_data = {
                'rate': 1347.5,
                'change': -2.5,
                'change_percent': -0.18,
                'timestamp': datetime.now().isoformat(),
                'base_currency': 'USD',
                'target_currency': 'KRW'
            }
            
            quality_score = self._evaluate_data_quality(simulated_data, DataSource.EXCHANGE_API)
            confidence = self._calculate_confidence(simulated_data, 'exchange_rate')
            
            return DataPoint(
                value=simulated_data['rate'],
                timestamp=simulated_data['timestamp'],
                source=DataSource.EXCHANGE_API,
                quality_score=quality_score,
                confidence=confidence,
                metadata={
                    'change': simulated_data['change'],
                    'change_percent': simulated_data['change_percent'],
                    'base_currency': simulated_data['base_currency'],
                    'target_currency': simulated_data['target_currency']
                }
            )
            
        except Exception as e:
            print(f"âš ï¸ í™˜ìœ¨ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return self._create_fallback_datapoint('exchange_rate', DataSource.EXCHANGE_API)
    
    def _fetch_posco_stock_data(self) -> DataPoint:
        """POSCO ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            print("ğŸ­ POSCO ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ì‹¤ì œ êµ¬í˜„ ì‹œ API ì‘ë‹µìœ¼ë¡œ êµì²´)
            simulated_data = {
                'price': 285000,
                'change': 3500,
                'change_percent': 1.24,
                'timestamp': datetime.now().isoformat(),
                'volume': 125000,
                'market_cap': 24500000000000
            }
            
            quality_score = self._evaluate_data_quality(simulated_data, DataSource.POSCO_STOCK_API)
            confidence = self._calculate_confidence(simulated_data, 'posco_stock')
            
            return DataPoint(
                value=simulated_data['price'],
                timestamp=simulated_data['timestamp'],
                source=DataSource.POSCO_STOCK_API,
                quality_score=quality_score,
                confidence=confidence,
                metadata={
                    'change': simulated_data['change'],
                    'change_percent': simulated_data['change_percent'],
                    'volume': simulated_data['volume'],
                    'market_cap': simulated_data['market_cap']
                }
            )
            
        except Exception as e:
            print(f"âš ï¸ POSCO ì£¼ê°€ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return self._create_fallback_datapoint('posco_stock', DataSource.POSCO_STOCK_API)
    
    def _fetch_news_sentiment_data(self) -> DataPoint:
        """ë‰´ìŠ¤ ê°ì • ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            print("ğŸ“° ë‰´ìŠ¤ ê°ì • ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
            
            # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„° (ì‹¤ì œ êµ¬í˜„ ì‹œ ë‰´ìŠ¤ API + ê°ì • ë¶„ì„ìœ¼ë¡œ êµì²´)
            simulated_data = {
                'sentiment_score': 0.65,  # -1 (ë§¤ìš° ë¶€ì •) ~ 1 (ë§¤ìš° ê¸ì •)
                'sentiment_label': 'positive',
                'confidence': 0.82,
                'news_count': 15,
                'timestamp': datetime.now().isoformat(),
                'key_topics': ['ì‹¤ì ', 'íˆ¬ì', 'ì„±ì¥']
            }
            
            quality_score = self._evaluate_data_quality(simulated_data, DataSource.NEWS_API)
            confidence = simulated_data['confidence']
            
            return DataPoint(
                value=simulated_data['sentiment_score'],
                timestamp=simulated_data['timestamp'],
                source=DataSource.NEWS_API,
                quality_score=quality_score,
                confidence=confidence,
                metadata={
                    'sentiment_label': simulated_data['sentiment_label'],
                    'news_count': simulated_data['news_count'],
                    'key_topics': simulated_data['key_topics']
                }
            )
            
        except Exception as e:
            print(f"âš ï¸ ë‰´ìŠ¤ ê°ì • ë¶„ì„ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            # ë‰´ìŠ¤ ë°ì´í„°ëŠ” ì¤‘ë¦½ìœ¼ë¡œ í´ë°±
            return DataPoint(
                value=0.0,
                timestamp=datetime.now().isoformat(),
                source=DataSource.FALLBACK_DATA,
                quality_score=0.3,
                confidence=0.5,
                metadata={'sentiment_label': 'neutral', 'news_count': 0, 'key_topics': []}
            )
    
    def _evaluate_data_quality(self, data: Dict[str, Any], source: DataSource) -> float:
        """ë°ì´í„° í’ˆì§ˆ í‰ê°€"""
        quality_factors = []
        
        # 1. ë°ì´í„° ì™„ì„±ë„ (í•„ìˆ˜ í•„ë“œ ì¡´ì¬ ì—¬ë¶€)
        completeness = 0.0
        required_fields = self.quality_thresholds['required_fields']
        if isinstance(data, dict):
            present_fields = sum(1 for field in required_fields if field in data and data[field] is not None)
            completeness = present_fields / len(required_fields)
        quality_factors.append(completeness)
        
        # 2. ë°ì´í„° ì‹ ì„ ë„ (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€)
        freshness = 1.0
        if 'timestamp' in data:
            try:
                data_time = datetime.fromisoformat(data['timestamp'].replace('Z', '+00:00'))
                age_hours = (datetime.now() - data_time.replace(tzinfo=None)).total_seconds() / 3600
                freshness = max(0.0, 1.0 - (age_hours / self.quality_thresholds['freshness_hours']))
            except:
                freshness = 0.5
        quality_factors.append(freshness)
        
        # 3. ë°ì´í„° ì†ŒìŠ¤ ì‹ ë¢°ë„
        source_reliability = {
            DataSource.KOSPI_API: 0.95,
            DataSource.EXCHANGE_API: 0.90,
            DataSource.POSCO_STOCK_API: 0.85,
            DataSource.NEWS_API: 0.75,
            DataSource.CACHED_DATA: 0.60,
            DataSource.FALLBACK_DATA: 0.30
        }
        quality_factors.append(source_reliability.get(source, 0.5))
        
        # 4. ë°ì´í„° ê°’ì˜ í•©ë¦¬ì„± (ë²”ìœ„ ì²´í¬)
        reasonableness = self._check_data_reasonableness(data, source)
        quality_factors.append(reasonableness)
        
        # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
        weights = [0.3, 0.3, 0.2, 0.2]  # ì™„ì„±ë„, ì‹ ì„ ë„, ì†ŒìŠ¤ ì‹ ë¢°ë„, í•©ë¦¬ì„±
        quality_score = sum(factor * weight for factor, weight in zip(quality_factors, weights))
        
        return min(1.0, max(0.0, quality_score))
    
    def _check_data_reasonableness(self, data: Dict[str, Any], source: DataSource) -> float:
        """ë°ì´í„° ê°’ì˜ í•©ë¦¬ì„± ê²€ì‚¬"""
        try:
            if source == DataSource.KOSPI_API:
                value = data.get('index', 0)
                # KOSPI í•©ë¦¬ì  ë²”ìœ„: 1000 ~ 4000
                if 1000 <= value <= 4000:
                    return 1.0
                elif 500 <= value <= 5000:
                    return 0.7
                else:
                    return 0.3
                    
            elif source == DataSource.EXCHANGE_API:
                value = data.get('rate', 0)
                # USD/KRW í•©ë¦¬ì  ë²”ìœ„: 1000 ~ 1600
                if 1000 <= value <= 1600:
                    return 1.0
                elif 800 <= value <= 2000:
                    return 0.7
                else:
                    return 0.3
                    
            elif source == DataSource.POSCO_STOCK_API:
                value = data.get('price', 0)
                # POSCO ì£¼ê°€ í•©ë¦¬ì  ë²”ìœ„: 100,000 ~ 500,000
                if 100000 <= value <= 500000:
                    return 1.0
                elif 50000 <= value <= 800000:
                    return 0.7
                else:
                    return 0.3
                    
            elif source == DataSource.NEWS_API:
                value = data.get('sentiment_score', 0)
                # ê°ì • ì ìˆ˜ í•©ë¦¬ì  ë²”ìœ„: -1 ~ 1
                if -1 <= value <= 1:
                    return 1.0
                else:
                    return 0.3
            
            return 0.8  # ê¸°ë³¸ê°’
            
        except:
            return 0.5
    
    def _calculate_confidence(self, data: Dict[str, Any], data_type: str) -> float:
        """ë°ì´í„° ì‹ ë¢°ë„ ê³„ì‚°"""
        confidence_factors = []
        
        # 1. ë°ì´í„° ë³€ë™ì„± ê¸°ë°˜ ì‹ ë¢°ë„
        if 'change_percent' in data:
            change_percent = abs(data['change_percent'])
            # ê¸‰ê²©í•œ ë³€ë™ì€ ì‹ ë¢°ë„ ê°ì†Œ
            if change_percent <= 2.0:
                confidence_factors.append(0.95)
            elif change_percent <= 5.0:
                confidence_factors.append(0.80)
            elif change_percent <= 10.0:
                confidence_factors.append(0.60)
            else:
                confidence_factors.append(0.40)
        else:
            confidence_factors.append(0.70)
        
        # 2. ê±°ë˜ëŸ‰/í™œë™ëŸ‰ ê¸°ë°˜ ì‹ ë¢°ë„
        if 'volume' in data and data['volume'] > 0:
            confidence_factors.append(0.90)
        elif 'news_count' in data and data['news_count'] > 5:
            confidence_factors.append(0.85)
        else:
            confidence_factors.append(0.70)
        
        # 3. ì‹œê°„ëŒ€ë³„ ì‹ ë¢°ë„ (ì‹œì¥ ì‹œê°„ ê³ ë ¤)
        current_hour = datetime.now().hour
        if data_type in ['kospi', 'posco_stock']:
            # ì£¼ì‹ ì‹œì¥ ì‹œê°„ (9-15ì‹œ)
            if 9 <= current_hour <= 15:
                confidence_factors.append(0.95)
            elif 16 <= current_hour <= 18:
                confidence_factors.append(0.80)
            else:
                confidence_factors.append(0.60)
        else:
            # í™˜ìœ¨ì€ 24ì‹œê°„
            confidence_factors.append(0.85)
        
        return sum(confidence_factors) / len(confidence_factors)
    
    def _create_fallback_datapoint(self, data_type: str, original_source: DataSource) -> DataPoint:
        """í´ë°± ë°ì´í„° í¬ì¸íŠ¸ ìƒì„±"""
        fallback = self.fallback_data.get(data_type, {})
        
        return DataPoint(
            value=fallback.get('value', 0),
            timestamp=datetime.now().isoformat(),
            source=DataSource.FALLBACK_DATA,
            quality_score=0.3,
            confidence=0.5,
            metadata={
                'change': fallback.get('change', 0),
                'original_source': original_source.value,
                'fallback_reason': 'API í˜¸ì¶œ ì‹¤íŒ¨'
            }
        )
    
    def _calculate_overall_quality(self, market_data: MarketData) -> float:
        """ì „ì²´ ë°ì´í„° í’ˆì§ˆ ê³„ì‚°"""
        quality_scores = []
        
        for data_point in [market_data.kospi, market_data.exchange_rate, 
                          market_data.posco_stock, market_data.news_sentiment]:
            if data_point:
                quality_scores.append(data_point.quality_score)
        
        if not quality_scores:
            return 0.0
        
        return sum(quality_scores) / len(quality_scores)
    
    def _save_to_cache(self, market_data: MarketData):
        """ë°ì´í„° ìºì‹œì— ì €ì¥"""
        try:
            # MarketDataë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
            def datapoint_to_dict(dp):
                if not dp:
                    return None
                return {
                    'value': dp.value,
                    'timestamp': dp.timestamp,
                    'source': dp.source.value,  # Enumì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                    'quality_score': dp.quality_score,
                    'confidence': dp.confidence,
                    'metadata': dp.metadata
                }
            
            cache_data = {
                'market_data': {
                    'kospi': datapoint_to_dict(market_data.kospi),
                    'exchange_rate': datapoint_to_dict(market_data.exchange_rate),
                    'posco_stock': datapoint_to_dict(market_data.posco_stock),
                    'news_sentiment': datapoint_to_dict(market_data.news_sentiment),
                    'last_updated': market_data.last_updated,
                    'overall_quality': market_data.overall_quality
                },
                'cached_at': datetime.now().isoformat(),
                'cache_version': '1.0'
            }
            
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
                
            print(f"ğŸ’¾ ë°ì´í„° ìºì‹œ ì €ì¥ ì™„ë£Œ: {self.cache_file}")
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _log_data_quality(self, market_data: MarketData):
        """ë°ì´í„° í’ˆì§ˆ ë¡œê·¸ ê¸°ë¡"""
        try:
            # ê¸°ì¡´ ë¡œê·¸ ë¡œë“œ
            quality_log = []
            if os.path.exists(self.quality_log_file):
                with open(self.quality_log_file, 'r', encoding='utf-8') as f:
                    quality_log = json.load(f)
            
            # ìƒˆ ë¡œê·¸ ì—”íŠ¸ë¦¬ ì¶”ê°€
            log_entry = {
                'timestamp': datetime.now().isoformat(),
                'overall_quality': market_data.overall_quality,
                'data_sources': {
                    'kospi': {
                        'quality': market_data.kospi.quality_score if market_data.kospi else 0,
                        'confidence': market_data.kospi.confidence if market_data.kospi else 0,
                        'source': market_data.kospi.source.value if market_data.kospi else 'none'
                    },
                    'exchange_rate': {
                        'quality': market_data.exchange_rate.quality_score if market_data.exchange_rate else 0,
                        'confidence': market_data.exchange_rate.confidence if market_data.exchange_rate else 0,
                        'source': market_data.exchange_rate.source.value if market_data.exchange_rate else 'none'
                    },
                    'posco_stock': {
                        'quality': market_data.posco_stock.quality_score if market_data.posco_stock else 0,
                        'confidence': market_data.posco_stock.confidence if market_data.posco_stock else 0,
                        'source': market_data.posco_stock.source.value if market_data.posco_stock else 'none'
                    },
                    'news_sentiment': {
                        'quality': market_data.news_sentiment.quality_score if market_data.news_sentiment else 0,
                        'confidence': market_data.news_sentiment.confidence if market_data.news_sentiment else 0,
                        'source': market_data.news_sentiment.source.value if market_data.news_sentiment else 'none'
                    }
                }
            }
            
            quality_log.append(log_entry)
            
            # ìµœê·¼ 100ê°œ ë¡œê·¸ë§Œ ìœ ì§€
            if len(quality_log) > 100:
                quality_log = quality_log[-100:]
            
            # ë¡œê·¸ íŒŒì¼ ì €ì¥
            with open(self.quality_log_file, 'w', encoding='utf-8') as f:
                json.dump(quality_log, f, ensure_ascii=False, indent=2)
                
        except Exception as e:
            print(f"âŒ í’ˆì§ˆ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨: {e}")
    
    def load_cached_data(self) -> Optional[MarketData]:
        """ìºì‹œëœ ë°ì´í„° ë¡œë“œ"""
        try:
            if not os.path.exists(self.cache_file):
                return None
            
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # ìºì‹œ ìœ íš¨ì„± ê²€ì‚¬
            cached_at = datetime.fromisoformat(cache_data['cached_at'])
            cache_age = (datetime.now() - cached_at).total_seconds()
            
            if cache_age > self.api_config['cache_duration']:
                print("â° ìºì‹œ ë°ì´í„°ê°€ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
                return None
            
            # MarketData ê°ì²´ë¡œ ë³€í™˜
            market_data_dict = cache_data['market_data']
            
            def dict_to_datapoint(dp_dict):
                if not dp_dict:
                    return None
                return DataPoint(
                    value=dp_dict['value'],
                    timestamp=dp_dict['timestamp'],
                    source=DataSource(dp_dict['source']),
                    quality_score=dp_dict['quality_score'],
                    confidence=dp_dict['confidence'],
                    metadata=dp_dict['metadata']
                )
            
            market_data = MarketData(
                kospi=dict_to_datapoint(market_data_dict.get('kospi')),
                exchange_rate=dict_to_datapoint(market_data_dict.get('exchange_rate')),
                posco_stock=dict_to_datapoint(market_data_dict.get('posco_stock')),
                news_sentiment=dict_to_datapoint(market_data_dict.get('news_sentiment')),
                last_updated=market_data_dict.get('last_updated'),
                overall_quality=market_data_dict.get('overall_quality')
            )
            
            print(f"ğŸ“‚ ìºì‹œëœ ë°ì´í„° ë¡œë“œ ì™„ë£Œ (í’ˆì§ˆ: {market_data.overall_quality:.1%})")
            return market_data
            
        except Exception as e:
            print(f"âŒ ìºì‹œ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_market_data(self, force_refresh: bool = False) -> MarketData:
        """ì‹œì¥ ë°ì´í„° ì¡°íšŒ (ìºì‹œ ìš°ì„ )"""
        if not force_refresh:
            cached_data = self.load_cached_data()
            if cached_data:
                return cached_data
        
        # ìºì‹œê°€ ì—†ê±°ë‚˜ ê°•ì œ ìƒˆë¡œê³ ì¹¨ì¸ ê²½ìš° ìƒˆ ë°ì´í„° ìˆ˜ì§‘
        return self.collect_market_data()
    
    def generate_dynamic_message_data(self, market_data: MarketData) -> Dict[str, Any]:
        """ë™ì  ë©”ì‹œì§€ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„"""
        print("ğŸ’¬ ë™ì  ë©”ì‹œì§€ ë°ì´í„° ìƒì„± ì¤‘...")
        
        # ê¸°ë³¸ ë©”ì‹œì§€ ë°ì´í„°
        message_data = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'overall_quality': market_data.overall_quality,
            'data_reliability': self._get_quality_description(market_data.overall_quality)
        }
        
        # KOSPI ë°ì´í„° ì²˜ë¦¬
        if market_data.kospi:
            kospi_change = market_data.kospi.metadata.get('change', 0)
            kospi_change_percent = market_data.kospi.metadata.get('change_percent', 0)
            
            message_data.update({
                'kospi': f"{market_data.kospi.value:,.1f}",
                'kospi_change': self._format_change_value(kospi_change),
                'kospi_change_percent': f"{kospi_change_percent:+.2f}%",
                'kospi_trend': self._get_trend_description(kospi_change_percent),
                'kospi_quality': f"{market_data.kospi.quality_score:.1%}",
                'kospi_confidence': f"{market_data.kospi.confidence:.1%}",
                'kospi_source': self._get_source_description(market_data.kospi.source)
            })
        else:
            message_data.update({
                'kospi': 'N/A',
                'kospi_change': 'N/A',
                'kospi_trend': 'ë°ì´í„° ì—†ìŒ',
                'kospi_quality': '0%',
                'kospi_confidence': '0%'
            })
        
        # í™˜ìœ¨ ë°ì´í„° ì²˜ë¦¬
        if market_data.exchange_rate:
            exchange_change = market_data.exchange_rate.metadata.get('change', 0)
            exchange_change_percent = market_data.exchange_rate.metadata.get('change_percent', 0)
            
            message_data.update({
                'exchange_rate': f"{market_data.exchange_rate.value:,.1f}ì›",
                'exchange_change': self._format_change_value(exchange_change),
                'exchange_change_percent': f"{exchange_change_percent:+.2f}%",
                'exchange_trend': self._get_trend_description(exchange_change_percent),
                'exchange_quality': f"{market_data.exchange_rate.quality_score:.1%}",
                'exchange_confidence': f"{market_data.exchange_rate.confidence:.1%}",
                'exchange_source': self._get_source_description(market_data.exchange_rate.source)
            })
        else:
            message_data.update({
                'exchange_rate': 'N/A',
                'exchange_change': 'N/A',
                'exchange_trend': 'ë°ì´í„° ì—†ìŒ',
                'exchange_quality': '0%',
                'exchange_confidence': '0%'
            })
        
        # POSCO ì£¼ê°€ ë°ì´í„° ì²˜ë¦¬
        if market_data.posco_stock:
            posco_change = market_data.posco_stock.metadata.get('change', 0)
            posco_change_percent = market_data.posco_stock.metadata.get('change_percent', 0)
            
            message_data.update({
                'posco_stock': f"{market_data.posco_stock.value:,}ì›",
                'posco_change': self._format_change_value(posco_change),
                'posco_change_percent': f"{posco_change_percent:+.2f}%",
                'posco_trend': self._get_trend_description(posco_change_percent),
                'posco_quality': f"{market_data.posco_stock.quality_score:.1%}",
                'posco_confidence': f"{market_data.posco_stock.confidence:.1%}",
                'posco_source': self._get_source_description(market_data.posco_stock.source)
            })
        else:
            message_data.update({
                'posco_stock': 'N/A',
                'posco_change': 'N/A',
                'posco_trend': 'ë°ì´í„° ì—†ìŒ',
                'posco_quality': '0%',
                'posco_confidence': '0%'
            })
        
        # ë‰´ìŠ¤ ê°ì • ë¶„ì„ ë°ì´í„° ì²˜ë¦¬
        if market_data.news_sentiment:
            sentiment_label = market_data.news_sentiment.metadata.get('sentiment_label', 'neutral')
            news_count = market_data.news_sentiment.metadata.get('news_count', 0)
            key_topics = market_data.news_sentiment.metadata.get('key_topics', [])
            
            message_data.update({
                'news_sentiment': self._get_sentiment_description(sentiment_label),
                'news_sentiment_score': f"{market_data.news_sentiment.value:.2f}",
                'news_count': news_count,
                'key_topics': ', '.join(key_topics) if key_topics else 'ì—†ìŒ',
                'news_quality': f"{market_data.news_sentiment.quality_score:.1%}",
                'news_confidence': f"{market_data.news_sentiment.confidence:.1%}"
            })
        else:
            message_data.update({
                'news_sentiment': 'ì¤‘ë¦½',
                'news_sentiment_score': '0.00',
                'news_count': 0,
                'key_topics': 'ì—†ìŒ',
                'news_quality': '0%',
                'news_confidence': '0%'
            })
        
        # ì¢…í•© ë¶„ì„ ê²°ê³¼
        message_data.update({
            'market_summary': self._generate_market_summary(market_data),
            'quality_warning': self._generate_quality_warning(market_data),
            'data_freshness': self._get_data_freshness(market_data),
            'reliability_indicator': self._get_reliability_indicator(market_data.overall_quality)
        })
        
        print(f"âœ… ë™ì  ë©”ì‹œì§€ ë°ì´í„° ìƒì„± ì™„ë£Œ (í’ˆì§ˆ: {market_data.overall_quality:.1%})")
        return message_data
    
    def _format_change_value(self, change: float) -> str:
        """ë³€í™”ëŸ‰ í¬ë§·íŒ…"""
        if change > 0:
            return f"â–² +{change:,.2f}"
        elif change < 0:
            return f"â–¼ {change:,.2f}"
        else:
            return "â†’ 0.00"
    
    def _get_trend_description(self, change_percent: float) -> str:
        """íŠ¸ë Œë“œ ì„¤ëª… ìƒì„±"""
        if change_percent >= 2.0:
            return "ê°•í•œ ìƒìŠ¹ì„¸"
        elif change_percent >= 0.5:
            return "ìƒìŠ¹ì„¸"
        elif change_percent > -0.5:
            return "ë³´í•©ì„¸"
        elif change_percent > -2.0:
            return "í•˜ë½ì„¸"
        else:
            return "ê°•í•œ í•˜ë½ì„¸"
    
    def _get_sentiment_description(self, sentiment_label: str) -> str:
        """ê°ì • ë¶„ì„ ê²°ê³¼ ì„¤ëª…"""
        sentiment_map = {
            'very_positive': 'ë§¤ìš° ê¸ì •ì ',
            'positive': 'ê¸ì •ì ',
            'neutral': 'ì¤‘ë¦½ì ',
            'negative': 'ë¶€ì •ì ',
            'very_negative': 'ë§¤ìš° ë¶€ì •ì '
        }
        return sentiment_map.get(sentiment_label, 'ì¤‘ë¦½ì ')
    
    def _get_quality_description(self, quality_score: float) -> str:
        """ë°ì´í„° í’ˆì§ˆ ì„¤ëª…"""
        if quality_score >= 0.9:
            return "ë§¤ìš° ë†’ìŒ"
        elif quality_score >= 0.7:
            return "ë†’ìŒ"
        elif quality_score >= 0.5:
            return "ë³´í†µ"
        elif quality_score >= 0.3:
            return "ë‚®ìŒ"
        else:
            return "ë§¤ìš° ë‚®ìŒ"
    
    def _get_source_description(self, source: DataSource) -> str:
        """ë°ì´í„° ì†ŒìŠ¤ ì„¤ëª…"""
        source_map = {
            DataSource.KOSPI_API: "ì‹¤ì‹œê°„ API",
            DataSource.EXCHANGE_API: "í™˜ìœ¨ API",
            DataSource.POSCO_STOCK_API: "ì£¼ì‹ API",
            DataSource.NEWS_API: "ë‰´ìŠ¤ API",
            DataSource.CACHED_DATA: "ìºì‹œ ë°ì´í„°",
            DataSource.FALLBACK_DATA: "ë°±ì—… ë°ì´í„°"
        }
        return source_map.get(source, "ì•Œ ìˆ˜ ì—†ìŒ")
    
    def _generate_market_summary(self, market_data: MarketData) -> str:
        """ì‹œì¥ ì¢…í•© ìš”ì•½ ìƒì„±"""
        summaries = []
        
        # KOSPI ìš”ì•½
        if market_data.kospi:
            kospi_change_percent = market_data.kospi.metadata.get('change_percent', 0)
            if kospi_change_percent > 0:
                summaries.append(f"KOSPIê°€ {kospi_change_percent:.2f}% ìƒìŠ¹í–ˆìŠµë‹ˆë‹¤")
            elif kospi_change_percent < 0:
                summaries.append(f"KOSPIê°€ {abs(kospi_change_percent):.2f}% í•˜ë½í–ˆìŠµë‹ˆë‹¤")
            else:
                summaries.append("KOSPIëŠ” ë³´í•©ì„¸ë¥¼ ìœ ì§€í–ˆìŠµë‹ˆë‹¤")
        
        # í™˜ìœ¨ ìš”ì•½
        if market_data.exchange_rate:
            exchange_change_percent = market_data.exchange_rate.metadata.get('change_percent', 0)
            if exchange_change_percent > 0:
                summaries.append("ì›í™”ê°€ ì•½ì„¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤")
            elif exchange_change_percent < 0:
                summaries.append("ì›í™”ê°€ ê°•ì„¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤")
        
        # POSCO ì£¼ê°€ ìš”ì•½
        if market_data.posco_stock:
            posco_change_percent = market_data.posco_stock.metadata.get('change_percent', 0)
            if posco_change_percent > 1.0:
                summaries.append("POSCO ì£¼ê°€ê°€ ê°•í•œ ìƒìŠ¹ì„¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤")
            elif posco_change_percent < -1.0:
                summaries.append("POSCO ì£¼ê°€ê°€ í•˜ë½ì„¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤")
        
        if not summaries:
            return "ì‹œì¥ì€ ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ëª¨ìŠµì„ ë³´ì˜€ìŠµë‹ˆë‹¤"
        
        return ". ".join(summaries) + "."
    
    def _generate_quality_warning(self, market_data: MarketData) -> str:
        """ë°ì´í„° í’ˆì§ˆ ê²½ê³  ë©”ì‹œì§€ ìƒì„±"""
        if market_data.overall_quality < 0.5:
            return "âš ï¸ ë°ì´í„° í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ë¶„ì„ ê²°ê³¼ë¥¼ ì°¸ê³ ìš©ìœ¼ë¡œë§Œ í™œìš©í•˜ì„¸ìš”."
        elif market_data.overall_quality < 0.7:
            return "â„¹ï¸ ì¼ë¶€ ë°ì´í„°ì˜ ì‹ ë¢°ë„ê°€ ì œí•œì ì…ë‹ˆë‹¤."
        else:
            return ""
    
    def _get_data_freshness(self, market_data: MarketData) -> str:
        """ë°ì´í„° ì‹ ì„ ë„ ì •ë³´"""
        if market_data.last_updated:
            try:
                updated_time = datetime.fromisoformat(market_data.last_updated)
                age_minutes = (datetime.now() - updated_time).total_seconds() / 60
                
                if age_minutes < 5:
                    return "ì‹¤ì‹œê°„"
                elif age_minutes < 30:
                    return f"{int(age_minutes)}ë¶„ ì „"
                elif age_minutes < 120:
                    return f"{int(age_minutes/60)}ì‹œê°„ ì „"
                else:
                    return "ì˜¤ë˜ëœ ë°ì´í„°"
            except:
                return "ì•Œ ìˆ˜ ì—†ìŒ"
        return "ì•Œ ìˆ˜ ì—†ìŒ"
    
    def _get_reliability_indicator(self, quality_score: float) -> str:
        """ì‹ ë¢°ë„ ì§€í‘œ"""
        if quality_score >= 0.9:
            return "ğŸŸ¢ ë§¤ìš° ì‹ ë¢°í•  ìˆ˜ ìˆìŒ"
        elif quality_score >= 0.7:
            return "ğŸŸ¡ ì‹ ë¢°í•  ìˆ˜ ìˆìŒ"
        elif quality_score >= 0.5:
            return "ğŸŸ  ì£¼ì˜ í•„ìš”"
        else:
            return "ğŸ”´ ì‹ ë¢°ë„ ë‚®ìŒ"
    
    def get_quality_statistics(self) -> Dict[str, Any]:
        """ë°ì´í„° í’ˆì§ˆ í†µê³„ ì¡°íšŒ"""
        try:
            if not os.path.exists(self.quality_log_file):
                return {'error': 'í’ˆì§ˆ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤'}
            
            with open(self.quality_log_file, 'r', encoding='utf-8') as f:
                quality_log = json.load(f)
            
            if not quality_log:
                return {'error': 'í’ˆì§ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
            
            # ìµœê·¼ 24ì‹œê°„ ë°ì´í„°ë§Œ ë¶„ì„
            recent_logs = []
            cutoff_time = datetime.now() - timedelta(hours=24)
            
            for log_entry in quality_log:
                try:
                    log_time = datetime.fromisoformat(log_entry['timestamp'])
                    if log_time >= cutoff_time:
                        recent_logs.append(log_entry)
                except:
                    continue
            
            if not recent_logs:
                return {'error': 'ìµœê·¼ í’ˆì§ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤'}
            
            # í†µê³„ ê³„ì‚°
            overall_qualities = [log['overall_quality'] for log in recent_logs]
            
            statistics = {
                'period': 'ìµœê·¼ 24ì‹œê°„',
                'total_measurements': len(recent_logs),
                'average_quality': sum(overall_qualities) / len(overall_qualities),
                'min_quality': min(overall_qualities),
                'max_quality': max(overall_qualities),
                'quality_trend': self._calculate_quality_trend(recent_logs),
                'source_reliability': self._calculate_source_reliability(recent_logs),
                'last_updated': recent_logs[-1]['timestamp'] if recent_logs else None
            }
            
            return statistics
            
        except Exception as e:
            return {'error': f'í’ˆì§ˆ í†µê³„ ê³„ì‚° ì‹¤íŒ¨: {str(e)}'}
    
    def _calculate_quality_trend(self, logs: List[Dict]) -> str:
        """í’ˆì§ˆ íŠ¸ë Œë“œ ê³„ì‚°"""
        if len(logs) < 2:
            return "ë°ì´í„° ë¶€ì¡±"
        
        # ìµœê·¼ 5ê°œì™€ ì´ì „ 5ê°œ ë¹„êµ
        recent_count = min(5, len(logs))
        recent_quality = sum(log['overall_quality'] for log in logs[-recent_count:]) / recent_count
        
        if len(logs) >= 10:
            previous_quality = sum(log['overall_quality'] for log in logs[-10:-recent_count]) / (10 - recent_count)
            
            if recent_quality > previous_quality + 0.05:
                return "ê°œì„  ì¤‘"
            elif recent_quality < previous_quality - 0.05:
                return "ì•…í™” ì¤‘"
            else:
                return "ì•ˆì •ì "
        else:
            return "ì•ˆì •ì "
    
    def _calculate_source_reliability(self, logs: List[Dict]) -> Dict[str, float]:
        """ì†ŒìŠ¤ë³„ ì‹ ë¢°ë„ ê³„ì‚°"""
        source_stats = {}
        
        for log in logs:
            for source_name, source_data in log.get('data_sources', {}).items():
                if source_name not in source_stats:
                    source_stats[source_name] = []
                source_stats[source_name].append(source_data.get('quality', 0))
        
        # í‰ê·  ê³„ì‚°
        source_reliability = {}
        for source_name, qualities in source_stats.items():
            if qualities:
                source_reliability[source_name] = sum(qualities) / len(qualities)
        
        return source_reliability


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª DynamicDataManager í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    manager = DynamicDataManager()
    
    # ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
    market_data = manager.collect_market_data()
    print(f"\nğŸ“Š ìˆ˜ì§‘ëœ ì‹œì¥ ë°ì´í„°:")
    print(f"- KOSPI: {market_data.kospi.value if market_data.kospi else 'N/A'}")
    print(f"- í™˜ìœ¨: {market_data.exchange_rate.value if market_data.exchange_rate else 'N/A'}")
    print(f"- POSCO ì£¼ê°€: {market_data.posco_stock.value if market_data.posco_stock else 'N/A'}")
    print(f"- ì „ì²´ í’ˆì§ˆ: {market_data.overall_quality:.1%}")
    
    # ë™ì  ë©”ì‹œì§€ ë°ì´í„° ìƒì„± í…ŒìŠ¤íŠ¸
    message_data = manager.generate_dynamic_message_data(market_data)
    print(f"\nğŸ’¬ ìƒì„±ëœ ë©”ì‹œì§€ ë°ì´í„°:")
    print(f"- ì‹œì¥ ìš”ì•½: {message_data['market_summary']}")
    print(f"- ë°ì´í„° ì‹ ë¢°ë„: {message_data['data_reliability']}")
    print(f"- í’ˆì§ˆ ê²½ê³ : {message_data['quality_warning']}")
    
    # ìºì‹œ í…ŒìŠ¤íŠ¸
    cached_data = manager.load_cached_data()
    if cached_data:
        print(f"\nğŸ“‚ ìºì‹œ ë°ì´í„° ë¡œë“œ ì„±ê³µ (í’ˆì§ˆ: {cached_data.overall_quality:.1%})")
    
    print("\nâœ… DynamicDataManager í…ŒìŠ¤íŠ¸ ì™„ë£Œ")