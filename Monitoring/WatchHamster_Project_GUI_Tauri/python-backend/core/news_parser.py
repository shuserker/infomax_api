# -*- coding: utf-8 -*-
"""
í†µí•© ë‰´ìŠ¤ ë°ì´í„° íŒŒì‹± ì‹œìŠ¤í…œ

ê¸°ì¡´ WatchHamster_Projectì˜ news_data_parser.py, exchange_rate_parser.py, 
newyork_market_parser.py, kospi_close_parser.pyë¥¼ í†µí•©í•˜ì—¬ 
3ê°€ì§€ ë‰´ìŠ¤ íƒ€ì…ë³„ íŒŒì‹± ë¡œì§ì„ ì œê³µí•˜ëŠ” í†µí•© íŒŒì„œì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- 3ê°€ì§€ ë‰´ìŠ¤ íƒ€ì…ë³„ ì „ë¬¸ íŒŒì‹± (exchange-rate, newyork-market-watch, kospi-close)
- ë‰´ìŠ¤ ìƒíƒœ íŒë‹¨ ì•Œê³ ë¦¬ì¦˜ (ìµœì‹ /ì§€ì—°/ê³¼ê±°)
- ì˜ì—…ì¼/ë¹„ì˜ì—…ì¼ íŒë‹¨ ë¡œì§
- ì‹¤ì‹œê°„ ìƒíƒœ ë¶„ì„ ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- í†µí•©ëœ ë°ì´í„° ëª¨ë¸ ë° ê²€ì¦

ì‘ì„±ì: AI Assistant
ì‘ì„± ì¼ì‹œ: 2025-01-02
ê¸°ë°˜: WatchHamster_Project/core/news_data_parser.py ë° ê°œë³„ íŒŒì„œë“¤
"""

import re
import json
from datetime import datetime, timedelta, time
from typing import Dict, Any, Optional, List, Tuple, Union
from dataclasses import dataclass, asdict
from enum import Enum
import logging


class NewsStatus(Enum):
    """ë‰´ìŠ¤ ìƒíƒœ ì—´ê±°í˜•"""
    LATEST = "latest"           # ìµœì‹ 
    DELAYED = "delayed"         # ë°œí–‰ ì§€ì—°
    EARLY = "early"            # ì¡°ê¸° ë°œí–‰
    OLD = "old"                # ê³¼ê±° ë‰´ìŠ¤
    NO_DATA = "no_data"        # ë°ì´í„° ì—†ìŒ
    INVALID = "invalid"        # ìœ íš¨í•˜ì§€ ì•ŠìŒ
    PENDING = "pending"        # ë°œí–‰ ì „
    ERROR = "error"            # ì˜¤ë¥˜


@dataclass
class NewsItem:
    """ë‰´ìŠ¤ ì•„ì´í…œ ë°ì´í„° í´ë˜ìŠ¤"""
    news_type: str
    title: str
    content: str
    date: str
    time: str
    status: NewsStatus
    status_description: str
    is_latest: bool
    is_delayed: bool
    delay_minutes: int
    expected_time: str
    display_name: str
    emoji: str
    raw_data: Dict[str, Any]
    parsed_datetime: Optional[datetime] = None
    
    # íƒ€ì…ë³„ ì „ë¬¸ ë°ì´í„°
    specialized_data: Optional[Dict[str, Any]] = None


@dataclass
class NewsTypeConfig:
    """ë‰´ìŠ¤ íƒ€ì…ë³„ ì„¤ì •"""
    display_name: str
    emoji: str
    expected_publish_time: str
    expected_time_range: Dict[str, str]
    delay_check_times: List[str]
    tolerance_minutes: int
    time_format: str
    business_hours_only: bool = True


@dataclass
class CurrencyRate:
    """í†µí™” í™˜ìœ¨ ë°ì´í„°"""
    currency_pair: str
    rate: float
    change: float
    change_percent: float
    direction: str
    high: Optional[float] = None
    low: Optional[float] = None


@dataclass
class MarketIndex:
    """ì‹œì¥ ì§€ìˆ˜ ë°ì´í„°"""
    name: str
    value: float
    change: float
    change_percent: float
    direction: str


@dataclass
class TradingFlow:
    """ë§¤ë§¤ ë™í–¥ ë°ì´í„°"""
    foreign_net: float
    institution_net: float
    individual_net: float


class NewsDataParser:
    """
    í†µí•© ë‰´ìŠ¤ ë°ì´í„° íŒŒì‹± ë° ìƒíƒœ íŒë‹¨ í´ë˜ìŠ¤
    
    INFOMAX APIì—ì„œ ë°›ì€ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ê³  ê° ë°ì´í„° ì†ŒìŠ¤ë³„ë¡œ
    ìƒíƒœë¥¼ íŒë‹¨í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        """íŒŒì„œ ì´ˆê¸°í™”"""
        self.logger = logging.getLogger(__name__)
        
        # ë‰´ìŠ¤ íƒ€ì…ë³„ ì„¤ì •
        self.news_configs = {
            'newyork-market-watch': NewsTypeConfig(
                display_name='ë‰´ìš•ë§ˆì¼“ì›Œì¹˜',
                emoji='ğŸŒ†',
                expected_publish_time='060000',
                expected_time_range={'start': '055500', 'end': '061500'},
                delay_check_times=['070000', '073000', '080000', '083000'],
                tolerance_minutes=15,
                time_format='6digit',
                business_hours_only=False  # 24ì‹œê°„ ìš´ì˜
            ),
            'kospi-close': NewsTypeConfig(
                display_name='ì¦ì‹œë§ˆê°',
                emoji='ğŸ“ˆ',
                expected_publish_time='154000',
                expected_time_range={'start': '153500', 'end': '155000'},
                delay_check_times=['155500', '160000', '163000', '170000'],
                tolerance_minutes=10,
                time_format='6digit',
                business_hours_only=True
            ),
            'exchange-rate': NewsTypeConfig(
                display_name='ì„œí™˜ë§ˆê°',
                emoji='ğŸ’±',
                expected_publish_time='163000',
                expected_time_range={'start': '162500', 'end': '163500'},
                delay_check_times=['164000', '170000', '173000', '180000'],
                tolerance_minutes=5,
                time_format='6digit',
                business_hours_only=True
            )
        }
        
        # í•œêµ­ ì˜ì—…ì¼ ì„¤ì • (2025ë…„ ê¸°ì¤€)
        self.korean_holidays = [
            '20250101', '20250128', '20250129', '20250130',  # ì‹ ì •, ì„¤ë‚ 
            '20250301', '20250505', '20250506', '20250815',  # ì‚¼ì¼ì ˆ, ì–´ë¦°ì´ë‚ , ëŒ€ì²´íœ´ì¼, ê´‘ë³µì ˆ
            '20250917', '20250918', '20250919',              # ì¶”ì„
            '20251003', '20251009', '20251225'               # ê°œì²œì ˆ, í•œê¸€ë‚ , ì„±íƒ„ì ˆ
        ]
        
        # í†µí™” íŒ¨í„´ (ì„œí™˜ë§ˆê°ìš©)
        self.currency_patterns = {
            'usd_krw': [
                r'ì›ë‹¬ëŸ¬\s*(?:í™˜ìœ¨)?\s*([0-9,]+\.?[0-9]*)',
                r'ë‹¬ëŸ¬ì›\s*(?:í™˜ìœ¨)?\s*([0-9,]+\.?[0-9]*)',
                r'USD/KRW\s*([0-9,]+\.?[0-9]*)',
                r'ë¯¸êµ­\s*ë‹¬ëŸ¬\s*([0-9,]+\.?[0-9]*)'
            ],
            'jpy_krw': [
                r'ì—”í™”\s*(?:í™˜ìœ¨)?\s*([0-9,]+\.?[0-9]*)',
                r'ì¼ë³¸\s*ì—”\s*([0-9,]+\.?[0-9]*)',
                r'JPY/KRW\s*([0-9,]+\.?[0-9]*)'
            ],
            'eur_krw': [
                r'ìœ ë¡œ\s*(?:í™˜ìœ¨)?\s*([0-9,]+\.?[0-9]*)',
                r'EUR/KRW\s*([0-9,]+\.?[0-9]*)'
            ]
        }
        
        # ì§€ìˆ˜ íŒ¨í„´ (ë‰´ìš•ë§ˆì¼“ì›Œì¹˜, ì¦ì‹œë§ˆê°ìš©)
        self.index_patterns = {
            # ë‰´ìš• ì§€ìˆ˜
            'dow': [
                r'ë‹¤ìš°(?:ì¡´ìŠ¤)?(?:\s*ì‚°ì—…í‰ê· ì§€ìˆ˜)?\s*(?:ì§€ìˆ˜)?\s*([0-9,]+\.?[0-9]*)',
                r'DOW\s*([0-9,]+\.?[0-9]*)',
                r'Dow\s*Jones\s*([0-9,]+\.?[0-9]*)'
            ],
            'nasdaq': [
                r'ë‚˜ìŠ¤ë‹¥\s*(?:ì¢…í•©ì§€ìˆ˜)?\s*([0-9,]+\.?[0-9]*)',
                r'NASDAQ\s*([0-9,]+\.?[0-9]*)'
            ],
            'sp500': [
                r'S&P\s*500\s*([0-9,]+\.?[0-9]*)',
                r'ìŠ¤íƒ ë”ë“œ\s*í‘¸ì–´\s*500\s*([0-9,]+\.?[0-9]*)'
            ],
            # í•œêµ­ ì§€ìˆ˜
            'kospi': [
                r'ì½”ìŠ¤í”¼\s*(?:ì§€ìˆ˜)?\s*([0-9,]+\.?[0-9]*)',
                r'KOSPI\s*([0-9,]+\.?[0-9]*)',
                r'ì¢…í•©ì£¼ê°€ì§€ìˆ˜\s*([0-9,]+\.?[0-9]*)'
            ],
            'kosdaq': [
                r'ì½”ìŠ¤ë‹¥\s*(?:ì§€ìˆ˜)?\s*([0-9,]+\.?[0-9]*)',
                r'KOSDAQ\s*([0-9,]+\.?[0-9]*)'
            ]
        }
        
        # ì‹œì¥ ìƒí™© í‚¤ì›Œë“œ
        self.market_keywords = {
            'positive': ['ìƒìŠ¹', 'ì˜¤ë¦„', 'ê¸‰ë“±', 'ê°•ì„¸', 'ë°˜ë“±', 'íšŒë³µ', 'ì¦ê°€', 'í”ŒëŸ¬ìŠ¤'],
            'negative': ['í•˜ë½', 'ë‚´ë¦¼', 'ê¸‰ë½', 'ì•½ì„¸', 'í•˜ë½ì„¸', 'ê°ì†Œ', 'ë§ˆì´ë„ˆìŠ¤'],
            'mixed': ['í˜¼ì¡°', 'ë“±ë½', 'ë³´í•©', 'íš¡ë³´', 'í˜¼ì¬', 'ì—‡ê°ˆë¦¼']
        }
        
        self.logger.info("í†µí•© ë‰´ìŠ¤ ë°ì´í„° íŒŒì„œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def parse_news_data(self, raw_data: Dict[str, Any]) -> Dict[str, NewsItem]:
        """ì›ì‹œ API ì‘ë‹µ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ NewsItem ê°ì²´ë¡œ ë³€í™˜"""
        parsed_items = {}
        
        if not isinstance(raw_data, dict):
            self.logger.error("ì›ì‹œ ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜")
            return parsed_items
        
        for news_type, news_data in raw_data.items():
            if news_type in self.news_configs:
                try:
                    parsed_item = await self._parse_single_news_item(news_type, news_data)
                    if parsed_item:
                        parsed_items[news_type] = parsed_item
                        self.logger.debug(f"{news_type} íŒŒì‹± ì„±ê³µ: {parsed_item.status.value}")
                except Exception as e:
                    self.logger.error(f"{news_type} íŒŒì‹± ì‹¤íŒ¨: {e}")
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ NewsItem ìƒì„±
                    parsed_items[news_type] = self._create_error_news_item(news_type, str(e))
            else:
                self.logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë‰´ìŠ¤ íƒ€ì…: {news_type}")
        
        self.logger.info(f"ë‰´ìŠ¤ ë°ì´í„° íŒŒì‹± ì™„ë£Œ: {len(parsed_items)}ê°œ íƒ€ì…")
        return parsed_items
    
    async def _parse_single_news_item(self, news_type: str, news_data: Dict[str, Any]) -> Optional[NewsItem]:
        """ê°œë³„ ë‰´ìŠ¤ ì•„ì´í…œ íŒŒì‹±"""
        config = self.news_configs[news_type]
        
        # ê¸°ë³¸ ë°ì´í„° ì¶”ì¶œ
        title = news_data.get('title', '') if news_data else ''
        content = news_data.get('content', '') if news_data else ''
        date = news_data.get('date', '') if news_data else ''
        time_str = news_data.get('time', '') if news_data else ''
        
        # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°
        if not news_data or not title:
            return NewsItem(
                news_type=news_type,
                title='',
                content='',
                date='',
                time='',
                status=NewsStatus.NO_DATA,
                status_description='ë°ì´í„° ì—†ìŒ',
                is_latest=False,
                is_delayed=False,
                delay_minutes=0,
                expected_time=config.expected_publish_time,
                display_name=config.display_name,
                emoji=config.emoji,
                raw_data=news_data or {},
                specialized_data=None
            )
        
        # ë‚ ì§œ/ì‹œê°„ íŒŒì‹±
        parsed_datetime = self._parse_datetime(date, time_str)
        
        # ìƒíƒœ íŒë‹¨
        status_info = self._determine_news_status(news_type, date, time_str, parsed_datetime)
        
        # íƒ€ì…ë³„ ì „ë¬¸ ë°ì´í„° íŒŒì‹±
        specialized_data = await self._parse_specialized_data(news_type, title, content)
        
        return NewsItem(
            news_type=news_type,
            title=title,
            content=content,
            date=date,
            time=time_str,
            status=status_info['status'],
            status_description=status_info['description'],
            is_latest=status_info['is_latest'],
            is_delayed=status_info['is_delayed'],
            delay_minutes=status_info['delay_minutes'],
            expected_time=config.expected_publish_time,
            display_name=config.display_name,
            emoji=config.emoji,
            raw_data=news_data,
            parsed_datetime=parsed_datetime,
            specialized_data=specialized_data
        )
    
    async def _parse_specialized_data(self, news_type: str, title: str, content: str) -> Optional[Dict[str, Any]]:
        """íƒ€ì…ë³„ ì „ë¬¸ ë°ì´í„° íŒŒì‹±"""
        text = f"{title} {content}"
        
        try:
            if news_type == 'exchange-rate':
                return await self._parse_exchange_rate_data(text)
            elif news_type == 'newyork-market-watch':
                return await self._parse_newyork_market_data(text)
            elif news_type == 'kospi-close':
                return await self._parse_kospi_close_data(text)
        except Exception as e:
            self.logger.error(f"{news_type} ì „ë¬¸ ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {e}")
        
        return None
    
    async def _parse_exchange_rate_data(self, text: str) -> Dict[str, Any]:
        """ì„œí™˜ë§ˆê° ì „ë¬¸ ë°ì´í„° íŒŒì‹±"""
        exchange_data = {
            'market_situation': 'ë³´í•©',
            'usd_krw_rate': None,
            'major_currencies': [],
            'volatility_level': 'medium'
        }
        
        # ì›ë‹¬ëŸ¬ í™˜ìœ¨ ì¶”ì¶œ
        for pattern in self.currency_patterns['usd_krw']:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                try:
                    rate_str = match.group(1).replace(',', '')
                    rate = float(rate_str)
                    
                    # ë³€í™”ëŸ‰ê³¼ ë³€í™”ìœ¨ ì¶”ì¶œ
                    change, change_percent = self._extract_rate_change(text, match.start())
                    
                    exchange_data['usd_krw_rate'] = {
                        'currency_pair': 'USD/KRW',
                        'rate': rate,
                        'change': change,
                        'change_percent': change_percent,
                        'direction': 'up' if change > 0 else 'down' if change < 0 else 'flat'
                    }
                    break
                except (ValueError, IndexError):
                    continue
        
        # ì£¼ìš” í†µí™” í™˜ìœ¨ ì¶”ì¶œ
        major_currencies = []
        for currency_name, patterns in self.currency_patterns.items():
            if currency_name == 'usd_krw':
                continue
                
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    try:
                        rate_str = match.group(1).replace(',', '')
                        rate = float(rate_str)
                        
                        change, change_percent = self._extract_rate_change(text, match.start())
                        
                        major_currencies.append({
                            'currency_pair': currency_name.upper().replace('_', '/'),
                            'rate': rate,
                            'change': change,
                            'change_percent': change_percent,
                            'direction': 'up' if change > 0 else 'down' if change < 0 else 'flat'
                        })
                        break
                    except (ValueError, IndexError):
                        continue
        
        exchange_data['major_currencies'] = major_currencies
        
        # ì‹œì¥ ìƒí™© íŒë‹¨
        exchange_data['market_situation'] = self._determine_market_situation_from_text(text)
        
        return exchange_data
    
    async def _parse_newyork_market_data(self, text: str) -> Dict[str, Any]:
        """ë‰´ìš•ë§ˆì¼“ì›Œì¹˜ ì „ë¬¸ ë°ì´í„° íŒŒì‹±"""
        market_data = {
            'market_situation': 'í˜¼ì¡°',
            'major_indices': [],
            'key_factors': []
        }
        
        # ì£¼ìš” ì§€ìˆ˜ ì¶”ì¶œ
        major_indices = []
        for index_name in ['dow', 'nasdaq', 'sp500']:
            if index_name in self.index_patterns:
                for pattern in self.index_patterns[index_name]:
                    match = re.search(pattern, text, re.IGNORECASE)
                    if match:
                        try:
                            value_str = match.group(1).replace(',', '')
                            value = float(value_str)
                            
                            change, change_percent = self._extract_change_info(text, match.start())
                            
                            major_indices.append({
                                'name': self._get_index_display_name(index_name),
                                'value': value,
                                'change': change,
                                'change_percent': change_percent,
                                'direction': 'up' if change > 0 else 'down' if change < 0 else 'flat'
                            })
                            break
                        except (ValueError, IndexError):
                            continue
        
        market_data['major_indices'] = major_indices
        
        # ì£¼ìš” ìš”ì¸ ì¶”ì¶œ
        factor_patterns = [
            r'(ì—°ì¤€|Fed|ê¸ˆë¦¬|ì¸í”Œë ˆì´ì…˜).*?(?:[.ã€‚]|$)',
            r'(ì‹¤ì |ì–´ë‹|earnings).*?(?:[.ã€‚]|$)',
            r'(ì¤‘êµ­|ë¬´ì—­|ê´€ì„¸).*?(?:[.ã€‚]|$)',
            r'(ìœ ê°€|ì›ìœ |oil).*?(?:[.ã€‚]|$)'
        ]
        
        key_factors = []
        for pattern in factor_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                if len(match) > 10 and len(match) < 100:
                    key_factors.append(match.strip())
        
        market_data['key_factors'] = key_factors[:5]  # ìµœëŒ€ 5ê°œ
        
        # ì‹œì¥ ìƒí™© íŒë‹¨
        market_data['market_situation'] = self._determine_market_situation_from_text(text)
        
        return market_data
    
    async def _parse_kospi_close_data(self, text: str) -> Dict[str, Any]:
        """ì¦ì‹œë§ˆê° ì „ë¬¸ ë°ì´í„° íŒŒì‹±"""
        kospi_data = {
            'market_situation': 'í˜¼ì¡°',
            'main_indices': [],
            'trading_flow': None,
            'sector_analysis': {}
        }
        
        # ì£¼ìš” ì§€ìˆ˜ ì¶”ì¶œ
        main_indices = []
        for index_name in ['kospi', 'kosdaq']:
            if index_name in self.index_patterns:
                for pattern in self.index_patterns[index_name]:
                    match = re.search(pattern, text, re.IGNORECASE)
                    if match:
                        try:
                            value_str = match.group(1).replace(',', '')
                            value = float(value_str)
                            
                            change, change_percent = self._extract_change_info(text, match.start())
                            
                            main_indices.append({
                                'name': self._get_index_display_name(index_name),
                                'value': value,
                                'change': change,
                                'change_percent': change_percent,
                                'direction': 'up' if change > 0 else 'down' if change < 0 else 'flat'
                            })
                            break
                        except (ValueError, IndexError):
                            continue
        
        kospi_data['main_indices'] = main_indices
        
        # ë§¤ë§¤ ë™í–¥ ì¶”ì¶œ
        trading_flow = {}
        
        # ì™¸êµ­ì¸ ë§¤ë§¤
        foreign_pattern = r'ì™¸êµ­ì¸.*?([+-]?\s*[0-9,]+(?:\.[0-9]+)?)\s*ì–µ'
        foreign_match = re.search(foreign_pattern, text)
        if foreign_match:
            try:
                trading_flow['foreign_net'] = float(foreign_match.group(1).replace(' ', '').replace(',', ''))
            except ValueError:
                pass
        
        # ê¸°ê´€ ë§¤ë§¤
        institution_pattern = r'ê¸°ê´€.*?([+-]?\s*[0-9,]+(?:\.[0-9]+)?)\s*ì–µ'
        institution_match = re.search(institution_pattern, text)
        if institution_match:
            try:
                trading_flow['institution_net'] = float(institution_match.group(1).replace(' ', '').replace(',', ''))
            except ValueError:
                pass
        
        if trading_flow:
            kospi_data['trading_flow'] = trading_flow
        
        # ì‹œì¥ ìƒí™© íŒë‹¨
        kospi_data['market_situation'] = self._determine_market_situation_from_text(text)
        
        return kospi_data
    
    def _extract_rate_change(self, text: str, position: int) -> Tuple[float, float]:
        """í™˜ìœ¨ ë³€í™”ëŸ‰ê³¼ ë³€í™”ìœ¨ ì¶”ì¶œ"""
        start = max(0, position - 100)
        end = min(len(text), position + 100)
        context = text[start:end]
        
        change = 0.0
        change_percent = 0.0
        
        # ë³€í™”ëŸ‰ íŒ¨í„´
        change_patterns = [
            r'([+-]?\s*[0-9,]+\.?[0-9]*)\s*(?:ì›|won)',
            r'ì „ì¼\s*ëŒ€ë¹„\s*([+-]?\s*[0-9,]+\.?[0-9]*)',
            r'([+-]\s*[0-9,]+\.?[0-9]*)'
        ]
        
        for pattern in change_patterns:
            matches = re.findall(pattern, context)
            if matches:
                try:
                    change_str = matches[0].replace(' ', '').replace(',', '')
                    change = float(change_str)
                    break
                except ValueError:
                    continue
        
        # ë³€í™”ìœ¨ íŒ¨í„´
        percent_patterns = [
            r'([+-]?\s*[0-9]+\.?[0-9]*)\s*%',
            r'([+-]?\s*[0-9]+\.?[0-9]*)\s*í¼ì„¼íŠ¸'
        ]
        
        for pattern in percent_patterns:
            matches = re.findall(pattern, context)
            if matches:
                try:
                    percent_str = matches[0].replace(' ', '')
                    change_percent = float(percent_str)
                    break
                except ValueError:
                    continue
        
        return change, change_percent
    
    def _extract_change_info(self, text: str, position: int) -> Tuple[float, float]:
        """ì§€ìˆ˜ ë³€í™”ëŸ‰ê³¼ ë³€í™”ìœ¨ ì¶”ì¶œ"""
        start = max(0, position - 100)
        end = min(len(text), position + 100)
        context = text[start:end]
        
        change = 0.0
        change_percent = 0.0
        
        # ë³€í™”ëŸ‰ íŒ¨í„´
        change_patterns = [
            r'([+-]?\s*[0-9,]+\.?[0-9]*)\s*(?:í¬ì¸íŠ¸|pt|ì )',
            r'ì „ì¼\s*ëŒ€ë¹„\s*([+-]?\s*[0-9,]+\.?[0-9]*)',
            r'([+-]\s*[0-9,]+\.?[0-9]*)'
        ]
        
        for pattern in change_patterns:
            matches = re.findall(pattern, context)
            if matches:
                try:
                    change_str = matches[0].replace(' ', '').replace(',', '')
                    change = float(change_str)
                    break
                except ValueError:
                    continue
        
        # ë³€í™”ìœ¨ íŒ¨í„´
        percent_patterns = [
            r'([+-]?\s*[0-9]+\.?[0-9]*)\s*%',
            r'([+-]?\s*[0-9]+\.?[0-9]*)\s*í¼ì„¼íŠ¸'
        ]
        
        for pattern in percent_patterns:
            matches = re.findall(pattern, context)
            if matches:
                try:
                    percent_str = matches[0].replace(' ', '')
                    change_percent = float(percent_str)
                    break
                except ValueError:
                    continue
        
        return change, change_percent
    
    def _get_index_display_name(self, index_name: str) -> str:
        """ì§€ìˆ˜ í‘œì‹œëª… ë°˜í™˜"""
        display_names = {
            'dow': 'ë‹¤ìš°ì¡´ìŠ¤',
            'nasdaq': 'ë‚˜ìŠ¤ë‹¥',
            'sp500': 'S&P500',
            'kospi': 'ì½”ìŠ¤í”¼',
            'kosdaq': 'ì½”ìŠ¤ë‹¥'
        }
        return display_names.get(index_name, index_name.upper())
    
    def _determine_market_situation_from_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ì—ì„œ ì‹œì¥ ìƒí™© íŒë‹¨"""
        text_lower = text.lower()
        
        positive_count = sum(1 for keyword in self.market_keywords['positive'] 
                           if keyword in text_lower)
        negative_count = sum(1 for keyword in self.market_keywords['negative'] 
                           if keyword in text_lower)
        mixed_count = sum(1 for keyword in self.market_keywords['mixed'] 
                         if keyword in text_lower)
        
        if mixed_count > 0:
            return 'í˜¼ì¡°'
        elif positive_count > negative_count:
            return 'ìƒìŠ¹'
        elif negative_count > positive_count:
            return 'í•˜ë½'
        else:
            return 'ë³´í•©'
    
    def _determine_news_status(self, news_type: str, date: str, time_str: str, 
                             parsed_datetime: Optional[datetime]) -> Dict[str, Any]:
        """ë‰´ìŠ¤ ìƒíƒœ íŒë‹¨ (ìµœì‹ , ë°œí–‰ ì „, ë°œí–‰ ì§€ì—°)"""
        config = self.news_configs[news_type]
        now = datetime.now()
        today_str = now.strftime('%Y%m%d')
        
        # ê¸°ë³¸ ìƒíƒœ ì •ë³´
        status_info = {
            'status': NewsStatus.INVALID,
            'description': 'ìƒíƒœ ë¶ˆëª…',
            'is_latest': False,
            'is_delayed': False,
            'delay_minutes': 0
        }
        
        # ë‚ ì§œ/ì‹œê°„ ì •ë³´ê°€ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°
        if not date or not time_str or not parsed_datetime:
            status_info.update({
                'status': NewsStatus.INVALID,
                'description': 'ì‹œê°„ ì •ë³´ ì˜¤ë¥˜'
            })
            return status_info
        
        # ì˜ì—…ì¼ í™•ì¸ (í•„ìš”í•œ ê²½ìš°)
        if config.business_hours_only and not self._is_business_day(date):
            status_info.update({
                'status': NewsStatus.OLD,
                'description': 'ë¹„ì˜ì—…ì¼ ë‰´ìŠ¤'
            })
            return status_info
        
        # ë‚ ì§œë³„ ìƒíƒœ íŒë‹¨
        if date == today_str:
            # ì˜¤ëŠ˜ ë‰´ìŠ¤ - ì‹œê°„ ê¸°ë°˜ ìƒíƒœ íŒë‹¨
            return self._analyze_today_news_status(news_type, parsed_datetime, now)
        elif date < today_str:
            # ê³¼ê±° ë‰´ìŠ¤
            days_ago = (now.date() - parsed_datetime.date()).days
            status_info.update({
                'status': NewsStatus.OLD,
                'description': f'{days_ago}ì¼ ì „ ë‰´ìŠ¤',
                'is_latest': False
            })
        else:
            # ë¯¸ë˜ ë‰´ìŠ¤ (ì‹œìŠ¤í…œ ì‹œê°„ ì˜¤ë¥˜?)
            status_info.update({
                'status': NewsStatus.INVALID,
                'description': 'ë¯¸ë˜ ë‰´ìŠ¤ (ì‹œê°„ ì˜¤ë¥˜?)',
                'is_latest': False
            })
        
        return status_info
    
    def _analyze_today_news_status(self, news_type: str, news_datetime: datetime, 
                                 now: datetime) -> Dict[str, Any]:
        """ì˜¤ëŠ˜ ë‰´ìŠ¤ì˜ ìƒíƒœ ë¶„ì„"""
        config = self.news_configs[news_type]
        
        # ì˜ˆìƒ ë°œí–‰ ì‹œê°„ íŒŒì‹±
        expected_time = self._parse_time_string(config.expected_publish_time)
        if not expected_time:
            return {
                'status': NewsStatus.LATEST,
                'description': 'ìµœì‹ ',
                'is_latest': True,
                'is_delayed': False,
                'delay_minutes': 0
            }
        
        # ì˜ˆìƒ ë°œí–‰ ì‹œê°„ì„ ì˜¤ëŠ˜ ë‚ ì§œë¡œ ë³€í™˜
        expected_datetime = datetime.combine(now.date(), expected_time)
        
        # ì‹œê°„ ì°¨ì´ ê³„ì‚° (ë¶„ ë‹¨ìœ„)
        time_diff_minutes = (news_datetime - expected_datetime).total_seconds() / 60
        
        # í—ˆìš© ì˜¤ì°¨ ë²”ìœ„ í™•ì¸
        tolerance = config.tolerance_minutes
        
        if abs(time_diff_minutes) <= tolerance:
            # ì •ì‹œ ë°œí–‰ (í—ˆìš© ì˜¤ì°¨ ë²”ìœ„ ë‚´)
            return {
                'status': NewsStatus.LATEST,
                'description': 'ìµœì‹  (ì •ì‹œ ë°œí–‰)',
                'is_latest': True,
                'is_delayed': False,
                'delay_minutes': 0
            }
        elif time_diff_minutes > tolerance:
            # ì§€ì—° ë°œí–‰
            delay_minutes = int(time_diff_minutes)
            delay_level = self._get_delay_level(news_type, delay_minutes)
            
            return {
                'status': NewsStatus.DELAYED,
                'description': f'ì§€ì—° ë°œí–‰ ({delay_minutes}ë¶„ ì§€ì—°, {delay_level})',
                'is_latest': True,
                'is_delayed': True,
                'delay_minutes': delay_minutes
            }
        else:
            # ì¡°ê¸° ë°œí–‰
            early_minutes = int(abs(time_diff_minutes))
            return {
                'status': NewsStatus.EARLY,
                'description': f'ì¡°ê¸° ë°œí–‰ ({early_minutes}ë¶„ ë¹ ë¦„)',
                'is_latest': True,
                'is_delayed': False,
                'delay_minutes': 0
            }
    
    def _get_delay_level(self, news_type: str, delay_minutes: int) -> str:
        """ì§€ì—° ì •ë„ ë ˆë²¨ íŒë‹¨"""
        if delay_minutes <= 15:
            return "ê²½ë¯¸í•œ ì§€ì—°"
        elif delay_minutes <= 30:
            return "ë³´í†µ ì§€ì—°"
        elif delay_minutes <= 60:
            return "ì‹¬ê°í•œ ì§€ì—°"
        else:
            return "ë§¤ìš° ì‹¬ê°í•œ ì§€ì—°"
    
    def _parse_datetime(self, date_str: str, time_str: str) -> Optional[datetime]:
        """ë‚ ì§œ/ì‹œê°„ ë¬¸ìì—´ì„ datetime ê°ì²´ë¡œ ë³€í™˜"""
        try:
            # ë‚ ì§œ íŒŒì‹± (YYYYMMDD)
            if len(date_str) == 8 and date_str.isdigit():
                date_obj = datetime.strptime(date_str, '%Y%m%d').date()
            else:
                return None
            
            # ì‹œê°„ íŒŒì‹±
            time_obj = self._parse_time_string(time_str)
            if not time_obj:
                return None
            
            return datetime.combine(date_obj, time_obj)
            
        except Exception as e:
            self.logger.error(f"ë‚ ì§œ/ì‹œê°„ íŒŒì‹± ì˜¤ë¥˜: {date_str} {time_str} - {e}")
            return None
    
    def _parse_time_string(self, time_str: str) -> Optional[time]:
        """ì‹œê°„ ë¬¸ìì—´ì„ time ê°ì²´ë¡œ ë³€í™˜"""
        try:
            # ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ì ì œê±°
            clean_time = re.sub(r'[^0-9]', '', time_str)
            
            if len(clean_time) == 6:
                # HHMMSS í˜•ì‹
                return datetime.strptime(clean_time, '%H%M%S').time()
            elif len(clean_time) == 4:
                # HHMM í˜•ì‹
                return datetime.strptime(clean_time, '%H%M').time()
            elif len(clean_time) == 5:
                # HMMSS í˜•ì‹ (ì•ìë¦¬ 0 ëˆ„ë½)
                return datetime.strptime(clean_time.zfill(6), '%H%M%S').time()
            elif len(clean_time) == 3:
                # HMM í˜•ì‹ (ì•ìë¦¬ 0 ëˆ„ë½)
                return datetime.strptime(clean_time.zfill(4), '%H%M').time()
            else:
                return None
                
        except Exception as e:
            self.logger.error(f"ì‹œê°„ ë¬¸ìì—´ íŒŒì‹± ì˜¤ë¥˜: {time_str} - {e}")
            return None
    
    def _is_business_day(self, date_str: str) -> bool:
        """ì˜ì—…ì¼ ì—¬ë¶€ í™•ì¸"""
        try:
            # ê³µíœ´ì¼ í™•ì¸
            if date_str in self.korean_holidays:
                return False
            
            # ì£¼ë§ í™•ì¸
            date_obj = datetime.strptime(date_str, '%Y%m%d')
            weekday = date_obj.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
            
            # í† ìš”ì¼(5), ì¼ìš”ì¼(6)ì€ ë¹„ì˜ì—…ì¼
            return weekday < 5
            
        except Exception:
            return True  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì˜ì—…ì¼ë¡œ ê°„ì£¼
    
    def _create_error_news_item(self, news_type: str, error_message: str) -> NewsItem:
        """ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ NewsItem ìƒì„±"""
        config = self.news_configs.get(news_type)
        if not config:
            config = NewsTypeConfig(
                display_name=news_type.upper(),
                emoji='ğŸ“°',
                expected_publish_time='120000',
                expected_time_range={'start': '115500', 'end': '120500'},
                delay_check_times=['130000'],
                tolerance_minutes=30,
                time_format='6digit'
            )
        
        return NewsItem(
            news_type=news_type,
            title='',
            content='',
            date='',
            time='',
            status=NewsStatus.ERROR,
            status_description=f'íŒŒì‹± ì˜¤ë¥˜: {error_message}',
            is_latest=False,
            is_delayed=False,
            delay_minutes=0,
            expected_time=config.expected_publish_time,
            display_name=config.display_name,
            emoji=config.emoji,
            raw_data={},
            specialized_data=None
        )
    
    def get_status_summary(self, parsed_items: Dict[str, NewsItem]) -> Dict[str, Any]:
        """íŒŒì‹±ëœ ë‰´ìŠ¤ ì•„ì´í…œë“¤ì˜ ìƒíƒœ ìš”ì•½ ìƒì„±"""
        summary = {
            'total_news': len(parsed_items),
            'latest_count': 0,
            'delayed_count': 0,
            'old_count': 0,
            'no_data_count': 0,
            'error_count': 0,
            'overall_status': 'unknown',
            'news_status': {},
            'delay_analysis': {
                'max_delay_minutes': 0,
                'avg_delay_minutes': 0,
                'delayed_news_types': []
            }
        }
        
        total_delay = 0
        delayed_count = 0
        
        for news_type, news_item in parsed_items.items():
            status = news_item.status
            
            # ê°œë³„ ë‰´ìŠ¤ ìƒíƒœ ì •ë³´
            summary['news_status'][news_type] = {
                'status': status.value,
                'description': news_item.status_description,
                'is_latest': news_item.is_latest,
                'is_delayed': news_item.is_delayed,
                'delay_minutes': news_item.delay_minutes,
                'display_name': news_item.display_name,
                'emoji': news_item.emoji
            }
            
            # ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
            if status == NewsStatus.LATEST:
                summary['latest_count'] += 1
            elif status == NewsStatus.DELAYED:
                summary['delayed_count'] += 1
                total_delay += news_item.delay_minutes
                delayed_count += 1
                summary['delay_analysis']['delayed_news_types'].append(news_type)
                summary['delay_analysis']['max_delay_minutes'] = max(
                    summary['delay_analysis']['max_delay_minutes'],
                    news_item.delay_minutes
                )
            elif status == NewsStatus.OLD:
                summary['old_count'] += 1
            elif status == NewsStatus.NO_DATA:
                summary['no_data_count'] += 1
            elif status == NewsStatus.ERROR:
                summary['error_count'] += 1
        
        # í‰ê·  ì§€ì—° ì‹œê°„ ê³„ì‚°
        if delayed_count > 0:
            summary['delay_analysis']['avg_delay_minutes'] = total_delay / delayed_count
        
        # ì „ì²´ ìƒíƒœ íŒë‹¨
        if summary['error_count'] > 0:
            summary['overall_status'] = 'error'
        elif summary['latest_count'] == summary['total_news']:
            summary['overall_status'] = 'all_latest'
        elif summary['latest_count'] > 0:
            summary['overall_status'] = 'partial_latest'
        elif summary['delayed_count'] > 0:
            summary['overall_status'] = 'has_delayed'
        elif summary['no_data_count'] > 0:
            summary['overall_status'] = 'no_data'
        else:
            summary['overall_status'] = 'all_old'
        
        return summary
    
    def validate_parsed_data(self, parsed_items: Dict[str, NewsItem]) -> Tuple[bool, List[str]]:
        """íŒŒì‹±ëœ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
        errors = []
        
        if not isinstance(parsed_items, dict):
            errors.append("íŒŒì‹±ëœ ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹˜")
            return False, errors
        
        if not parsed_items:
            errors.append("íŒŒì‹±ëœ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ")
            return False, errors
        
        # ê° ë‰´ìŠ¤ ì•„ì´í…œ ê²€ì¦
        for news_type, news_item in parsed_items.items():
            if not isinstance(news_item, NewsItem):
                errors.append(f"{news_type}: NewsItem ê°ì²´ê°€ ì•„ë‹˜")
                continue
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            if not news_item.news_type:
                errors.append(f"{news_type}: news_type í•„ë“œ ëˆ„ë½")
            
            if news_item.status == NewsStatus.ERROR:
                errors.append(f"{news_type}: íŒŒì‹± ì˜¤ë¥˜ ìƒíƒœ")
            
            # ë‰´ìŠ¤ íƒ€ì… ì„¤ì • í™•ì¸
            if news_type not in self.news_configs:
                errors.append(f"{news_type}: ì•Œ ìˆ˜ ì—†ëŠ” ë‰´ìŠ¤ íƒ€ì…")
        
        is_valid = len(errors) == 0
        return is_valid, errors


# íŒ©í† ë¦¬ í•¨ìˆ˜
def create_news_parser() -> NewsDataParser:
    """ë‰´ìŠ¤ íŒŒì„œ íŒ©í† ë¦¬ í•¨ìˆ˜"""
    return NewsDataParser()


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    import asyncio
    
    async def test_news_parser():
        """ë‰´ìŠ¤ íŒŒì„œ í…ŒìŠ¤íŠ¸"""
        parser = NewsDataParser()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_data = {
            'exchange-rate': {
                'title': 'ì›ë‹¬ëŸ¬ í™˜ìœ¨ 1,350ì› ë§ˆê°',
                'content': 'ì›ë‹¬ëŸ¬ í™˜ìœ¨ì´ ì „ì¼ ëŒ€ë¹„ 5ì› ìƒìŠ¹í•œ 1,350ì›ì— ë§ˆê°í–ˆìŠµë‹ˆë‹¤.',
                'date': '20250102',
                'time': '163000'
            },
            'newyork-market-watch': {
                'title': 'ë‰´ìš•ì¦ì‹œ ìƒìŠ¹ ë§ˆê°',
                'content': 'ë‹¤ìš°ì¡´ìŠ¤ 35,000í¬ì¸íŠ¸, ë‚˜ìŠ¤ë‹¥ 14,000í¬ì¸íŠ¸ë¡œ ìƒìŠ¹ ë§ˆê°',
                'date': '20250102',
                'time': '060000'
            },
            'kospi-close': {
                'title': 'ì½”ìŠ¤í”¼ 2,500í¬ì¸íŠ¸ ìƒìŠ¹ ë§ˆê°',
                'content': 'ì½”ìŠ¤í”¼ê°€ ì „ì¼ ëŒ€ë¹„ 20í¬ì¸íŠ¸ ìƒìŠ¹í•œ 2,500í¬ì¸íŠ¸ì— ë§ˆê°',
                'date': '20250102',
                'time': '154000'
            }
        }
        
        print("=== í†µí•© ë‰´ìŠ¤ íŒŒì„œ í…ŒìŠ¤íŠ¸ ===")
        
        # íŒŒì‹± í…ŒìŠ¤íŠ¸
        parsed_items = await parser.parse_news_data(test_data)
        
        print(f"íŒŒì‹±ëœ ë‰´ìŠ¤ ì•„ì´í…œ: {len(parsed_items)}ê°œ")
        
        for news_type, news_item in parsed_items.items():
            print(f"\n{news_item.emoji} {news_item.display_name}")
            print(f"  ìƒíƒœ: {news_item.status.value}")
            print(f"  ì„¤ëª…: {news_item.status_description}")
            print(f"  ìµœì‹  ì—¬ë¶€: {news_item.is_latest}")
            print(f"  ì§€ì—° ì—¬ë¶€: {news_item.is_delayed}")
            if news_item.specialized_data:
                print(f"  ì „ë¬¸ ë°ì´í„°: {len(news_item.specialized_data)}ê°œ í•„ë“œ")
        
        # ìƒíƒœ ìš”ì•½ í…ŒìŠ¤íŠ¸
        summary = parser.get_status_summary(parsed_items)
        print(f"\nì „ì²´ ìƒíƒœ: {summary['overall_status']}")
        print(f"ìµœì‹  ë‰´ìŠ¤: {summary['latest_count']}ê°œ")
        print(f"ì§€ì—° ë‰´ìŠ¤: {summary['delayed_count']}ê°œ")
        
        # ê²€ì¦ í…ŒìŠ¤íŠ¸
        is_valid, errors = parser.validate_parsed_data(parsed_items)
        print(f"\në°ì´í„° ìœ íš¨ì„±: {'ìœ íš¨' if is_valid else 'ì˜¤ë¥˜'}")
        if errors:
            for error in errors:
                print(f"  - {error}")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_news_parser())