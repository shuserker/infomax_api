#!/usr/bin/env python3
"""
POSCO ì‹œìŠ¤í…œ íŒŒì¼ ì°¸ì¡° ë¬´ê²°ì„± ì™„ì „ ë³µêµ¬ ë„êµ¬

Task 4: íŒŒì¼ ì°¸ì¡° ë¬´ê²°ì„± ì™„ì „ ë³µêµ¬
- 83ê°œ ê¹¨ì§„ íŒŒì¼ ì°¸ì¡° ëª¨ë‘ ìˆ˜ì •
- ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼ ê²½ë¡œ ì°¸ì¡° ì œê±° ë˜ëŠ” ìˆ˜ì •
- ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´ ì˜¤ì¸ì‹ ë¬¸ì œ í•´ê²°
- ìƒëŒ€ ê²½ë¡œ ì°¸ì¡° ì •í™•ì„± ê²€ì¦ ë° í‘œì¤€í™”
"""

import os
import re
import json
import shutil
import ast
from pathlib import Path
from typing import Dict, List, Set, Optional, Tuple
from dataclasses import dataclass
import logging
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class FileReferenceIssue:
    """íŒŒì¼ ì°¸ì¡° ë¬¸ì œ ì •ë³´"""
    source_file: str
    referenced_path: str
    line_number: int
    issue_type: str
    context: str
    severity: str
    suggested_fix: Optional[str] = None

@dataclass
class RepairResult:
    """ìˆ˜ë¦¬ ê²°ê³¼ ì •ë³´"""
    file_path: str
    repair_type: str
    success: bool
    changes_made: List[str]
    backup_created: bool
    error_message: Optional[str] = None

class ComprehensiveFileReferenceRepairer:
    """ì¢…í•©ì ì¸ íŒŒì¼ ì°¸ì¡° ë¬´ê²°ì„± ë³µêµ¬ í´ë˜ìŠ¤"""
    
    def __init__(self, root_path: str = "."):
        self.root_path = Path(root_path).resolve()
        self.issues: List[FileReferenceIssue] = []
        self.repair_results: List[RepairResult] = []
        self.existing_files: Dict[str, List[str]] = {}
        self.python_modules: Dict[str, str] = {}
        self.backup_dir = Path(".comprehensive_file_reference_backup")
        
        # Python í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì œì™¸í•  ëª¨ë“ˆë“¤)
        self.standard_library = {
            'os', 'sys', 'json', 'time', 'datetime', 'pathlib', 'logging', 'unittest',
            'subprocess', 'shutil', 'glob', 'collections', 'itertools', 'functools',
            'typing', 'dataclasses', 'abc', 'contextlib', 'warnings', 'traceback',
            'inspect', 'importlib', 'pkgutil', 'threading', 'multiprocessing',
            'queue', 'socket', 'urllib', 'http', 'email', 'html', 'xml', 'csv',
            'sqlite3', 'hashlib', 'hmac', 'secrets', 'uuid', 'random', 'math',
            'statistics', 'decimal', 'fractions', 'cmath', 'operator', 'copy',
            'pickle', 'copyreg', 'shelve', 'marshal', 'dbm', 'zlib', 'gzip',
            'bz2', 'lzma', 'zipfile', 'tarfile', 'configparser', 'netrc',
            'xdrlib', 'plistlib', 'calendar', 'locale', 'gettext', 'argparse',
            'optparse', 'getopt', 'tempfile', 'glob', 'fnmatch', 'linecache',
            'shlex', 'string', 'textwrap', 'unicodedata', 'stringprep',
            'readline', 'rlcompleter', 'struct', 'codecs', 'encodings',
            'io', 'mmap', 'select', 'selectors', 'asyncio', 'asynchat',
            'asyncore', 'signal', 'msilib', 'msvcrt', 'winreg', 'winsound',
            'ast', 'dis', 'keyword', 'token', 'tokenize', 'parser', 'symbol',
            'compile', 'compileall', 'py_compile', 'zipimport', 'runpy'
        }
        
        # ì œì™¸í•  íŒ¨í„´ë“¤ (ì‹¤ì œ íŒŒì¼ì´ ì•„ë‹Œ ê²ƒë“¤)
        self.exclude_patterns = [
            r'/*/.',  # ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´
            r'/{.*/}',  # í…œí”Œë¦¿ ë³€ìˆ˜
            r'http[s]?:/',  # URL
            r'file:/',  # íŒŒì¼ URL
            r'^/$',  # í™˜ê²½ ë³€ìˆ˜
            r'/././',  # ìƒìœ„ ë””ë ‰í† ë¦¬ ì°¸ì¡°
            r'^/',  # ì ˆëŒ€ ê²½ë¡œ (ì‹œìŠ¤í…œ íŒŒì¼)
            r'__pycache__',  # Python ìºì‹œ
            r'/.git/',  # Git ë””ë ‰í† ë¦¬
            r'/.pyc$',  # Python ë°”ì´íŠ¸ì½”ë“œ
            r'backup_/d+',  # ë°±ì—… íŒŒì¼
        ]
        
        self._build_file_index()

    def _build_file_index(self):
        """íŒŒì¼ ì¸ë±ìŠ¤ êµ¬ì¶•"""
        logger.info("íŒŒì¼ ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
        
        for file_path in self.root_path.rglob("*"):
            if (file_path.is_file() and 
                not file_path.name.startswith('.') and
                not any(pattern in str(file_path) for pattern in ['.git', '__pycache__', 'backup'])):
                
                filename = file_path.name
                stem = file_path.stem
                relative_path = str(file_path.relative_to(self.root_path))
                
                # íŒŒì¼ëª…ìœ¼ë¡œ ë§¤í•‘
                if filename not in self.existing_files:
                    self.existing_files[filename] = []
                self.existing_files[filename].append(relative_path)
                
                # í™•ì¥ì ì—†ëŠ” ì´ë¦„ìœ¼ë¡œë„ ë§¤í•‘ (Python ëª¨ë“ˆìš©)
                if stem != filename:
                    if stem not in self.existing_files:
                        self.existing_files[stem] = []
                    self.existing_files[stem].append(relative_path)
                
                # Python ëª¨ë“ˆ ë§¤í•‘
                if file_path.suffix == '.py':
                    self.python_modules[stem] = relative_path

    def _should_exclude(self, reference: str) -> bool:
        """ì°¸ì¡°ë¥¼ ì œì™¸í•´ì•¼ í•˜ëŠ”ì§€ í™•ì¸"""
        for pattern in self.exclude_patterns:
            if re.search(pattern, reference):
                return True
        return False

    def scan_all_file_references(self) -> List[FileReferenceIssue]:
        """ëª¨ë“  íŒŒì¼ ì°¸ì¡° ìŠ¤ìº”"""
        logger.info("íŒŒì¼ ì°¸ì¡° ìŠ¤ìº” ì‹œì‘...")
        
        # Python íŒŒì¼ ìŠ¤ìº”
        for py_file in self.root_path.rglob("*.py"):
            if self._should_scan_file(py_file):
                self._scan_python_file(py_file)
        
        # ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìŠ¤ìº”
        for script_ext in ['*.sh', '*.bat', '*.command']:
            for script_file in self.root_path.rglob(script_ext):
                if self._should_scan_file(script_file):
                    self._scan_script_file(script_file)
        
        # JSON ì„¤ì • íŒŒì¼ ìŠ¤ìº”
        for json_file in self.root_path.rglob("*.json"):
            if self._should_scan_file(json_file):
                self._scan_json_file(json_file)
        
        # Markdown ë¬¸ì„œ ìŠ¤ìº”
        for md_file in self.root_path.rglob("*.md"):
            if self._should_scan_file(md_file):
                self._scan_markdown_file(md_file)
        
        logger.info(f"ì´ {len(self.issues)}ê°œì˜ íŒŒì¼ ì°¸ì¡° ë¬¸ì œ ë°œê²¬")
        return self.issues

    def _should_scan_file(self, file_path: Path) -> bool:
        """íŒŒì¼ì„ ìŠ¤ìº”í•´ì•¼ í•˜ëŠ”ì§€ í™•ì¸"""
        if file_path.name.startswith('.'):
            return False
        
        path_str = str(file_path)
        exclude_dirs = ['.git', '__pycache__', 'backup', '.vscode', '.kiro']
        
        for exclude_dir in exclude_dirs:
            if exclude_dir in path_str:
                return False
        
        return True

    def _scan_python_file(self, file_path: Path):
        """Python íŒŒì¼ ìŠ¤ìº”"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            lines = content.split('\n')
            
            # AST íŒŒì‹±ìœ¼ë¡œ import ë¬¸ ì¶”ì¶œ
            try:
                tree = ast.parse(content)
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            self._check_python_import(alias.name, file_path, node.lineno)
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            self._check_python_import(node.module, file_path, node.lineno)
            except SyntaxError:
                # êµ¬ë¬¸ ì˜¤ë¥˜ê°€ ìˆëŠ” íŒŒì¼ì€ ë¼ì¸ë³„ë¡œ ê²€ì‚¬
                for line_num, line in enumerate(lines, 1):
                    if 'import ' in line:
                        self._check_import_line(line, file_path, line_num)
            
            # íŒŒì¼ ê²½ë¡œ ì°¸ì¡° ê²€ì‚¬
            for line_num, line in enumerate(lines, 1):
                self._check_file_references_in_line(line, file_path, line_num)
                
        except Exception as e:
            logger.error(f"Python íŒŒì¼ ìŠ¤ìº” ì˜¤ë¥˜ {file_path}: {e}")

    def _check_python_import(self, module_name: str, source_file: Path, line_num: int):
        """Python import ê²€ì¦"""
        if not module_name or self._should_exclude(module_name):
            return
        
        # í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì²´í¬
        base_module = module_name.split('.')[0]
        if base_module in self.standard_library:
            return
        
        # ìƒëŒ€ importëŠ” ì œì™¸
        if module_name.startswith('.'):
            return
        
        # ë¡œì»¬ ëª¨ë“ˆ ì²´í¬
        if self._is_valid_local_module(module_name):
            return
        
        # ê¹¨ì§„ import ë°œê²¬
        issue = FileReferenceIssue(
            source_file=str(source_file.relative_to(self.root_path)),
            referenced_path=module_name,
            line_number=line_num,
            issue_type='broken_import',
            context=f"import {module_name}",
            severity='high',
            suggested_fix=self._suggest_import_fix(module_name)
        )
        self.issues.append(issue)

    def _check_import_line(self, line: str, source_file: Path, line_num: int):
        """import ë¼ì¸ ê²€ì‚¬ (êµ¬ë¬¸ ì˜¤ë¥˜ê°€ ìˆëŠ” íŒŒì¼ìš©)"""
        # import íŒ¨í„´ ë§¤ì¹­
        import_patterns = [
            r'from/s+([a-zA-Z_][a-zA-Z0-9_.]*)/s+import',
            r'import/s+([a-zA-Z_][a-zA-Z0-9_.]*)'
        ]
        
        for pattern in import_patterns:
            matches = re.finditer(pattern, line)
            for match in matches:
                module_name = match.group(1)
                self._check_python_import(module_name, source_file, line_num)

    def _is_valid_local_module(self, module_name: str) -> bool:
        """ë¡œì»¬ ëª¨ë“ˆì´ ìœ íš¨í•œì§€ í™•ì¸"""
        base_module = module_name.split('.')[0]
        
        # ì§ì ‘ ë§¤ì¹­
        if base_module in self.python_modules:
            return True
        
        # íŒŒì¼ ê²½ë¡œë¡œ í™•ì¸
        module_path = module_name.replace('.', '/') + '.py'
        if module_path in [paths[0] for paths in self.existing_files.values() if paths]:
            return True
        
        # íŒ¨í‚¤ì§€ í™•ì¸
        package_init = module_name.replace('.', '/') + '/__init__.py'
        if package_init in [paths[0] for paths in self.existing_files.values() if paths]:
            return True
        
        return False

    def _check_file_references_in_line(self, line: str, source_file: Path, line_num: int):
        """ë¼ì¸ì—ì„œ íŒŒì¼ ì°¸ì¡° ê²€ì‚¬"""
        # íŒŒì¼ ê²½ë¡œ íŒ¨í„´ë“¤
        patterns = [
            r'[\'"]([^\'"/s]+/.(py|sh|bat|json|md|txt|log|command|html|css|js|csv))[\'"]',
            r'Path/([\'"]([^\'"]+)[\'"]',
            r'open/([\'"]([^\'"]+)[\'"]',
            r'with/s+open/([\'"]([^\'"]+)[\'"]'
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, line)
            for match in matches:
                file_ref = match.group(1)
                if self._should_exclude(file_ref):
                    continue
                
                if not self._file_exists(file_ref, source_file):
                    issue = FileReferenceIssue(
                        source_file=str(source_file.relative_to(self.root_path)),
                        referenced_path=file_ref,
                        line_number=line_num,
                        issue_type='missing_file',
                        context=line.strip(),
                        severity='medium',
                        suggested_fix=self._suggest_file_fix(file_ref)
                    )
                    self.issues.append(issue)

    def _scan_script_file(self, file_path: Path):
        """ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìŠ¤ìº”"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            for line_num, line in enumerate(lines, 1):
                # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ íŒ¨í„´
                patterns = [
                    r'python3?/s+([^/s]+/.py)',
                    r'bash/s+([^/s]+/.sh)',
                    r'/./([^/s]+/.(sh|command|bat))',
                    r'exec/s+([^/s]+/.(sh|command|bat))'
                ]
                
                for pattern in patterns:
                    matches = re.finditer(pattern, line)
                    for match in matches:
                        script_ref = match.group(1)
                        if not self._file_exists(script_ref, file_path):
                            issue = FileReferenceIssue(
                                source_file=str(file_path.relative_to(self.root_path)),
                                referenced_path=script_ref,
                                line_number=line_num,
                                issue_type='invalid_script',
                                context=line.strip(),
                                severity='high',
                                suggested_fix=self._suggest_file_fix(script_ref)
                            )
                            self.issues.append(issue)
                            
        except Exception as e:
            logger.error(f"ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìŠ¤ìº” ì˜¤ë¥˜ {file_path}: {e}")

    def _scan_json_file(self, file_path: Path):
        """JSON íŒŒì¼ ìŠ¤ìº”"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            # JSON íŒŒì¼ì—ì„œ íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
            file_patterns = re.findall(r'"([^"]+/.(py|sh|bat|json|md|txt|log))"', content)
            
            for file_ref, ext in file_patterns:
                if self._should_exclude(file_ref):
                    continue
                
                if not self._file_exists(file_ref, file_path):
                    # ë¼ì¸ ë²ˆí˜¸ ì°¾ê¸°
                    lines = content.split('\n')
                    line_num = 1
                    for i, line in enumerate(lines, 1):
                        if file_ref in line:
                            line_num = i
                            break
                    
                    issue = FileReferenceIssue(
                        source_file=str(file_path.relative_to(self.root_path)),
                        referenced_path=file_ref,
                        line_number=line_num,
                        issue_type='missing_file',
                        context=f"JSON reference: {file_ref}",
                        severity='medium',
                        suggested_fix=self._suggest_file_fix(file_ref)
                    )
                    self.issues.append(issue)
                    
        except Exception as e:
            logger.error(f"JSON íŒŒì¼ ìŠ¤ìº” ì˜¤ë¥˜ {file_path}: {e}")

    def _scan_markdown_file(self, file_path: Path):
        """Markdown íŒŒì¼ ìŠ¤ìº”"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            for line_num, line in enumerate(lines, 1):
                # Markdown ë§í¬ íŒ¨í„´
                patterns = [
                    r'/[.*?/]/(([^)]+/.(py|sh|bat|json|md|txt|log))/)',
                    r'`([^`]+/.(py|sh|bat|json|md|txt|log))`'
                ]
                
                for pattern in patterns:
                    matches = re.finditer(pattern, line)
                    for match in matches:
                        file_ref = match.group(1)
                        if self._should_exclude(file_ref):
                            continue
                        
                        if not self._file_exists(file_ref, file_path):
                            issue = FileReferenceIssue(
                                source_file=str(file_path.relative_to(self.root_path)),
                                referenced_path=file_ref,
                                line_number=line_num,
                                issue_type='missing_file',
                                context=line.strip(),
                                severity='low',
                                suggested_fix=self._suggest_file_fix(file_ref)
                            )
                            self.issues.append(issue)
                            
        except Exception as e:
            logger.error(f"Markdown íŒŒì¼ ìŠ¤ìº” ì˜¤ë¥˜ {file_path}: {e}")

    def _file_exists(self, file_ref: str, source_file: Path) -> bool:
        """íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        # ì ˆëŒ€ ê²½ë¡œ
        if os.path.isabs(file_ref):
            return Path(file_ref).exists()
        
        # ìƒëŒ€ ê²½ë¡œ (ì†ŒìŠ¤ íŒŒì¼ ê¸°ì¤€)
        source_dir = source_file.parent
        relative_path = source_dir / file_ref
        if relative_path.exists():
            return True
        
        # ë£¨íŠ¸ ê¸°ì¤€ ê²½ë¡œ
        root_path = self.root_path / file_ref
        if root_path.exists():
            return True
        
        # íŒŒì¼ ì¸ë±ìŠ¤ì—ì„œ í™•ì¸
        filename = Path(file_ref).name
        return filename in self.existing_files

    def _suggest_import_fix(self, module_name: str) -> Optional[str]:
        """import ìˆ˜ì • ì œì•ˆ"""
        base_module = module_name.split('.')[0]
        
        # ì§ì ‘ ë§¤ì¹­
        if base_module in self.python_modules:
            return base_module
        
        # ìœ ì‚¬í•œ ëª¨ë“ˆëª… ì°¾ê¸°
        for existing_module in self.python_modules.keys():
            if (existing_module.lower() == base_module.lower() or
                base_module.lower() in existing_module.lower() or
                existing_module.lower() in base_module.lower()):
                return existing_module
        
        return None

    def _suggest_file_fix(self, file_ref: str) -> Optional[str]:
        """íŒŒì¼ ê²½ë¡œ ìˆ˜ì • ì œì•ˆ"""
        filename = Path(file_ref).name
        
        # ì •í™•í•œ íŒŒì¼ëª… ë§¤ì¹­
        if filename in self.existing_files:
            candidates = self.existing_files[filename]
            if len(candidates) == 1:
                return candidates[0]
            elif len(candidates) > 1:
                # ê°€ì¥ ìœ ì‚¬í•œ ê²½ë¡œ ì„ íƒ
                return self._find_best_path_match(file_ref, candidates)
        
        # ìœ ì‚¬í•œ íŒŒì¼ëª… ì°¾ê¸°
        for existing_name, paths in self.existing_files.items():
            if (existing_name.lower() == filename.lower() or
                filename.lower() in existing_name.lower() or
                existing_name.lower() in filename.lower()):
                return paths[0] if paths else None
        
        return None

    def _find_best_path_match(self, original_path: str, candidates: List[str]) -> str:
        """ê°€ì¥ ì í•©í•œ ê²½ë¡œ ë§¤ì¹˜ ì°¾ê¸°"""
        original_parts = Path(original_path).parts
        best_score = 0
        best_match = candidates[0]
        
        for candidate in candidates:
            candidate_parts = Path(candidate).parts
            score = len(set(original_parts) & set(candidate_parts))
            if score > best_score:
                best_score = score
                best_match = candidate
        
        return best_match

    def repair_all_references(self) -> List[RepairResult]:
        """ëª¨ë“  ê¹¨ì§„ ì°¸ì¡° ìˆ˜ë¦¬"""
        logger.info("íŒŒì¼ ì°¸ì¡° ìˆ˜ë¦¬ ì‹œì‘...")
        
        # íŒŒì¼ë³„ë¡œ ê·¸ë£¹í™”
        files_to_repair = {}
        for issue in self.issues:
            if issue.source_file not in files_to_repair:
                files_to_repair[issue.source_file] = []
            files_to_repair[issue.source_file].append(issue)
        
        # ê° íŒŒì¼ ìˆ˜ë¦¬
        for file_path, issues in files_to_repair.items():
            # ìˆ˜ì • ê°€ëŠ¥í•œ ì´ìŠˆë§Œ ì²˜ë¦¬
            fixable_issues = [issue for issue in issues if issue.suggested_fix]
            if fixable_issues:
                result = self._repair_file_references(file_path, fixable_issues)
                self.repair_results.append(result)
        
        logger.info(f"ì´ {len(self.repair_results)}ê°œ íŒŒì¼ ìˆ˜ë¦¬ ì™„ë£Œ")
        return self.repair_results

    def _repair_file_references(self, file_path: str, issues: List[FileReferenceIssue]) -> RepairResult:
        """ê°œë³„ íŒŒì¼ì˜ ì°¸ì¡° ìˆ˜ë¦¬"""
        full_path = self.root_path / file_path
        changes_made = []
        
        try:
            # ë°±ì—… ìƒì„±
            backup_created = self._create_backup(full_path)
            
            # íŒŒì¼ ì½ê¸°
            with open(full_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            # ë¼ì¸ë³„ ìˆ˜ì • (ì—­ìˆœìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ë¼ì¸ ë²ˆí˜¸ ë³€ê²½ ë°©ì§€)
            issues_sorted = sorted(issues, key=lambda x: x.line_number, reverse=True)
            
            for issue in issues_sorted:
                if issue.suggested_fix and issue.line_number <= len(lines):
                    old_line = lines[issue.line_number - 1]
                    new_line = old_line.replace(issue.referenced_path, issue.suggested_fix)
                    if new_line != old_line:
                        lines[issue.line_number - 1] = new_line
                        changes_made.append(f"Line {issue.line_number}: {issue.referenced_path} â†’ {issue.suggested_fix}")
            
            # íŒŒì¼ ì“°ê¸°
            if changes_made:
                with open(full_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines)
            
            return RepairResult(
                file_path=file_path,
                repair_type="file_reference",
                success=True,
                changes_made=changes_made,
                backup_created=backup_created
            )
            
        except Exception as e:
            return RepairResult(
                file_path=file_path,
                repair_type="file_reference",
                success=False,
                changes_made=[],
                backup_created=False,
                error_message=str(e)
            )

    def _create_backup(self, file_path: Path) -> bool:
        """íŒŒì¼ ë°±ì—… ìƒì„±"""
        try:
            if not self.backup_dir.exists():
                self.backup_dir.mkdir(parents=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = self.backup_dir / f"{file_path.name}.backup_{timestamp}"
            shutil.copy2(file_path, backup_path)
            return True
        except Exception as e:
            logger.error(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨ {file_path}: {e}")
            return False

    def generate_comprehensive_report(self) -> Dict:
        """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
        high_severity = [i for i in self.issues if i.severity == 'high']
        medium_severity = [i for i in self.issues if i.severity == 'medium']
        low_severity = [i for i in self.issues if i.severity == 'low']
        
        fixable_issues = [i for i in self.issues if i.suggested_fix]
        unfixable_issues = [i for i in self.issues if not i.suggested_fix]
        
        report = {
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "summary": {
                "total_issues": len(self.issues),
                "high_severity": len(high_severity),
                "medium_severity": len(medium_severity),
                "low_severity": len(low_severity),
                "fixable_issues": len(fixable_issues),
                "unfixable_issues": len(unfixable_issues),
                "files_repaired": len(self.repair_results),
                "successful_repairs": len([r for r in self.repair_results if r.success]),
                "issues_by_type": {
                    "broken_import": len([i for i in self.issues if i.issue_type == 'broken_import']),
                    "missing_file": len([i for i in self.issues if i.issue_type == 'missing_file']),
                    "invalid_script": len([i for i in self.issues if i.issue_type == 'invalid_script'])
                }
            },
            "repair_results": [
                {
                    "file_path": result.file_path,
                    "repair_type": result.repair_type,
                    "success": result.success,
                    "changes_made": result.changes_made,
                    "backup_created": result.backup_created,
                    "error_message": result.error_message
                }
                for result in self.repair_results
            ],
            "remaining_issues": [
                {
                    "source_file": issue.source_file,
                    "referenced_path": issue.referenced_path,
                    "line_number": issue.line_number,
                    "issue_type": issue.issue_type,
                    "context": issue.context,
                    "severity": issue.severity,
                    "suggested_fix": issue.suggested_fix
                }
                for issue in unfixable_issues[:100]  # ìƒìœ„ 100ê°œë§Œ
            ]
        }
        
        return report

    def save_report(self, report: Dict, filename: str = "comprehensive_file_reference_repair_report.json"):
        """ë³´ê³ ì„œ ì €ì¥"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        logger.info(f"ë³´ê³ ì„œ ì €ì¥: {filename}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”§ POSCO ì‹œìŠ¤í…œ íŒŒì¼ ì°¸ì¡° ë¬´ê²°ì„± ì™„ì „ ë³µêµ¬ ë„êµ¬")
    print("=" * 60)
    
    repairer = ComprehensiveFileReferenceRepairer()
    
    # 1. íŒŒì¼ ì°¸ì¡° ìŠ¤ìº”
    print("\n1ï¸âƒ£ ì¢…í•©ì ì¸ íŒŒì¼ ì°¸ì¡° ìŠ¤ìº” ì¤‘...")
    issues = repairer.scan_all_file_references()
    print(f"   ğŸ“Š {len(issues)}ê°œì˜ íŒŒì¼ ì°¸ì¡° ë¬¸ì œ ë°œê²¬")
    
    if issues:
        # ë¬¸ì œ ìœ í˜•ë³„ ë¶„ì„
        broken_imports = [i for i in issues if i.issue_type == 'broken_import']
        missing_files = [i for i in issues if i.issue_type == 'missing_file']
        invalid_scripts = [i for i in issues if i.issue_type == 'invalid_script']
        fixable_issues = [i for i in issues if i.suggested_fix]
        
        print(f"   â€¢ ê¹¨ì§„ import: {len(broken_imports)}ê°œ")
        print(f"   â€¢ ëˆ„ë½ëœ íŒŒì¼: {len(missing_files)}ê°œ")
        print(f"   â€¢ ì˜ëª»ëœ ìŠ¤í¬ë¦½íŠ¸: {len(invalid_scripts)}ê°œ")
        print(f"   â€¢ ìˆ˜ì • ê°€ëŠ¥í•œ ë¬¸ì œ: {len(fixable_issues)}ê°œ")
        
        # 2. ìˆ˜ì • ê°€ëŠ¥í•œ ì°¸ì¡° ìˆ˜ë¦¬
        if fixable_issues:
            print(f"\n2ï¸âƒ£ {len(fixable_issues)}ê°œì˜ ìˆ˜ì • ê°€ëŠ¥í•œ ì°¸ì¡° ìˆ˜ë¦¬ ì¤‘...")
            repair_results = repairer.repair_all_references()
            successful = len([r for r in repair_results if r.success])
            print(f"   âœ… {successful}/{len(repair_results)}ê°œ íŒŒì¼ ìˆ˜ë¦¬ ì™„ë£Œ")
        
        # 3. ì¢…í•© ë³´ê³ ì„œ ìƒì„±
        print("\n3ï¸âƒ£ ì¢…í•© ìˆ˜ë¦¬ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
        report = repairer.generate_comprehensive_report()
        repairer.save_report(report)
        print("   âœ… ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        
        # ê²°ê³¼ ìš”ì•½
        print(f"\nğŸ“Š ìµœì¢… ìˆ˜ë¦¬ ê²°ê³¼:")
        print(f"   â€¢ ë°œê²¬ëœ ë¬¸ì œ: {len(issues)}ê°œ")
        print(f"   â€¢ ìˆ˜ë¦¬ëœ íŒŒì¼: {report['summary']['successful_repairs']}ê°œ")
        print(f"   â€¢ ë‚¨ì€ ë¬¸ì œ: {report['summary']['unfixable_issues']}ê°œ")
        print(f"   â€¢ ë°±ì—… ë””ë ‰í† ë¦¬: {repairer.backup_dir}")
        
        # ì£¼ìš” ì„±ê³¼
        if report['summary']['successful_repairs'] > 0:
            print(f"\nğŸ‰ ì£¼ìš” ì„±ê³¼:")
            total_changes = sum(len(r['changes_made']) for r in report['repair_results'] if r['success'])
            print(f"   â€¢ ì´ {total_changes}ê°œì˜ íŒŒì¼ ì°¸ì¡° ìˆ˜ì • ì™„ë£Œ")
            print(f"   â€¢ íŒŒì¼ ì°¸ì¡° ë¬´ê²°ì„± í¬ê²Œ ê°œì„ ")
    else:
        print("   âœ… íŒŒì¼ ì°¸ì¡° ë¬¸ì œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    
    return len(issues) == 0 or len([r for r in repairer.repair_results if r.success]) > 0

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)