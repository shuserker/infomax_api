#!/usr/bin/env python3
"""
POSCO ì‹œìŠ¤í…œ ë°±ì—… ë° ë¡¤ë°± ì‹œìŠ¤í…œ
System Backup and Rollback Manager

ê¸°ì¡´ ì‹œìŠ¤í…œì˜ ëª¨ë“  ë‚´ìš©ê³¼ ë¡œì§ì„ ì™„ì „íˆ ë³´ì¡´í•˜ë©´ì„œ ì•ˆì „í•œ ë°±ì—…/ë³µêµ¬ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import sys
import shutil
import json
import hashlib
import tarfile
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import logging

# í•œê¸€ ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backup_system.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SystemBackupManager:
    """ì‹œìŠ¤í…œ ë°±ì—… ê´€ë¦¬ì"""
    
    def __init__(self):
        self.backup_root = Path("archive/backups")
        self.backup_root.mkdir(parents=True, exist_ok=True)
        
        # í•µì‹¬ ë³´ì¡´ íŒŒì¼ ëª©ë¡ (ì ˆëŒ€ ë³€ê²½ ê¸ˆì§€)
        self.critical_files = [
            "POSCO_News_250808.py",
            "ğŸ¹POSCO_ì›Œì¹˜í–„ìŠ¤í„°_v3_ì œì–´ì„¼í„°.bat",
            "ğŸ¹POSCO_ì›Œì¹˜í–„ìŠ¤í„°_v3_ì œì–´ì„¼í„°.command",
            "Monitoring/POSCO_News_250808/posco_main_notifier.py",
            "Monitoring/POSCO_News_250808/posco_main_notifier_minimal.py",
            "Monitoring/POSCO_News_250808/monitor_WatchHamster_v3.0_minimal.py"
        ]
        
        # ë°±ì—… ë©”íƒ€ë°ì´í„°
        self.metadata_file = self.backup_root / "backup_metadata.json"
        self.load_metadata()
    
    def load_metadata(self):
        """ë°±ì—… ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    self.metadata = json.load(f)
            except Exception as e:
                logger.warning(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.metadata = {}
        else:
            self.metadata = {}
    
    def save_metadata(self):
        """ë°±ì—… ë©”íƒ€ë°ì´í„° ì €ì¥"""
        try:
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.metadata, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def create_full_backup(self) -> str:
        """ì „ì²´ ì‹œìŠ¤í…œ ë°±ì—… ìƒì„±"""
        backup_id = f"full_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        backup_path = self.backup_root / backup_id
        
        logger.info(f"ğŸ”„ ì „ì²´ ì‹œìŠ¤í…œ ë°±ì—… ì‹œì‘: {backup_id}")
        
        try:
            # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
            backup_path.mkdir(exist_ok=True)
            
            # í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ ë°±ì—… (ìˆ¨ê¹€ íŒŒì¼ ì œì™¸)
            exclude_patterns = [
                '__pycache__',
                '*.pyc',
                '.git',
                'archive/backups',  # ë°±ì—… ë””ë ‰í† ë¦¬ ìì²´ëŠ” ì œì™¸
                '*.log'
            ]
            
            file_count = 0
            total_size = 0
            
            for root, dirs, files in os.walk('.'):
                # ì œì™¸í•  ë””ë ‰í† ë¦¬ í•„í„°ë§
                dirs[:] = [d for d in dirs if not any(pattern in os.path.join(root, d) for pattern in exclude_patterns)]
                
                for file in files:
                    file_path = Path(root) / file
                    
                    # ì œì™¸ íŒ¨í„´ ì²´í¬
                    if any(pattern in str(file_path) for pattern in exclude_patterns):
                        continue
                    
                    try:
                        # ìƒëŒ€ ê²½ë¡œë¡œ ë°±ì—…
                        relative_path = file_path.relative_to('.')
                        backup_file_path = backup_path / relative_path
                        
                        # ë””ë ‰í† ë¦¬ ìƒì„±
                        backup_file_path.parent.mkdir(parents=True, exist_ok=True)
                        
                        # íŒŒì¼ ë³µì‚¬
                        shutil.copy2(file_path, backup_file_path)
                        
                        file_count += 1
                        total_size += file_path.stat().st_size
                        
                        if file_count % 100 == 0:
                            logger.info(f"ì§„í–‰ ìƒí™©: {file_count}ê°œ íŒŒì¼ ë°±ì—… ì™„ë£Œ")
                            
                    except Exception as e:
                        logger.warning(f"íŒŒì¼ ë°±ì—… ì‹¤íŒ¨ {file_path}: {e}")
            
            # ë°±ì—… ì••ì¶•
            compressed_backup = self._compress_backup(backup_path, backup_id)
            
            # ì²´í¬ì„¬ ìƒì„±
            checksum = self._calculate_checksum(compressed_backup)
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            self.metadata[backup_id] = {
                'type': 'full_backup',
                'created_at': datetime.now().isoformat(),
                'file_count': file_count,
                'total_size': total_size,
                'compressed_file': str(compressed_backup),
                'checksum': checksum,
                'description': 'ì •ë¦¬ ì‘ì—… ì‹œì‘ ì „ ì „ì²´ ì‹œìŠ¤í…œ ë°±ì—…'
            }
            
            self.save_metadata()
            
            # ì›ë³¸ ë””ë ‰í† ë¦¬ ì‚­ì œ (ì••ì¶• íŒŒì¼ë§Œ ë³´ê´€)
            shutil.rmtree(backup_path)
            
            logger.info(f"âœ… ì „ì²´ ë°±ì—… ì™„ë£Œ: {backup_id}")
            logger.info(f"   íŒŒì¼ ìˆ˜: {file_count:,}ê°œ")
            logger.info(f"   ì´ í¬ê¸°: {total_size / 1024 / 1024:.1f}MB")
            logger.info(f"   ì••ì¶• íŒŒì¼: {compressed_backup}")
            
            return backup_id
            
        except Exception as e:
            logger.error(f"âŒ ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            if backup_path.exists():
                shutil.rmtree(backup_path)
            raise
    
    def _compress_backup(self, backup_path: Path, backup_id: str) -> Path:
        """ë°±ì—… ë””ë ‰í† ë¦¬ ì••ì¶•"""
        compressed_file = self.backup_root / f"{backup_id}.tar.gz"
        
        logger.info(f"ğŸ—œï¸ ë°±ì—… ì••ì¶• ì¤‘: {compressed_file}")
        
        with tarfile.open(compressed_file, 'w:gz') as tar:
            tar.add(backup_path, arcname=backup_id)
        
        return compressed_file
    
    def _calculate_checksum(self, file_path: Path) -> str:
        """íŒŒì¼ ì²´í¬ì„¬ ê³„ì‚°"""
        hash_sha256 = hashlib.sha256()
        
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_sha256.update(chunk)
        
        return hash_sha256.hexdigest()
    
    def create_stage_backup(self, stage_name: str, changed_files: List[str] = None) -> str:
        """ë‹¨ê³„ë³„ ë°±ì—… ìƒì„±"""
        backup_id = f"stage_{stage_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        backup_path = self.backup_root / backup_id
        
        logger.info(f"ğŸ”„ ë‹¨ê³„ë³„ ë°±ì—… ì‹œì‘: {stage_name}")
        
        try:
            backup_path.mkdir(exist_ok=True)
            
            # ë³€ê²½ëœ íŒŒì¼ë“¤ë§Œ ë°±ì—… (ì§€ì •ëœ ê²½ìš°)
            if changed_files:
                files_to_backup = changed_files
            else:
                # í•µì‹¬ íŒŒì¼ë“¤ì€ í•­ìƒ ë°±ì—…
                files_to_backup = [f for f in self.critical_files if Path(f).exists()]
            
            file_count = 0
            for file_path in files_to_backup:
                try:
                    source = Path(file_path)
                    if source.exists():
                        dest = backup_path / file_path
                        dest.parent.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(source, dest)
                        file_count += 1
                except Exception as e:
                    logger.warning(f"íŒŒì¼ ë°±ì—… ì‹¤íŒ¨ {file_path}: {e}")
            
            # ì••ì¶• ë° ë©”íƒ€ë°ì´í„° ì €ì¥
            compressed_backup = self._compress_backup(backup_path, backup_id)
            checksum = self._calculate_checksum(compressed_backup)
            
            self.metadata[backup_id] = {
                'type': 'stage_backup',
                'stage_name': stage_name,
                'created_at': datetime.now().isoformat(),
                'file_count': file_count,
                'compressed_file': str(compressed_backup),
                'checksum': checksum,
                'files': files_to_backup
            }
            
            self.save_metadata()
            shutil.rmtree(backup_path)
            
            logger.info(f"âœ… ë‹¨ê³„ë³„ ë°±ì—… ì™„ë£Œ: {backup_id} ({file_count}ê°œ íŒŒì¼)")
            return backup_id
            
        except Exception as e:
            logger.error(f"âŒ ë‹¨ê³„ë³„ ë°±ì—… ì‹¤íŒ¨: {e}")
            if backup_path.exists():
                shutil.rmtree(backup_path)
            raise
    
    def list_backups(self) -> List[Dict]:
        """ë°±ì—… ëª©ë¡ ì¡°íšŒ"""
        backups = []
        for backup_id, info in self.metadata.items():
            backups.append({
                'id': backup_id,
                'type': info.get('type', 'unknown'),
                'created_at': info.get('created_at', ''),
                'file_count': info.get('file_count', 0),
                'description': info.get('description', info.get('stage_name', ''))
            })
        
        # ìƒì„± ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬
        backups.sort(key=lambda x: x['created_at'], reverse=True)
        return backups
    
    def rollback_to_backup(self, backup_id: str) -> bool:
        """ì§€ì •ëœ ë°±ì—…ìœ¼ë¡œ ë¡¤ë°±"""
        if backup_id not in self.metadata:
            logger.error(f"âŒ ë°±ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {backup_id}")
            return False
        
        backup_info = self.metadata[backup_id]
        compressed_file = Path(backup_info['compressed_file'])
        
        if not compressed_file.exists():
            logger.error(f"âŒ ë°±ì—… íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {compressed_file}")
            return False
        
        logger.info(f"ğŸ”„ ë¡¤ë°± ì‹œì‘: {backup_id}")
        
        try:
            # ì²´í¬ì„¬ ê²€ì¦
            current_checksum = self._calculate_checksum(compressed_file)
            if current_checksum != backup_info['checksum']:
                logger.error("âŒ ë°±ì—… íŒŒì¼ ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨")
                return False
            
            # í˜„ì¬ ìƒíƒœ ì„ì‹œ ë°±ì—…
            emergency_backup = self.create_stage_backup("emergency_before_rollback")
            logger.info(f"ë¹„ìƒ ë°±ì—… ìƒì„±: {emergency_backup}")
            
            # ë°±ì—… ì••ì¶• í•´ì œ
            temp_restore_path = self.backup_root / f"temp_restore_{int(time.time())}"
            
            with tarfile.open(compressed_file, 'r:gz') as tar:
                tar.extractall(temp_restore_path)
            
            # ë°±ì—… ë‚´ìš©ì„ í˜„ì¬ ë””ë ‰í† ë¦¬ë¡œ ë³µì›
            backup_content_path = temp_restore_path / backup_id
            
            if backup_info['type'] == 'full_backup':
                # ì „ì²´ ë³µì›
                logger.info("ì „ì²´ ì‹œìŠ¤í…œ ë³µì› ì¤‘...")
                
                # ê¸°ì¡´ íŒŒì¼ë“¤ ë°±ì—… í›„ ì‚­ì œ (í•µì‹¬ íŒŒì¼ ì œì™¸)
                for item in Path('.').iterdir():
                    if item.name not in ['archive', '.git', '.kiro']:
                        if item.is_file():
                            item.unlink()
                        elif item.is_dir():
                            shutil.rmtree(item)
                
                # ë°±ì—…ì—ì„œ ë³µì›
                for item in backup_content_path.iterdir():
                    if item.is_file():
                        shutil.copy2(item, item.name)
                    elif item.is_dir():
                        shutil.copytree(item, item.name)
            
            else:
                # ë¶€ë¶„ ë³µì› (ë‹¨ê³„ë³„ ë°±ì—…)
                logger.info("ë¶€ë¶„ ì‹œìŠ¤í…œ ë³µì› ì¤‘...")
                
                for file_path in backup_info.get('files', []):
                    source = backup_content_path / file_path
                    dest = Path(file_path)
                    
                    if source.exists():
                        dest.parent.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(source, dest)
            
            # ì„ì‹œ ë””ë ‰í† ë¦¬ ì •ë¦¬
            shutil.rmtree(temp_restore_path)
            
            logger.info(f"âœ… ë¡¤ë°± ì™„ë£Œ: {backup_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ë¡¤ë°± ì‹¤íŒ¨: {e}")
            return False
    
    def verify_backup_integrity(self, backup_id: str) -> bool:
        """ë°±ì—… ë¬´ê²°ì„± ê²€ì¦"""
        if backup_id not in self.metadata:
            return False
        
        backup_info = self.metadata[backup_id]
        compressed_file = Path(backup_info['compressed_file'])
        
        if not compressed_file.exists():
            return False
        
        try:
            current_checksum = self._calculate_checksum(compressed_file)
            return current_checksum == backup_info['checksum']
        except:
            return False

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='POSCO ì‹œìŠ¤í…œ ë°±ì—… ê´€ë¦¬')
    parser.add_argument('--create-full', action='store_true', help='ì „ì²´ ë°±ì—… ìƒì„±')
    parser.add_argument('--create-stage', type=str, help='ë‹¨ê³„ë³„ ë°±ì—… ìƒì„±')
    parser.add_argument('--list', action='store_true', help='ë°±ì—… ëª©ë¡ ì¡°íšŒ')
    parser.add_argument('--rollback', type=str, help='ì§€ì •ëœ ë°±ì—…ìœ¼ë¡œ ë¡¤ë°±')
    parser.add_argument('--verify', type=str, help='ë°±ì—… ë¬´ê²°ì„± ê²€ì¦')
    
    args = parser.parse_args()
    
    backup_manager = SystemBackupManager()
    
    try:
        if args.create_full:
            backup_id = backup_manager.create_full_backup()
            print(f"âœ… ì „ì²´ ë°±ì—… ìƒì„± ì™„ë£Œ: {backup_id}")
            
        elif args.create_stage:
            backup_id = backup_manager.create_stage_backup(args.create_stage)
            print(f"âœ… ë‹¨ê³„ë³„ ë°±ì—… ìƒì„± ì™„ë£Œ: {backup_id}")
            
        elif args.list:
            backups = backup_manager.list_backups()
            print("\nğŸ“‹ ë°±ì—… ëª©ë¡:")
            print("-" * 80)
            for backup in backups:
                print(f"ID: {backup['id']}")
                print(f"ìœ í˜•: {backup['type']}")
                print(f"ìƒì„±ì¼: {backup['created_at']}")
                print(f"íŒŒì¼ ìˆ˜: {backup['file_count']:,}ê°œ")
                print(f"ì„¤ëª…: {backup['description']}")
                print("-" * 80)
                
        elif args.rollback:
            success = backup_manager.rollback_to_backup(args.rollback)
            if success:
                print(f"âœ… ë¡¤ë°± ì™„ë£Œ: {args.rollback}")
            else:
                print(f"âŒ ë¡¤ë°± ì‹¤íŒ¨: {args.rollback}")
                
        elif args.verify:
            is_valid = backup_manager.verify_backup_integrity(args.verify)
            if is_valid:
                print(f"âœ… ë°±ì—… ë¬´ê²°ì„± ê²€ì¦ í†µê³¼: {args.verify}")
            else:
                print(f"âŒ ë°±ì—… ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨: {args.verify}")
                
        else:
            parser.print_help()
            
    except Exception as e:
        logger.error(f"âŒ ì‘ì—… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()